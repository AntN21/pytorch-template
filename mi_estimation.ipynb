{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer\n",
    "from utils import prepare_device\n",
    "from experiments import get_experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config='config.json', resume=None, device=None, exp=0)\n",
      "<class 'argparse.Namespace'>\n",
      "Experiment 0 / 112:\n",
      "                USE_ECG: True\n",
      "                USE_HRV: True\n",
      "                USE_FEATURES: True\n",
      "                HRV_DURATION: 5m\n",
      "                ECG_DURATION: 30s\n",
      "                ADDITIONAL_FEATURES: ['newmultifracs', 'shannon_encoding', 'autoreg']                \n",
      "{'_config': OrderedDict([('name', 'MyTraining'), ('n_gpu', 1), ('arch', OrderedDict([('type', 'MyModel'), ('args', OrderedDict([('use_ecg_time_series', True), ('use_hrv_time_series', True), ('use_features', True)]))])), ('data_loader', OrderedDict([('type', 'MyDataLoader'), ('args', OrderedDict([('data_dir', 'data/data_patient'), ('batch_size', 32), ('shuffle', True), ('validation_split', 0.2), ('num_workers', 2), ('features_duration', '5m'), ('hrv_duration', '5m'), ('ecg_duration', '30s'), ('additional_feature_names', ['newmultifracs', 'shannon_encoding', 'autoreg'])]))])), ('optimizer', OrderedDict([('type', 'Adam'), ('args', OrderedDict([('lr', 0.001), ('amsgrad', True)]))])), ('loss', 'cross_entropy'), ('metrics', ['accuracy', 'top_k_acc']), ('lr_scheduler', OrderedDict([('type', 'StepLR'), ('args', OrderedDict([('step_size', 50), ('gamma', 0.9)]))])), ('trainer', OrderedDict([('epochs', 3), ('save_dir', 'saved/'), ('save_period', 10), ('verbosity', 2), ('monitor', 'min val_loss'), ('early_stop', 30), ('tensorboard', True)])), ('id', 0)]), 'resume': None, '_save_dir': WindowsPath('saved/models/MyTraining/0/1018_145720'), '_log_dir': WindowsPath('saved/log/MyTraining/0/1018_145720'), 'log_levels': {0: 30, 1: 20, 2: 10}}\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser(description='PyTorch Template')\n",
    "args.add_argument('-c', '--config', default=None, type=str,\n",
    "                      help='config file path (default: None)')\n",
    "args.add_argument('-r', '--resume', default=None, type=str,\n",
    "                      help='path to latest checkpoint (default: None)')\n",
    "args.add_argument('-d', '--device', default=None, type=str,\n",
    "                  help='indices of GPUs to enable (default: all)')\n",
    "# args.add_argument(\"-e\", \"--exp\", type=int, required=True, help=\"Experiment id\")\n",
    "# args\n",
    "# args.c = \"config.json\"\n",
    "# \n",
    "\n",
    "args = args.parse_args(['-c','config.json',])\n",
    "args.exp = 0\n",
    "# batch_size = 10_000\n",
    "print(args)\n",
    "print(type(args))\n",
    "config = ConfigParser.from_args(args)\n",
    "config = get_experiment_config(config, config['id'])\n",
    "# config['data_loader']['args'][\"additional_feature_names\"] =  []\n",
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.dataset.get_feature_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = config.init_obj('data_loader', module_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hrv_conv): ConvNet(\n",
       "    (conv1): Conv1d(1, 16, kernel_size=(5,), stride=(1,))\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n",
       "    (conv3): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv4): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv5): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv6): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv7): Conv1d(32, 256, kernel_size=(3,), stride=(1,))\n",
       "    (conv8): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (global_maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (ecg_conv): ConvNet(\n",
       "    (conv1): Conv1d(1, 16, kernel_size=(5,), stride=(1,))\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n",
       "    (conv3): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv4): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv5): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv6): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
       "    (conv7): Conv1d(32, 256, kernel_size=(3,), stride=(1,))\n",
       "    (conv8): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (global_maxpool): AdaptiveMaxPool1d(output_size=1)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (features): Identity()\n",
       "  (mlp): MLPClassifier(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=89, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_loader = getattr(module_data, config['data_loader']['type'])(\n",
    "#         config['data_loader']['args']['data_dir'],\n",
    "#         batch_size=512,\n",
    "#         shuffle=False,\n",
    "#         validation_split=0.0,\n",
    "#         training=False,\n",
    "#         num_workers=2\n",
    "#     )\n",
    "\n",
    "config['arch']['args']['feature_size'] = data_loader.dataset.get_feature_size()\n",
    "config['arch']['args']['num_classes'] = data_loader.dataset.get_num_classes()\n",
    "\n",
    "# build model architecture\n",
    "model = config.init_obj('arch', module_arch)\n",
    "# logger.info(model)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "loss_fn = getattr(module_loss, config['loss'])\n",
    "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
    "checkpoint = torch.load(\"saved/models/MyTraining/0/0926_144845/model_best.pth\") # config.resume)\n",
    "state_dict = checkpoint['state_dict']\n",
    "# if config['n_gpu'] > 1:\n",
    "#     model = torch.nn.DataParallel(model)\n",
    "# state_dict = \n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# prepare model for testing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:39<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0.0\n",
    "total_metrics = torch.zeros(len(metric_fns))\n",
    "\n",
    "outputs = []\n",
    "inputs = []\n",
    "inputs_ecg = []\n",
    "inputs_hrv = []\n",
    "outputs1 = []\n",
    "outputs2 = []\n",
    "outputs3 = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(tqdm(data_loader)):\n",
    "        # data, target = data.to(device), target.to(device)\n",
    "\n",
    "        out1 = model.flatten(model.ecg_conv(data[\"ecg_time_series\"]))\n",
    "        out2 = model.flatten(model.hrv_conv(data[\"hrv_time_series\"]))\n",
    "\n",
    "        features = model.features(data[\"features\"])\n",
    "    \n",
    "        concat = torch.cat([model.flatten(out1), model.flatten(out2), features],dim=-1)\n",
    "        outputs.append(concat)\n",
    "        \n",
    "        labels.append(target)\n",
    "        inputs.append(data)\n",
    "        inputs_ecg.append(data[\"ecg_time_series\"])\n",
    "        inputs_hrv.append(data[\"hrv_time_series\"])\n",
    "        outputs1.append(out1)\n",
    "        outputs2.append(out2)\n",
    "        outputs3.append(features)\n",
    "        #\n",
    "        # save sample images, or do something with output here\n",
    "        #\n",
    "\n",
    "        # computing loss, metrics on test set\n",
    "        # loss = loss_fn(output, target)\n",
    "        # batch_size = data.shape[0]\n",
    "        # total_loss += loss.item() * batch_size\n",
    "        # for i, metric in enumerate(metric_fns):\n",
    "        #     total_metrics[i] += metric(output, target) * batch_size\n",
    "\n",
    "# inputs = torch.cat(inputs)\n",
    "inputs_ecg = torch.cat(inputs_ecg,dim=0)\n",
    "inputs_hrv = torch.cat(inputs_hrv,dim=0)\n",
    "outputs = torch.cat(outputs,dim=0)\n",
    "outputs1 = torch.cat(outputs1,dim=0)\n",
    "outputs2 = torch.cat(outputs2,dim=0)\n",
    "outputs3 = torch.cat(outputs3,dim=0)\n",
    "\n",
    "labels = torch.cat(labels,dim=0)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.my_model import ConvNet\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y, labels):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the features and corresponding label at the given index\n",
    "        return self.X[idx], self.Y[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(X=inputs_ecg,Y=outputs1,labels=torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,label = dataset[:]\n",
    "X = np.array(X).squeeze()\n",
    "y = np.array(y)\n",
    "label = np.array(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 3840)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mutual_info_classif(X,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6404705  0.57393381 0.61927569 0.58060789 0.59413071 0.50187154\n",
      " 0.60830378 0.62696188 0.32441916 0.53262602 0.61225841 0.74059727\n",
      " 0.48948113 0.59043673 0.54220141 0.45538354 0.37147048 0.50280187\n",
      " 0.30205925 0.27534448 0.56806143 0.68974686 0.57530696 0.56609478\n",
      " 0.66276285 0.72381776 0.79170604 0.69976952 0.35594996 0.53310458\n",
      " 0.73651443 0.25047196]\n",
      "0.5511857096775474\n",
      "[0.63384949 0.56602845 0.6289287  0.58991649 0.60558246 0.51296952\n",
      " 0.60294843 0.62982341 0.31535674 0.53276119 0.61623834 0.74128486\n",
      " 0.48993895 0.58747691 0.54789223 0.46922131 0.35509732 0.50283769\n",
      " 0.3025302  0.27304373 0.56164058 0.69962279 0.57169637 0.55783955\n",
      " 0.66442238 0.71077282 0.78734242 0.70015154 0.35402105 0.53259765\n",
      " 0.73623339 0.24535914]\n",
      "0.5507945652957595\n",
      "[0.63953696 0.57240928 0.63758452 0.59612831 0.61130032 0.51819036\n",
      " 0.61575303 0.63328438 0.31412404 0.54161889 0.62323628 0.75339921\n",
      " 0.49606786 0.59351975 0.55951108 0.48407816 0.35615827 0.50150089\n",
      " 0.29434321 0.28054456 0.57796053 0.70984124 0.57996759 0.56814154\n",
      " 0.67165075 0.72621674 0.79334757 0.71797054 0.36583392 0.54627968\n",
      " 0.74678496 0.2525238 ]\n",
      "0.5587127570039747\n",
      "[0.64910335 0.58006608 0.64830421 0.60477231 0.62583611 0.51489452\n",
      " 0.62375225 0.64650835 0.310198   0.55181666 0.63338267 0.76084898\n",
      " 0.49625797 0.59416444 0.55585292 0.49183837 0.36472164 0.49259519\n",
      " 0.28734509 0.27673106 0.58181451 0.71044631 0.58955429 0.57740089\n",
      " 0.67863303 0.73100237 0.79899324 0.72870212 0.37129383 0.54501248\n",
      " 0.75225308 0.2440404 ]\n",
      "0.5630667733062371\n",
      "[0.65951998 0.6127167  0.65903335 0.61772835 0.67209896 0.52302115\n",
      " 0.6167663  0.65842519 0.273286   0.58650851 0.65236764 0.78464732\n",
      " 0.50282295 0.59070077 0.56882081 0.51215208 0.36623246 0.52754733\n",
      " 0.28135252 0.23323329 0.56419394 0.71996002 0.61038144 0.5904395\n",
      " 0.68406812 0.75697361 0.82893854 0.74746893 0.3461366  0.55644573\n",
      " 0.77689664 0.24781666]\n",
      "0.5727719186394136\n"
     ]
    }
   ],
   "source": [
    "for n in [3,10,50,100,300]:\n",
    "    res = mutual_info_classif(y,label,n_neighbors=n)\n",
    "    print(res)\n",
    "    print(res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dtw-python\n",
      "  Obtaining dependency information for dtw-python from https://files.pythonhosted.org/packages/32/9f/e0b91a75a810bec321909ed910ee5fca7ba6b7808f5e0f389d90d46623e8/dtw_python-1.5.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading dtw_python-1.5.3-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/49.0 kB ? eta -:--:--\n",
      "     -------- ------------------------------- 10.2/49.0 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 30.7/49.0 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 49.0/49.0 kB 355.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\aejog\\anaconda3\\lib\\site-packages (from dtw-python) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\aejog\\anaconda3\\lib\\site-packages (from dtw-python) (1.24.3)\n",
      "Downloading dtw_python-1.5.3-cp311-cp311-win_amd64.whl (376 kB)\n",
      "   ---------------------------------------- 0.0/376.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/376.2 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 225.3/376.2 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 376.2/376.2 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: dtw-python\n",
      "Successfully installed dtw-python-1.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\aejog\\anaconda3\\lib\\site-packages\\appdirs-1.4.4-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n",
      "DEPRECATION: Loading egg at c:\\users\\aejog\\anaconda3\\lib\\site-packages\\kymatio-0.4.0.dev0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "%pip install dtw-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW distance: 2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dtw import dtw\n",
    "\n",
    "# Example sequences\n",
    "sequence1 = np.array([0, 1, 2, 3, 4, 5])\n",
    "sequence2 = np.array([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Define a distance function (Euclidean distance is commonly used)\n",
    "def euclidean_distance(x, y):\n",
    "    return np.abs(x - y)\n",
    "\n",
    "# Perform DTW\n",
    "alignment = dtw(sequence1, sequence2)\n",
    "\n",
    "# Display the alignment distance\n",
    "print(\"DTW distance:\", alignment.distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\"\"\" Python implementation of the mutual information estimator proposed by\n",
    "Ross, 2014, \"Mutual Information between Discrete and Continuous Data Sets\",\n",
    "PLOS One. Computes mutual information between a continuous multidimensional\n",
    "variable and a discrete (categorical) variable, from an array of samples.\n",
    "\n",
    "The formula for this estimator is\n",
    "    $$ MI(X, Y) = psi(N) - <psi(N_x)> + psi(k) - <psi(m)> $$\n",
    "where:\n",
    "    - psi is the digamma function;\n",
    "    - N is the number of points;\n",
    "    - N_x is the number of points of category X=x;\n",
    "    - k is the number of nearest-neighbors of the same category used to\n",
    "        estimate the probability density;\n",
    "    - m is the number of nearest-neighbors of any category within the ball\n",
    "        extending up to the kth nearest-neighbor of the same category x;\n",
    "    - <psi(N_x)> and <psi(m)> are averaged over samples of X (each category\n",
    "        X=x is weighted by the number of occurences of x);\n",
    "\n",
    "Speed improved by vectorizing some operations, using Scipy's cKDTree\n",
    "for nearest-neighbor search, and using its multi-code capabilities.\n",
    "Includes a direct translation in Python of the original Matlab code\n",
    "provided by Ross 2014, for comparison (it is slower).\n",
    "\n",
    "WARNING: limited testing of the code was carried out. It worked fine on the\n",
    "test case provided below and for the authors' use cases, but results are not\n",
    "guaranteed in other applications (especially with very high-dimensional data).\n",
    "\n",
    "@authors: François Bourassa (frbourassa), Sooraj Achar (soorajachar)\n",
    "Spring 2021\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "from scipy.spatial import cKDTree\n",
    "import psutil\n",
    "\n",
    "\n",
    "def discrete_continuous_info_fast(d, c, k=3, base=np.e, eps=0):\n",
    "    \"\"\"\n",
    "    Estimates mutual information between a discrete vector d and a continuous\n",
    "    vector c (can be multidimensional) using nearest-neighbor statistics.\n",
    "    Relatively fast Python implementation, using Scipy's cKDTree, of the\n",
    "    estimator described by Ross, 2014, \"Mutual Information between Discrete\n",
    "    and Continuous Data Sets\", PLOS One.\n",
    "    Similar to the estimator described by Kraskov et al., 2004,\n",
    "    \"Estimating Mutual Information\", PRE.\n",
    "\n",
    "    Author of this implementation: Francois Bourassa (Github: frbourassa)\n",
    "\n",
    "    Args:\n",
    "        d (np.array): Array of discrete categories. Should be 1-dimensional\n",
    "        c (np.array): Two-dimensional array or matrix of the continuous data.\n",
    "            Dimensions should be (n samples x f features)\n",
    "        k (int): Number of nearest neighbors for density estimation\n",
    "        base (float): Logarithm base in which the MI is computed (default: e)\n",
    "        eps (float): Relative tolerance on the radius up to which neighbors\n",
    "            are included (default: 0, exact computation).\n",
    "\n",
    "    Returns:\n",
    "        float: Mutual information estimate\n",
    "    \"\"\"\n",
    "    # Make sure d is an array to allow use of numpy functions\n",
    "    if type(d) is list:\n",
    "        d = np.asarray(d, dtype=type(d[0]))\n",
    "    if d.ndim > 1:\n",
    "        raise TypeError(\"d should be a 1d list or array\")\n",
    "\n",
    "    # First, prepare a list of categories according to the discrete symbols d\n",
    "    numDimensions = c.shape[0]\n",
    "    categories = list(np.unique(d))\n",
    "    num_d_symbols = len(categories)\n",
    "\n",
    "    # Build a KDTree of all points\n",
    "    main_tree = cKDTree(c, leafsize=max(16, int(k*numDimensions/4)))\n",
    "\n",
    "    # Number of workers for parallel processing, use half of them.\n",
    "    n_workers = min(1, psutil.cpu_count() // 2)\n",
    "\n",
    "    # Check that there are no exactly identical points\n",
    "    identical_pairs = main_tree.query_pairs(r=0.0, eps=0.0, output_type=\"ndarray\")\n",
    "    # If any, perturb them slightly to avoid numerical instabilities\n",
    "    dup_pts = np.unique(identical_pairs[:, 0])\n",
    "    if identical_pairs.shape[0] > 0:\n",
    "        # Average nn distance as a perturbation\n",
    "        perturb = 1e-6*np.mean(main_tree.query(c, k=[2])[0])\n",
    "        # Perturb the first point of each pair\n",
    "        c[dup_pts, :] = c[dup_pts, :] + perturb*(np.random.random(size=(dup_pts.shape[0], c.shape[1])) - 0.5)\n",
    "        # Update the tree\n",
    "        main_tree = cKDTree(c, leafsize=max(16, int(k*numDimensions/4)))\n",
    "\n",
    "    # Build an internal tree for each category\n",
    "    m_tot = 0\n",
    "    av_psi_Nd = 0\n",
    "    psi_ks = 0\n",
    "    for c_bin in range(num_d_symbols):\n",
    "         # Slice elements in that category, save indices\n",
    "        ii = (d == categories[c_bin]).nonzero()\n",
    "        c_split = c[ii]\n",
    "        numSamplesInBin = c_split.shape[0]\n",
    "        one_k = min(k, numSamplesInBin-1)\n",
    "\n",
    "        # For each point in the category, find the radius to its kth\n",
    "        # nearest-neighbor, and count how many points of any category\n",
    "        # are in that radius.\n",
    "        if one_k > 0:\n",
    "            # Build KDTree with leaf size one_k+2, since we won't need\n",
    "            # to go much further\n",
    "            categ_tree = cKDTree(c_split, leafsize=16)\n",
    "\n",
    "            # Go to one_k+1 because self point is included as a neighbors.\n",
    "            radii, indices = categ_tree.query(\n",
    "                                c_split, [one_k+1], eps=eps, workers=n_workers)\n",
    "\n",
    "            # For each, count how many total points are within that distance.\n",
    "            # Increase radii a little bit to make sure at least the one_k\n",
    "            # neighbours in the category are found back\n",
    "            # (float comparison issues in query in a different tree otherwise)\n",
    "            m_points_all = main_tree.query_ball_point(\n",
    "                                c_split, radii.ravel()*(1+1e-15), eps=eps,\n",
    "                                workers=n_workers, return_length=True)\n",
    "            m_points_all -= 1  # the query includes the point itself\n",
    "\n",
    "            # m_tot is \\sum_i (psi(m_i))\n",
    "            m_tot = m_tot + np.sum(special.psi(m_points_all))\n",
    "\n",
    "        else:  # There was a single point in the category.\n",
    "            m_tot = m_tot + special.psi(num_d_symbols*2)\n",
    "\n",
    "        # Probability of each category given by its relative abundance in d\n",
    "        p_d = numSamplesInBin/len(d)\n",
    "        # Running estimates of the average digamma terms in the estimator\n",
    "        av_psi_Nd += p_d*special.psi(p_d*len(d))\n",
    "        psi_ks = psi_ks + p_d * special.psi(max(one_k, 1))\n",
    "    # Computing the estimator\n",
    "    f = special.psi(len(d)) - av_psi_Nd + psi_ks - m_tot/len(d)\n",
    "    return f / np.log(base)\n",
    "\n",
    "\n",
    "def discrete_continuous_info_ref(d, c, k=3, base=np.exp(1)):\n",
    "    \"\"\"\n",
    "    Estimates the mutual information between a discrete vector 'd' and a\n",
    "    continuous vector 'c' using nearest-neighbor statistics.\n",
    "    Python translation of the estimator coded in Matlab\n",
    "    Ross, 2014, https://doi.org/10.1371/journal.pone.0087357\n",
    "    Similar to the estimator proposed by Kraskov et al., 2004,\n",
    "    \"Estimating Mutual Information\", PRE.\n",
    "\n",
    "    Author of the translation: Sooraj Achar (Github: soorajachar)\n",
    "\n",
    "    Parameters:\n",
    "        d (np.array): List of discrete categories. Should be 1 dimensional\n",
    "        c (np.matrix): Matrix of continuous data.\n",
    "            Dimensions should be n samples x f features\n",
    "        k (int): Number of nearest neighbors\n",
    "        base (float): Logarithm base in which the MI is computed (default: e)\n",
    "\n",
    "    Returns:\n",
    "        float: Mutual information estimate\n",
    "    \"\"\"\n",
    "    #Make sure d is an array to allow use of numpy functions\n",
    "    if type(d) is list:\n",
    "        d = np.array(d, dtype=str)\n",
    "    #Remove eventually\n",
    "    if c.shape[1] < c.shape[0]:\n",
    "        c = c.T\n",
    "    first_symbol = []\n",
    "    symbol_IDs = np.zeros(len(d))\n",
    "    c_split = []\n",
    "    cs_indices = []\n",
    "    num_d_symbols = -1\n",
    "    #First, bin the continuous data \"c\" according to the discrete symbols \"d\"\n",
    "    numDimensions = c.shape[0]\n",
    "    categories = list(np.unique(d))\n",
    "    num_d_symbols = len(categories)\n",
    "    for category in categories:\n",
    "        ii = np.where(d == category)[0]\n",
    "        cs_indices.append(ii)\n",
    "        #Flip later\n",
    "        c_split.append(c[:, ii])\n",
    "\n",
    "    m_tot = 0\n",
    "    av_psi_Nd = 0\n",
    "    all_c_distances = np.zeros(len(d))\n",
    "    psi_ks = 0\n",
    "    for c_bin in range(num_d_symbols):\n",
    "        numSamplesInBin = c_split[c_bin].shape[1]\n",
    "        one_k = min(k, numSamplesInBin-1)\n",
    "        if one_k > 0:\n",
    "            c_distances = np.zeros([numSamplesInBin])\n",
    "            for pivot in range(numSamplesInBin):\n",
    "                # find the radius of our volume using only those samples with\n",
    "                # the particular value of the discrete symbol 'd'\n",
    "                for cv in range(numSamplesInBin):\n",
    "                    vec_diff = (c_split[c_bin][:, cv]\n",
    "                                    - c_split[c_bin][:, pivot])\n",
    "                    vec_diff = np.reshape(vec_diff, (-1, c.shape[0])).T\n",
    "                    c_distances[cv] = np.sqrt(np.dot(vec_diff.T, vec_diff))\n",
    "                sorted_distances = np.sort(c_distances)\n",
    "                eps_over_2 = sorted_distances[one_k]   # don't count pivot\n",
    "\n",
    "                #count the number of total samples within our volume using all\n",
    "                #  samples (all values of 'd')\n",
    "                for cv in range(c.shape[1]):\n",
    "                    vec_diff = c[:, cv] - c_split[c_bin][:, pivot]\n",
    "                    vec_diff = np.reshape(vec_diff, (-1, c.shape[0])).T\n",
    "                    all_c_distances[cv] = np.sqrt(np.dot(vec_diff.T, vec_diff))\n",
    "                # Don't count pivot point\n",
    "                neigh_all_categs = np.where(all_c_distances <= eps_over_2)\n",
    "                m = max(len(all_c_distances[neigh_all_categs]) - 1, 0)\n",
    "                m_tot = m_tot + special.psi(m)\n",
    "\n",
    "        else:\n",
    "            m_tot = m_tot + special.psi(num_d_symbols*2)\n",
    "\n",
    "        p_d = numSamplesInBin/len(d)\n",
    "        av_psi_Nd = av_psi_Nd + p_d*special.psi(p_d*len(d))\n",
    "        psi_ks = psi_ks + p_d * special.psi(max(one_k, 1))\n",
    "\n",
    "    f = special.psi(len(d)) - av_psi_Nd + psi_ks - m_tot/len(d)\n",
    "    return f / np.log(base)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Some test case to make sure both approaches work the same way\n",
    "#     # nsamp = 50\n",
    "#     # data = np.zeros([nsamp*4, 2])\n",
    "#     # target = np.zeros(nsamp*4)\n",
    "#     # rndgen = np.random.default_rng(seed=12323452)\n",
    "#     # for i in range(4):\n",
    "#     #     mean = np.asarray([i, i])\n",
    "#     #     cov = np.eye(2)*(i+1)*0.75\n",
    "#     #     data[nsamp*i:nsamp*(i+1)] = rndgen.multivariate_normal(\n",
    "#     #                                         mean=mean, cov=cov, size=nsamp)\n",
    "#     #     target[nsamp*i:nsamp*(i+1)] = i\n",
    "#     target = labels\n",
    "#     print(target.shape)\n",
    "#     data = X\n",
    "#     # Reference algorithm with for loops\n",
    "#     mi_ref = discrete_continuous_info_ref(target, data, k=3, base=2)\n",
    "#     print(\"Reference MI = \", mi_ref)\n",
    "\n",
    "#     # Fast, approximate algorithm using KDTrees and vectorized queries\n",
    "#     mi_fast = discrete_continuous_info_fast(target, data, k=3, base=2)\n",
    "#     msg = \"Difference too large to be true: found \"+str(mi_fast)\n",
    "#     assert abs(mi_ref - mi_fast) < 1e-10, msg\n",
    "#     print(\"Fast MI = \", mi_fast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0036287 , -0.33342677, -0.7028649 , ..., -0.02573977,\n",
       "         0.37117124,  0.02566248],\n",
       "       [-0.8337579 ,  0.35795164, -0.73773265, ...,  0.0935782 ,\n",
       "         0.74977994,  0.07879715],\n",
       "       [-0.934284  ,  0.2652989 , -0.62785053, ...,  0.01784897,\n",
       "         0.8059541 ,  0.14918669],\n",
       "       ...,\n",
       "       [ 0.7639055 ,  0.04372032,  0.6465986 , ...,  0.9228038 ,\n",
       "        -0.49429268,  0.39612967],\n",
       "       [-0.6291675 ,  0.14245938, -0.36647016, ..., -0.02929656,\n",
       "         0.5634943 ,  0.10434194],\n",
       "       [-0.751663  , -0.10784094, -0.36594906, ...,  0.05336997,\n",
       "         0.1765241 ,  0.31795323]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5140,)\n",
      "Reference MI =  1.4995459098992576\n",
      "Fast MI =  1.499545909899439\n"
     ]
    }
   ],
   "source": [
    "target = labels\n",
    "print(target.shape)\n",
    "data = y\n",
    "# # Reference algorithm with for loops\n",
    "mi_ref = discrete_continuous_info_ref(target, data, k=10, base=2)\n",
    "print(\"Reference MI = \", mi_ref)\n",
    "\n",
    "# Fast, approximate algorithm using KDTrees and vectorized queries\n",
    "mi_fast = discrete_continuous_info_fast(target, data, k=10, base=2,eps=1e-5)\n",
    "msg = \"Difference too large to be true: found \"+str(mi_fast)\n",
    "assert abs(mi_ref - mi_fast) < 1e-10, msg\n",
    "print(\"Fast MI = \", mi_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = copy.deepcopy(model.ecg_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MINE(nn.Module):\n",
    "    def __init__(self,zd_dim):\n",
    "        super(MINE, self).__init__()\n",
    "        self.convnet = convnet\n",
    "        self.net = nn.Sequential(nn.Linear(32+zd_dim,64),nn.ReLU(),nn.Linear(64,32),nn.ReLU(),nn.Linear(32,1))#FF(args, zc_dim + zd_dim, zc_dim, 1)\n",
    "\n",
    "    def forward(self, z_c, z_d,y=0):  # samples have shape [sample_size, dim]\n",
    "        # shuffle and concatenate\n",
    "        z_c = self.convnet(z_c)\n",
    "        sample_size = z_d.shape[0]\n",
    "        random_index = torch.randint(sample_size, (sample_size,)).long()\n",
    "\n",
    "        z_d_shuffle = z_d[random_index]\n",
    "\n",
    "        T0 = self.net(torch.cat([z_c, z_d], dim=-1))\n",
    "        T1 = self.net(torch.cat([z_c, z_d_shuffle], dim=-1))\n",
    "\n",
    "        mi = T0.mean() - (T1.squeeze().logsumexp(0) - math.log(sample_size))\n",
    "        return mi, 0., 0.\n",
    "\n",
    "    def learning_loss(self, z_c, z_d,y=0):\n",
    "        return - self(z_c, z_d)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.0225, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0474, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0475, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0845, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0564, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1191, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1043, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1601, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1715, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1475, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1595, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2018, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2275, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2809, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2333, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2735, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3085, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3291, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3373, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3332, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4975, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3024, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4561, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6252, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4631, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6144, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5327, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6993, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7042, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5867, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6749, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5552, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5665, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7020, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6804, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8773, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7485, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8464, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7979, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7042, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9381, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8375, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0047, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9159, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1162, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9457, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0201, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9795, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1031, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.0624)\n",
      "test  tensor(1.0286)\n",
      "test  tensor(0.9507)\n",
      "test  tensor(1.0198)\n",
      "test  tensor(1.2944)\n",
      "test  tensor(0.6560)\n",
      "test  tensor(1.0423)\n",
      "test  tensor(1.2302)\n",
      "test  tensor(1.1995)\n",
      "test  tensor(1.2813)\n",
      "test  tensor(1.1237)\n",
      "test  tensor(0.9517)\n",
      "test  tensor(1.2770)\n",
      "test  tensor(1.0936)\n",
      "test  tensor(1.2109)\n",
      "test  tensor(0.9389)\n",
      "test  tensor(0.5449)\n",
      "train  tensor(1.2028, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0486, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4652, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0218, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1572, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6818, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4026, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2759, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5527, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0848, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5356, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3388, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4689, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   1%|          | 1/100 [01:02<1:43:12, 62.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8628, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3100, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3799, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2406, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3254, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3597, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1981, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1444, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8681, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3825, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5520, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3728, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3725, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2884, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4614, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5000, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4561, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2133, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7527, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6345, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7599, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8987, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5041, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4300, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4943, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2200, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7553, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2957, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6720, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3061, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8937, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3024, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5948, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1073, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7112, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1289, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.4062)\n",
      "test  tensor(1.3511)\n",
      "test  tensor(1.5580)\n",
      "test  tensor(1.4231)\n",
      "test  tensor(1.4346)\n",
      "test  tensor(1.4260)\n",
      "test  tensor(1.3311)\n",
      "test  tensor(1.6392)\n",
      "test  tensor(1.5027)\n",
      "test  tensor(1.7958)\n",
      "test  tensor(1.5260)\n",
      "test  tensor(1.4494)\n",
      "test  tensor(1.5528)\n",
      "test  tensor(1.3703)\n",
      "test  tensor(1.5417)\n",
      "test  tensor(1.2335)\n",
      "test  tensor(0.9217)\n",
      "train  tensor(1.2653, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6200, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4144, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7292, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5935, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6351, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7621, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2609, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3504, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1811, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5909, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5866, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3812, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5725, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8646, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3775, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6509, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2548, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3708, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1171, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8416, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4938, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1700, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5147, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0379, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6575, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9488, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1564, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   2%|▏         | 2/100 [02:06<1:43:18, 63.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.6833, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5813, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3765, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0281, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0561, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1142, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6251, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2823, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7904, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1447, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1175, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3747, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3556, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7998, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0294, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4995, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7854, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0725, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3072, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3151, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.3251)\n",
      "test  tensor(1.1416)\n",
      "test  tensor(1.0770)\n",
      "test  tensor(1.2867)\n",
      "test  tensor(1.7204)\n",
      "test  tensor(1.7883)\n",
      "test  tensor(1.4705)\n",
      "test  tensor(2.2561)\n",
      "test  tensor(1.4199)\n",
      "test  tensor(1.7154)\n",
      "test  tensor(1.1668)\n",
      "test  tensor(1.2414)\n",
      "test  tensor(1.6876)\n",
      "test  tensor(1.7142)\n",
      "test  tensor(1.4177)\n",
      "test  tensor(1.3922)\n",
      "test  tensor(-0.2262)\n",
      "train  tensor(1.2332, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3726, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1794, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7144, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9429, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1394, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6781, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5020, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5392, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6384, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3656, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6570, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9217, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0642, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5653, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9879, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6404, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8363, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5606, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6621, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6416, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5751, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0750, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8937, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8640, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3703, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0784, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7699, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9284, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7241, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8642, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7581, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2231, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9342, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7238, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0781, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8503, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1358, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5437, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3702, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3878, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2358, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3629, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8932, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   3%|▎         | 3/100 [03:07<1:40:41, 62.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.6686, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2274, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1632, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5318, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8155, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6461, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.3706)\n",
      "test  tensor(1.7409)\n",
      "test  tensor(1.9923)\n",
      "test  tensor(1.5301)\n",
      "test  tensor(1.8415)\n",
      "test  tensor(1.8198)\n",
      "test  tensor(1.4290)\n",
      "test  tensor(1.5571)\n",
      "test  tensor(1.0194)\n",
      "test  tensor(1.9879)\n",
      "test  tensor(1.5226)\n",
      "test  tensor(1.3206)\n",
      "test  tensor(2.0775)\n",
      "test  tensor(1.3836)\n",
      "test  tensor(1.8332)\n",
      "test  tensor(1.5948)\n",
      "test  tensor(2.3184)\n",
      "train  tensor(1.6537, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9589, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5042, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2375, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0391, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5873, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0935, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4470, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2891, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1037, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7545, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2088, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0050, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6822, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7394, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0007, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9098, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1923, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1718, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5903, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1050, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7401, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4054, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1750, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8688, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6301, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9594, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9640, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9746, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7422, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6182, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4054, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6226, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0725, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8364, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9426, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7511, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8786, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8032, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7804, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4453, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4752, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6947, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0381, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4501, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9783, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.7354)\n",
      "test  tensor(1.8867)\n",
      "test  tensor(1.5361)\n",
      "test  tensor(1.3793)\n",
      "test  tensor(1.1581)\n",
      "test  tensor(0.9257)\n",
      "test  tensor(0.6111)\n",
      "test  tensor(2.1981)\n",
      "test  tensor(1.0965)\n",
      "test  tensor(1.2962)\n",
      "test  tensor(1.3187)\n",
      "test  tensor(1.2032)\n",
      "test  tensor(1.4058)\n",
      "test  tensor(1.7194)\n",
      "test  tensor(0.7684)\n",
      "test  tensor(1.4522)\n",
      "test  tensor(2.7081)\n",
      "train  tensor(0.9491, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2817, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5385, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4536, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5448, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3090, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0819, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3669, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9639, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   4%|▍         | 4/100 [04:10<1:40:23, 62.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.8845, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1069, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7134, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9858, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9023, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7783, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0121, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0302, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6350, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1139, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6834, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7804, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5365, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0705, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4345, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1800, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6409, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3562, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3017, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2039, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3291, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7718, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0640, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0429, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1950, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1806, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5019, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7461, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8181, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6902, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9849, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3390, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6116, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1498, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7149, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7424, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9408)\n",
      "test  tensor(1.8657)\n",
      "test  tensor(2.3635)\n",
      "test  tensor(1.8898)\n",
      "test  tensor(1.8746)\n",
      "test  tensor(2.4199)\n",
      "test  tensor(1.9679)\n",
      "test  tensor(2.4341)\n",
      "test  tensor(2.4516)\n",
      "test  tensor(1.3790)\n",
      "test  tensor(1.6756)\n",
      "test  tensor(1.4901)\n",
      "test  tensor(2.7744)\n",
      "test  tensor(2.3644)\n",
      "test  tensor(2.0617)\n",
      "test  tensor(2.1508)\n",
      "test  tensor(0.6748)\n",
      "train  tensor(1.5072, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8378, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1111, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1357, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0674, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6751, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6352, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3767, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0272, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4777, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7672, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7422, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0640, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0905, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8530, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5098, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1343, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4547, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4776, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1853, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8534, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   5%|▌         | 5/100 [05:10<1:37:43, 61.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.0034, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9413, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3160, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7821, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6383, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3521, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7366, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7327, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1170, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7435, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9912, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1718, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9104, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8553, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3846, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5853, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6542, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3444, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2531, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4909, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7140, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1044, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7383, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0727, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9198)\n",
      "test  tensor(2.1126)\n",
      "test  tensor(2.1760)\n",
      "test  tensor(1.9692)\n",
      "test  tensor(1.3569)\n",
      "test  tensor(1.3621)\n",
      "test  tensor(1.9854)\n",
      "test  tensor(2.4981)\n",
      "test  tensor(1.4050)\n",
      "test  tensor(1.7340)\n",
      "test  tensor(2.0526)\n",
      "test  tensor(1.3209)\n",
      "test  tensor(2.4020)\n",
      "test  tensor(1.4180)\n",
      "test  tensor(0.9540)\n",
      "test  tensor(2.0547)\n",
      "test  tensor(2.1413)\n",
      "train  tensor(2.1356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2276, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9872, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6879, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5679, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5416, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7162, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5599, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2213, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0707, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3818, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9410, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6025, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6513, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4043, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5441, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5656, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1725, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7611, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9252, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1164, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9810, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7530, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5805, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7978, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0090, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3550, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4620, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8637, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8013, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5637, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3104, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5228, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5655, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3426, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0728, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   6%|▌         | 6/100 [06:10<1:35:22, 60.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.1063, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6580, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6831, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3403, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3742, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1261, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9628, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0146, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7492, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4238, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5067, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1636)\n",
      "test  tensor(1.7959)\n",
      "test  tensor(2.3946)\n",
      "test  tensor(1.6775)\n",
      "test  tensor(2.2780)\n",
      "test  tensor(2.1607)\n",
      "test  tensor(2.5148)\n",
      "test  tensor(2.0505)\n",
      "test  tensor(2.2397)\n",
      "test  tensor(2.3131)\n",
      "test  tensor(1.8459)\n",
      "test  tensor(2.2354)\n",
      "test  tensor(2.1084)\n",
      "test  tensor(2.0928)\n",
      "test  tensor(2.1749)\n",
      "test  tensor(2.2014)\n",
      "test  tensor(2.1480)\n",
      "train  tensor(1.8027, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5774, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1571, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0920, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6804, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6752, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2556, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3966, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4365, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9188, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2678, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5062, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2522, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6461, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4870, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8621, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7827, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9001, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7504, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5846, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9151, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0675, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6682, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6466, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3009, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9531, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3782, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4840, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3198, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7030, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9475, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5071, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4635, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8911, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4814, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3770, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3044, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6328, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6960, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0018, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5774, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6263, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3319, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4812, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3995, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7199, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7467, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.8721)\n",
      "test  tensor(2.3255)\n",
      "test  tensor(2.1621)\n",
      "test  tensor(1.6959)\n",
      "test  tensor(1.7449)\n",
      "test  tensor(2.1755)\n",
      "test  tensor(2.3559)\n",
      "test  tensor(3.0393)\n",
      "test  tensor(1.9907)\n",
      "test  tensor(1.9357)\n",
      "test  tensor(2.2543)\n",
      "test  tensor(1.8526)\n",
      "test  tensor(1.8517)\n",
      "test  tensor(1.7658)\n",
      "test  tensor(1.9904)\n",
      "test  tensor(2.2376)\n",
      "test  tensor(3.3545)\n",
      "train  tensor(1.6153, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7029, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0179, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3751, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8674, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   7%|▋         | 7/100 [07:20<1:39:26, 64.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.7275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2309, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9346, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8532, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5913, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3770, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8788, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6969, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7491, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3220, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3758, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6532, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6167, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5968, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2041, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5177, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6408, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2958, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1342, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8624, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8918, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4295, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6727, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6241, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5796, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3065, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6362, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0230, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6817, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7395, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8260, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3309, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8999, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2348, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0008, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7072, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7932, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9502, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0969, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3160, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2150)\n",
      "test  tensor(1.7175)\n",
      "test  tensor(1.6858)\n",
      "test  tensor(2.4758)\n",
      "test  tensor(1.7456)\n",
      "test  tensor(2.1622)\n",
      "test  tensor(2.5514)\n",
      "test  tensor(2.1389)\n",
      "test  tensor(1.8903)\n",
      "test  tensor(2.0410)\n",
      "test  tensor(2.1556)\n",
      "test  tensor(1.6192)\n",
      "test  tensor(2.2468)\n",
      "test  tensor(2.0470)\n",
      "test  tensor(1.8500)\n",
      "test  tensor(1.6794)\n",
      "test  tensor(1.5063)\n",
      "train  tensor(1.6593, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3489, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7563, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3954, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8506, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1727, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8783, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4329, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1507, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7991, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6650, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4551, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0044, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4287, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9428, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4987, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2753, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4772, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   8%|▊         | 8/100 [08:19<1:35:49, 62.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.3467, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5013, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2902, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7757, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4245, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.1301, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3590, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5077, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5231, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1405, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4590, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7356, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7525, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8249, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7977, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3746, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4947, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6231, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3556, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4139, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8340, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5777, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0734, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5874, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3623, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4112, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4848, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0991, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3862, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.8437)\n",
      "test  tensor(1.4434)\n",
      "test  tensor(1.9253)\n",
      "test  tensor(1.7466)\n",
      "test  tensor(1.7944)\n",
      "test  tensor(2.3245)\n",
      "test  tensor(2.2165)\n",
      "test  tensor(1.6768)\n",
      "test  tensor(2.3952)\n",
      "test  tensor(2.0434)\n",
      "test  tensor(1.9460)\n",
      "test  tensor(1.8606)\n",
      "test  tensor(1.5295)\n",
      "test  tensor(1.6747)\n",
      "test  tensor(1.3057)\n",
      "test  tensor(2.3436)\n",
      "test  tensor(1.3353)\n",
      "train  tensor(2.3625, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1383, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9057, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7957, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7650, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9676, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8812, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9820, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5103, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1340, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2341, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7930, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0555, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7923, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2470, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9933, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6051, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2831, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1981, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5097, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9392, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0846, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5398, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3544, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7222, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0439, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1544, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5590, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5018, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6858, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   9%|▉         | 9/100 [09:21<1:34:21, 62.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.2802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3366, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1017, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3451, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8120, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6418, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5873, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2685, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6694, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0280, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3910, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2637, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2596, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7426, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0466, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3231)\n",
      "test  tensor(1.4371)\n",
      "test  tensor(2.4871)\n",
      "test  tensor(2.7804)\n",
      "test  tensor(0.7275)\n",
      "test  tensor(1.6461)\n",
      "test  tensor(3.1450)\n",
      "test  tensor(2.2837)\n",
      "test  tensor(3.5272)\n",
      "test  tensor(2.9952)\n",
      "test  tensor(2.2237)\n",
      "test  tensor(2.8342)\n",
      "test  tensor(1.7941)\n",
      "test  tensor(1.7278)\n",
      "test  tensor(1.9254)\n",
      "test  tensor(2.8536)\n",
      "test  tensor(0.5167)\n",
      "train  tensor(1.8409, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1760, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4739, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0680, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3804, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5881, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9476, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2760, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5653, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3956, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8835, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4892, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7811, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4278, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7965, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9861, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6888, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4164, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9918, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9045, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4768, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5697, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0817, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1322, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4140, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6370, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2066, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4603, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6108, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8396, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7958, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6298, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7784, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2291, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0288, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1538, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1315, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7946, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1148, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4993, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8442, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7191, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5395, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5310, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6030, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3748)\n",
      "test  tensor(2.9966)\n",
      "test  tensor(1.8075)\n",
      "test  tensor(1.7431)\n",
      "test  tensor(1.9092)\n",
      "test  tensor(2.2361)\n",
      "test  tensor(2.2353)\n",
      "test  tensor(2.2356)\n",
      "test  tensor(1.6342)\n",
      "test  tensor(2.0035)\n",
      "test  tensor(2.1090)\n",
      "test  tensor(2.1427)\n",
      "test  tensor(2.1557)\n",
      "test  tensor(1.6848)\n",
      "test  tensor(1.4132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  10%|█         | 10/100 [10:26<1:34:32, 63.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.8196)\n",
      "test  tensor(2.1090)\n",
      "train  tensor(2.2569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3521, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5226, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5473, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0196, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6118, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6283, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6902, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1879, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9192, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4760, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8532, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7014, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4360, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3739, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4711, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8969, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2579, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6478, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2131, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1132, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0734, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1352, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6547, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0761, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6030, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6567, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6113, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8375, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4959, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2494, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5661, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5312, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4629, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0317, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7434, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4505, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7438, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9713, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9541)\n",
      "test  tensor(1.7743)\n",
      "test  tensor(1.5961)\n",
      "test  tensor(1.4205)\n",
      "test  tensor(1.3955)\n",
      "test  tensor(2.0187)\n",
      "test  tensor(2.8414)\n",
      "test  tensor(1.6532)\n",
      "test  tensor(1.1323)\n",
      "test  tensor(0.6503)\n",
      "test  tensor(1.5056)\n",
      "test  tensor(1.8443)\n",
      "test  tensor(1.6339)\n",
      "test  tensor(2.2518)\n",
      "test  tensor(1.6080)\n",
      "test  tensor(1.2813)\n",
      "test  tensor(2.8155)\n",
      "train  tensor(2.0469, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8795, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0478, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9847, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4770, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7067, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2803, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6170, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6565, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8963, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1541, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4519, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9629, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2162, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  11%|█         | 11/100 [11:29<1:33:21, 62.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.6265, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4373, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6348, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9855, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5956, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3475, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5363, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6579, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9639, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5754, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4156, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6150, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9062, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9532, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1202, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2740, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1280, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6317, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7024, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9005, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0712, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5121, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4850, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0660, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7864, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7587, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2858, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5400, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6024, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5469, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8693, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5821, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.7071)\n",
      "test  tensor(0.6859)\n",
      "test  tensor(1.2924)\n",
      "test  tensor(0.7204)\n",
      "test  tensor(1.8487)\n",
      "test  tensor(1.6212)\n",
      "test  tensor(2.0020)\n",
      "test  tensor(1.4287)\n",
      "test  tensor(2.8385)\n",
      "test  tensor(1.4858)\n",
      "test  tensor(1.7066)\n",
      "test  tensor(2.0806)\n",
      "test  tensor(2.0561)\n",
      "test  tensor(1.3147)\n",
      "test  tensor(1.3767)\n",
      "test  tensor(1.3018)\n",
      "test  tensor(0.3687)\n",
      "train  tensor(1.2803, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2718, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3486, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4059, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3267, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5331, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7630, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3850, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5613, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0240, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3157, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7603, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1160, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8437, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7709, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8545, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7447, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9376, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6726, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3814, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3186, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5948, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0665, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0500, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4299, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9908, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1208, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  12%|█▏        | 12/100 [12:35<1:33:58, 64.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(7.4854, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5319, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8841, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4658, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8273, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9230, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8132, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9762, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8989, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7860, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0460, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4152, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8906, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5034, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9188, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0551, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9342, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0310, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0707, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4673, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0681, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.4107)\n",
      "test  tensor(2.1202)\n",
      "test  tensor(2.6049)\n",
      "test  tensor(2.5798)\n",
      "test  tensor(1.5274)\n",
      "test  tensor(2.4035)\n",
      "test  tensor(2.4114)\n",
      "test  tensor(3.7866)\n",
      "test  tensor(1.6857)\n",
      "test  tensor(2.7738)\n",
      "test  tensor(2.8675)\n",
      "test  tensor(1.8516)\n",
      "test  tensor(2.4158)\n",
      "test  tensor(1.4208)\n",
      "test  tensor(2.1451)\n",
      "test  tensor(1.9496)\n",
      "test  tensor(-0.1276)\n",
      "train  tensor(2.2252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0499, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1451, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6251, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6670, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4941, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0975, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9050, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4012, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2914, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2829, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7856, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0229, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0691, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4686, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4710, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8930, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4236, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7200, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0567, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0636, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8382, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5699, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8991, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5514, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8418, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9662, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9183, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0071, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4552, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0741, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8105, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9213, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9323, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3657, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1214, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5298, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8147, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4675, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3348, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0149, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9943, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  13%|█▎        | 13/100 [13:42<1:34:00, 64.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.3380, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8149, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2661, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4218, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.1612, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3124)\n",
      "test  tensor(2.0655)\n",
      "test  tensor(1.2865)\n",
      "test  tensor(1.5964)\n",
      "test  tensor(1.9696)\n",
      "test  tensor(2.0911)\n",
      "test  tensor(3.0621)\n",
      "test  tensor(1.6721)\n",
      "test  tensor(1.8006)\n",
      "test  tensor(1.9144)\n",
      "test  tensor(2.2739)\n",
      "test  tensor(2.8318)\n",
      "test  tensor(1.7492)\n",
      "test  tensor(2.2876)\n",
      "test  tensor(1.6443)\n",
      "test  tensor(2.3716)\n",
      "test  tensor(1.5146)\n",
      "train  tensor(1.5734, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1929, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7863, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7265, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8035, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3921, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8034, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8888, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4444, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8107, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8353, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2940, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2589, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4389, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2495, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0225, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6392, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6044, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9782, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6116, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6140, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2044, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3719, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5372, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2242, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5862, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1891, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9821, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6403, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9127, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5574, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2424, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0935, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0350, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9770, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2656, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3646, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0274, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4296, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2627, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4833, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2685, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1094, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0776, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5843, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2188, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4094)\n",
      "test  tensor(1.8822)\n",
      "test  tensor(1.1511)\n",
      "test  tensor(2.6572)\n",
      "test  tensor(3.2933)\n",
      "test  tensor(1.8488)\n",
      "test  tensor(1.7118)\n",
      "test  tensor(2.0970)\n",
      "test  tensor(2.4015)\n",
      "test  tensor(1.8754)\n",
      "test  tensor(1.6017)\n",
      "test  tensor(2.1894)\n",
      "test  tensor(2.0508)\n",
      "test  tensor(1.4475)\n",
      "test  tensor(2.1519)\n",
      "test  tensor(2.1205)\n",
      "test  tensor(0.9224)\n",
      "train  tensor(1.0125, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4038, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0936, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4483, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4604, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3223, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8386, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5478, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  14%|█▍        | 14/100 [14:54<1:36:03, 67.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.3822, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6120, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6385, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6763, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4664, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1238, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6142, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9549, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0686, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1651, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9724, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5680, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7343, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6904, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2995, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1925, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5740, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4138, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6323, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4454, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0786, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5213, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6648, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5059, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9364, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6756, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0436, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6056, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5234, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7264, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0751, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2786, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0415, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0049, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5598, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1369, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1670)\n",
      "test  tensor(2.5936)\n",
      "test  tensor(2.2005)\n",
      "test  tensor(3.9099)\n",
      "test  tensor(3.0004)\n",
      "test  tensor(1.8022)\n",
      "test  tensor(2.4300)\n",
      "test  tensor(2.3494)\n",
      "test  tensor(2.2687)\n",
      "test  tensor(2.3821)\n",
      "test  tensor(3.4704)\n",
      "test  tensor(2.5448)\n",
      "test  tensor(2.5363)\n",
      "test  tensor(2.9850)\n",
      "test  tensor(2.6766)\n",
      "test  tensor(1.7514)\n",
      "test  tensor(0.9754)\n",
      "train  tensor(2.1529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2870, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7292, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4243, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7804, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3318, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8469, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5739, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2344, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5151, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9738, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4208, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7065, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1489, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3181, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2458, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0595, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0798, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3065, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2333, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1820, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9518, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0140, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5777, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  15%|█▌        | 15/100 [16:00<1:34:22, 66.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.0695, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6570, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6693, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2231, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7333, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1386, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0342, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0546, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3406, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2018, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3853, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9296, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6941, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6154, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5166, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8483, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8646, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2251, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4026, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4007, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5479, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8573, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.0859)\n",
      "test  tensor(1.9385)\n",
      "test  tensor(2.3612)\n",
      "test  tensor(2.3151)\n",
      "test  tensor(2.2796)\n",
      "test  tensor(2.6895)\n",
      "test  tensor(2.5375)\n",
      "test  tensor(1.9882)\n",
      "test  tensor(1.8771)\n",
      "test  tensor(2.4273)\n",
      "test  tensor(2.3526)\n",
      "test  tensor(1.8449)\n",
      "test  tensor(2.4184)\n",
      "test  tensor(1.9006)\n",
      "test  tensor(2.4468)\n",
      "test  tensor(1.8296)\n",
      "test  tensor(4.7541)\n",
      "train  tensor(1.2294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1613, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3999, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7380, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6015, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2022, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6821, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4135, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5293, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5196, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5555, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6606, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1507, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1921, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3465, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0591, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3711, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8472, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5423, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0399, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5599, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1418, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4331, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1466, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7497, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6039, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1601, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3938, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5891, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5109, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9293, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5846, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2784, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.7426, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8788, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4263, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  16%|█▌        | 16/100 [17:08<1:34:07, 67.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8807, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8622, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5852, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5632, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3912, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6500, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6668, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8702, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7642, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.8992)\n",
      "test  tensor(0.9168)\n",
      "test  tensor(0.9696)\n",
      "test  tensor(0.8158)\n",
      "test  tensor(0.7328)\n",
      "test  tensor(0.6894)\n",
      "test  tensor(0.6440)\n",
      "test  tensor(0.8309)\n",
      "test  tensor(0.5916)\n",
      "test  tensor(1.0024)\n",
      "test  tensor(1.5806)\n",
      "test  tensor(1.0252)\n",
      "test  tensor(0.7561)\n",
      "test  tensor(0.5708)\n",
      "test  tensor(0.6803)\n",
      "test  tensor(2.1142)\n",
      "test  tensor(0.0902)\n",
      "train  tensor(0.6441, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1243, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3876, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.6782, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.2378, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2811, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6444, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2743, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1694, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7314, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8718, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1193, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4006, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1023, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8484, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1977, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1783, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3443, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3947, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6504, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0641, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7385, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9106, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6205, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4872, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7450, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4854, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9218, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1366, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6559, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4958, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2926, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2014, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9642, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9479, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0288, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1208, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2117, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4778, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3371, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8088, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8327, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7946)\n",
      "test  tensor(2.1663)\n",
      "test  tensor(2.6893)\n",
      "test  tensor(2.1836)\n",
      "test  tensor(1.7625)\n",
      "test  tensor(2.5932)\n",
      "test  tensor(2.6073)\n",
      "test  tensor(2.6759)\n",
      "test  tensor(2.1307)\n",
      "test  tensor(2.6798)\n",
      "test  tensor(2.8415)\n",
      "test  tensor(3.3818)\n",
      "test  tensor(2.3886)\n",
      "test  tensor(3.8058)\n",
      "test  tensor(2.0093)\n",
      "test  tensor(2.7879)\n",
      "test  tensor(0.9965)\n",
      "train  tensor(3.3126, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6861, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9234, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6981, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6553, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  17%|█▋        | 17/100 [18:18<1:34:10, 68.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.8885, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2168, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9267, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8786, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3577, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3170, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9292, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5644, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5609, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7457, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1328, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6069, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4776, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9932, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8406, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7597, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0949, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3368, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4310, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4742, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2409, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9132, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8028, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0763, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9939, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2249, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6530, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2153, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7122, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6069, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8014, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6075, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5741, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3983, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7050, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7043, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7679, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8949, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1147, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0861, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3085, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3919, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.3342)\n",
      "test  tensor(3.5414)\n",
      "test  tensor(2.2065)\n",
      "test  tensor(2.6756)\n",
      "test  tensor(2.3494)\n",
      "test  tensor(2.5984)\n",
      "test  tensor(2.3204)\n",
      "test  tensor(2.7043)\n",
      "test  tensor(2.6803)\n",
      "test  tensor(3.2176)\n",
      "test  tensor(2.2692)\n",
      "test  tensor(1.9598)\n",
      "test  tensor(2.4412)\n",
      "test  tensor(2.3038)\n",
      "test  tensor(2.0049)\n",
      "test  tensor(3.0694)\n",
      "test  tensor(3.8248)\n",
      "train  tensor(2.0390, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2805, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3851, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4803, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8025, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3164, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6299, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5230, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0645, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3904, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9801, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4905, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0993, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5242, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8553, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6465, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6414, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6887, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  18%|█▊        | 18/100 [19:24<1:32:02, 67.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.4147, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5795, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0986, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2345, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8720, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8621, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5744, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6765, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0786, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4535, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6467, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4736, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0112, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0540, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7979, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0750, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8339, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3486, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6042, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2275, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2423, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3592, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9838, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0524, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2588, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8273, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.5693)\n",
      "test  tensor(2.2414)\n",
      "test  tensor(1.5163)\n",
      "test  tensor(2.4001)\n",
      "test  tensor(2.7877)\n",
      "test  tensor(1.9341)\n",
      "test  tensor(2.0277)\n",
      "test  tensor(2.0750)\n",
      "test  tensor(2.8141)\n",
      "test  tensor(2.8804)\n",
      "test  tensor(2.5948)\n",
      "test  tensor(3.2236)\n",
      "test  tensor(2.6709)\n",
      "test  tensor(2.9750)\n",
      "test  tensor(2.1237)\n",
      "test  tensor(3.4768)\n",
      "test  tensor(0.8141)\n",
      "train  tensor(2.9420, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4974, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1937, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2398, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8320, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0839, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1654, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6234, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1959, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1189, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9491, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5432, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4836, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6045, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8186, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6081, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7091, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7056, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6566, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3425, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0023, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5898, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1247, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5803, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5550, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2539, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6091, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8209, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2135, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  19%|█▉        | 19/100 [20:27<1:29:09, 66.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.5072, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6502, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8495, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5351, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8567, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7335, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3714, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7103, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5717, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5610, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5282, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3860, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4582, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6396, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8455, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5214, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.7832)\n",
      "test  tensor(1.5397)\n",
      "test  tensor(1.2547)\n",
      "test  tensor(1.2280)\n",
      "test  tensor(1.3249)\n",
      "test  tensor(1.2277)\n",
      "test  tensor(2.1366)\n",
      "test  tensor(2.2564)\n",
      "test  tensor(1.2627)\n",
      "test  tensor(1.7836)\n",
      "test  tensor(1.4171)\n",
      "test  tensor(2.2622)\n",
      "test  tensor(1.2213)\n",
      "test  tensor(1.7992)\n",
      "test  tensor(1.8573)\n",
      "test  tensor(2.1158)\n",
      "test  tensor(3.3957)\n",
      "train  tensor(2.6169, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0965, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8693, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9792, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6673, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1932, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8402, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9004, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7207, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7176, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0350, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3740, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7962, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3967, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4701, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2639, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0744, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3310, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2718, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1326, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2476, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1145, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2982, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5375, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5929, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7151, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4639, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6587, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9255, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3549, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1697, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2567, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7746, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7601, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6639, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0790, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2049, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4114, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7003, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4508, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1132, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3227, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5970, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1028)\n",
      "test  tensor(2.8510)\n",
      "test  tensor(2.1837)\n",
      "test  tensor(2.3111)\n",
      "test  tensor(2.3917)\n",
      "test  tensor(1.9419)\n",
      "test  tensor(3.0760)\n",
      "test  tensor(2.7383)\n",
      "test  tensor(1.9274)\n",
      "test  tensor(2.8338)\n",
      "test  tensor(2.4442)\n",
      "test  tensor(2.7720)\n",
      "test  tensor(2.7868)\n",
      "test  tensor(2.6434)\n",
      "test  tensor(2.7281)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  20%|██        | 20/100 [21:40<1:30:45, 68.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.7863)\n",
      "test  tensor(0.8072)\n",
      "train  tensor(2.4053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5579, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9143, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9282, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7257, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2291, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2379, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7991, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4842, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6162, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4946, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5465, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6525, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2205, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2695, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0006, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6198, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6778, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8356, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6981, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0109, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7568, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5416, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6818, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4946, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0433, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8813, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9823, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6121, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8317, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3145, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3712, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9525, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7711, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3474, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2266, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2602, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1862, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8394, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7534, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5187, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1411, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5447, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6574, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1609, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9851)\n",
      "test  tensor(2.2124)\n",
      "test  tensor(1.6806)\n",
      "test  tensor(2.0103)\n",
      "test  tensor(1.2390)\n",
      "test  tensor(2.0719)\n",
      "test  tensor(2.3403)\n",
      "test  tensor(2.2097)\n",
      "test  tensor(1.8446)\n",
      "test  tensor(2.3456)\n",
      "test  tensor(1.9063)\n",
      "test  tensor(1.6601)\n",
      "test  tensor(1.3017)\n",
      "test  tensor(1.9433)\n",
      "test  tensor(2.3941)\n",
      "test  tensor(1.4745)\n",
      "test  tensor(0.4667)\n",
      "train  tensor(2.4552, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6189, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3845, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2836, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5196, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3410, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7360, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4847, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5163, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9272, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3061, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5856, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4845, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7566, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  21%|██        | 21/100 [22:47<1:29:21, 67.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.4524, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7799, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3873, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1734, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0921, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8916, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3906, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0309, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6471, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2964, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8406, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9213, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6378, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0928, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0787, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2110, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1951, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2066, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4442, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3897, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0025, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8251, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2957, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6527, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8111, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2411, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0742, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0447, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7600, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7236, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4240, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6187, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2313, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9945, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5502, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3423)\n",
      "test  tensor(1.7439)\n",
      "test  tensor(1.9663)\n",
      "test  tensor(1.9532)\n",
      "test  tensor(2.3260)\n",
      "test  tensor(0.9184)\n",
      "test  tensor(0.8610)\n",
      "test  tensor(2.0341)\n",
      "test  tensor(1.5024)\n",
      "test  tensor(1.4774)\n",
      "test  tensor(1.6240)\n",
      "test  tensor(2.4162)\n",
      "test  tensor(1.6233)\n",
      "test  tensor(1.8252)\n",
      "test  tensor(1.8405)\n",
      "test  tensor(2.5669)\n",
      "test  tensor(0.2275)\n",
      "train  tensor(1.0665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0503, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2832, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1272, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4938, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3047, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3395, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9425, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6044, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5694, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3341, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0284, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2813, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3237, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4147, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0658, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1360, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1310, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9803, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5116, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9730, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4202, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2261, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8895, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8535, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  22%|██▏       | 22/100 [23:50<1:26:22, 66.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8437, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4137, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9941, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5251, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4991, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3402, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0128, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2480, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1092, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2308, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0094, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4175, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1054, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1990, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1811, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1855, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0049, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6442, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6668, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0746, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.5404)\n",
      "test  tensor(2.0727)\n",
      "test  tensor(2.7789)\n",
      "test  tensor(2.4900)\n",
      "test  tensor(3.0645)\n",
      "test  tensor(1.9096)\n",
      "test  tensor(1.9188)\n",
      "test  tensor(2.1903)\n",
      "test  tensor(2.9964)\n",
      "test  tensor(2.1052)\n",
      "test  tensor(2.1322)\n",
      "test  tensor(1.9897)\n",
      "test  tensor(1.6864)\n",
      "test  tensor(1.3182)\n",
      "test  tensor(2.9388)\n",
      "test  tensor(1.9186)\n",
      "test  tensor(3.0142)\n",
      "train  tensor(3.5031, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0958, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7286, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6733, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1528, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7499, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9066, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7745, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3273, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9372, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1135, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4335, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1912, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6867, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7239, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3766, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5726, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4414, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7766, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1399, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9659, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1861, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6936, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7828, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9688, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5854, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8899, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3394, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8539, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4716, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6031, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5123, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3844, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6200, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1908, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0459, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5108, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  23%|██▎       | 23/100 [24:54<1:24:15, 65.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.0126, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5082, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4254, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7188, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2088, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1908)\n",
      "test  tensor(2.2740)\n",
      "test  tensor(3.2930)\n",
      "test  tensor(3.1262)\n",
      "test  tensor(2.2317)\n",
      "test  tensor(1.9671)\n",
      "test  tensor(2.0362)\n",
      "test  tensor(3.6375)\n",
      "test  tensor(2.0586)\n",
      "test  tensor(2.8396)\n",
      "test  tensor(2.4976)\n",
      "test  tensor(3.5462)\n",
      "test  tensor(3.2623)\n",
      "test  tensor(2.2307)\n",
      "test  tensor(2.0597)\n",
      "test  tensor(2.3896)\n",
      "test  tensor(19.8389)\n",
      "train  tensor(3.2682, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5685, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6311, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6261, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4618, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7742, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9980, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8481, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4698, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3257, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9641, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8091, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3562, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0989, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6690, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0765, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0611, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0068, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8228, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7251, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4610, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9074, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5536, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2939, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1768, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6002, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0561, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6685, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0969, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5215, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3354, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3792, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1505, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6057, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2740, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4091, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1855, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1542, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7688, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3160, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2450, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8329, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7709)\n",
      "test  tensor(2.0574)\n",
      "test  tensor(2.9419)\n",
      "test  tensor(2.7791)\n",
      "test  tensor(2.7394)\n",
      "test  tensor(3.0812)\n",
      "test  tensor(3.4793)\n",
      "test  tensor(2.4809)\n",
      "test  tensor(2.3363)\n",
      "test  tensor(3.8004)\n",
      "test  tensor(1.5170)\n",
      "test  tensor(2.9719)\n",
      "test  tensor(2.8746)\n",
      "test  tensor(2.7588)\n",
      "test  tensor(2.3681)\n",
      "test  tensor(2.4630)\n",
      "test  tensor(3.9344)\n",
      "train  tensor(1.7113, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9870, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6947, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0543, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2188, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2575, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3841, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2755, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  24%|██▍       | 24/100 [26:03<1:24:21, 66.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.3121, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6549, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1638, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1139, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0048, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0748, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0002, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0673, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9182, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6355, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6032, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5781, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0028, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1113, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4577, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1323, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3175, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6045, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7584, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5631, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4881, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1730, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7104, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5914, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0696, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9895, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0004, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5602, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6631, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3133, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2574, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9374, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9298, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0827, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6374, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8586, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2575, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4090, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8596, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.8434)\n",
      "test  tensor(1.5523)\n",
      "test  tensor(1.6457)\n",
      "test  tensor(2.3375)\n",
      "test  tensor(3.5710)\n",
      "test  tensor(2.1680)\n",
      "test  tensor(2.6956)\n",
      "test  tensor(1.9935)\n",
      "test  tensor(2.8941)\n",
      "test  tensor(2.3814)\n",
      "test  tensor(1.7085)\n",
      "test  tensor(2.7110)\n",
      "test  tensor(2.7552)\n",
      "test  tensor(2.0815)\n",
      "test  tensor(2.4669)\n",
      "test  tensor(1.8860)\n",
      "test  tensor(6.4456)\n",
      "train  tensor(2.5284, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7971, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2128, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4827, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8825, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4973, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7018, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9220, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3751, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0226, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7977, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5622, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0913, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5565, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6667, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4700, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9576, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9815, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8328, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6411, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5727, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1044, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5117, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5139, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  25%|██▌       | 25/100 [27:06<1:22:07, 65.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.5563, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0115, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7292, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4202, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9352, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0437, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4898, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5067, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7413, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8649, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5323, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8252, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2730, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1074, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0521, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1576, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9127, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9414, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4126, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5581, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1740, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1562, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8270, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.6899)\n",
      "test  tensor(2.4453)\n",
      "test  tensor(3.1721)\n",
      "test  tensor(3.3857)\n",
      "test  tensor(2.7467)\n",
      "test  tensor(2.9622)\n",
      "test  tensor(2.5788)\n",
      "test  tensor(3.0105)\n",
      "test  tensor(2.3229)\n",
      "test  tensor(2.0939)\n",
      "test  tensor(2.1037)\n",
      "test  tensor(2.7094)\n",
      "test  tensor(2.0762)\n",
      "test  tensor(1.6114)\n",
      "test  tensor(2.2076)\n",
      "test  tensor(2.8037)\n",
      "test  tensor(5.0064)\n",
      "train  tensor(2.4087, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0329, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5960, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6885, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4668, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9536, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8698, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3325, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5631, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3712, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4753, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5826, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9616, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3623, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9926, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1559, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4416, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8183, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1165, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1267, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1886, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1486, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9351, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4199, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8576, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9525, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8069, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7563, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8659, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3672, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8107, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8260, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4547, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  26%|██▌       | 26/100 [28:17<1:22:57, 67.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.6156, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2546, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5978, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1527, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1109, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7725, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6253, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6197, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2307)\n",
      "test  tensor(2.1628)\n",
      "test  tensor(2.4456)\n",
      "test  tensor(2.0776)\n",
      "test  tensor(0.9776)\n",
      "test  tensor(2.2029)\n",
      "test  tensor(2.7223)\n",
      "test  tensor(3.0635)\n",
      "test  tensor(2.2474)\n",
      "test  tensor(2.3258)\n",
      "test  tensor(1.1051)\n",
      "test  tensor(1.5717)\n",
      "test  tensor(2.6281)\n",
      "test  tensor(1.5941)\n",
      "test  tensor(3.1230)\n",
      "test  tensor(3.7228)\n",
      "test  tensor(0.3007)\n",
      "train  tensor(1.8142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6875, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4535, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9982, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5324, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9502, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4086, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3539, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7822, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3549, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1481, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7542, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2460, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9652, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9478, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5412, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2254, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9340, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8887, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1930, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1878, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9343, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0158, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5793, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2846, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7929, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1783, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1497, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3320, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9136, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9299, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6381, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2010, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8360, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6554, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1483, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1725, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1419, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6581, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2962, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9499, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2643)\n",
      "test  tensor(3.6150)\n",
      "test  tensor(2.5213)\n",
      "test  tensor(1.4770)\n",
      "test  tensor(1.9516)\n",
      "test  tensor(3.1150)\n",
      "test  tensor(3.0424)\n",
      "test  tensor(2.7750)\n",
      "test  tensor(2.5905)\n",
      "test  tensor(2.2588)\n",
      "test  tensor(2.6018)\n",
      "test  tensor(1.9142)\n",
      "test  tensor(2.3285)\n",
      "test  tensor(2.5717)\n",
      "test  tensor(2.0598)\n",
      "test  tensor(1.9499)\n",
      "test  tensor(4.7857)\n",
      "train  tensor(2.7480, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4626, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2779, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4183, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  27%|██▋       | 27/100 [29:28<1:23:08, 68.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.4228, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3204, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6545, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4964, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7369, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2537, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1856, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6405, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2448, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4616, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4326, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0168, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2744, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4230, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3973, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0169, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7772, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0816, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8453, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9394, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1839, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6975, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6167, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0151, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0922, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8808, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2062, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8948, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8543, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3312, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1291, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9097, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0033, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6110, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3140, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0259, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4931, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0684, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9866, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4838)\n",
      "test  tensor(1.7299)\n",
      "test  tensor(2.0507)\n",
      "test  tensor(1.9760)\n",
      "test  tensor(2.7975)\n",
      "test  tensor(2.7577)\n",
      "test  tensor(2.5548)\n",
      "test  tensor(3.7688)\n",
      "test  tensor(2.3792)\n",
      "test  tensor(2.6587)\n",
      "test  tensor(2.5916)\n",
      "test  tensor(2.6987)\n",
      "test  tensor(2.1264)\n",
      "test  tensor(1.9772)\n",
      "test  tensor(2.3054)\n",
      "test  tensor(2.4733)\n",
      "test  tensor(1.8435)\n",
      "train  tensor(3.1129, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6711, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3555, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8372, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4989, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5068, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6396, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8319, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7748, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4136, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1402, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5152, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5772, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  28%|██▊       | 28/100 [30:32<1:20:29, 67.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.8750, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0120, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5620, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1338, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5386, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3217, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2864, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2320, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5045, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3085, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3791, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1811, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5379, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8224, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0639, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4884, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2575, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3717, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4338, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4442, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8798, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1682, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2755, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5105, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8624, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2108, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3919, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2371)\n",
      "test  tensor(3.4038)\n",
      "test  tensor(2.3493)\n",
      "test  tensor(2.9370)\n",
      "test  tensor(2.2051)\n",
      "test  tensor(2.5196)\n",
      "test  tensor(2.8148)\n",
      "test  tensor(2.3868)\n",
      "test  tensor(2.1008)\n",
      "test  tensor(4.3827)\n",
      "test  tensor(3.2333)\n",
      "test  tensor(2.4027)\n",
      "test  tensor(2.3002)\n",
      "test  tensor(2.7724)\n",
      "test  tensor(3.7613)\n",
      "test  tensor(2.8737)\n",
      "test  tensor(2.0896)\n",
      "train  tensor(2.7877, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5817, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7888, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8272, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1311, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1632, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8528, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5705, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6429, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8204, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8715, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5168, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0266, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4203, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9833, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6289, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3414, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6157, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2463, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9255, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8288, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4461, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2080, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0714, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2765, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5651, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5266, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3272, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6883, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2043, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2516, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3162, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  29%|██▉       | 29/100 [31:38<1:18:43, 66.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.3724, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0445, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1667, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4237, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6720, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3024, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0466, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4577, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6596, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8591, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2332, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7055, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4549, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2101, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3430, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.6138)\n",
      "test  tensor(2.6383)\n",
      "test  tensor(1.2441)\n",
      "test  tensor(2.4215)\n",
      "test  tensor(1.3739)\n",
      "test  tensor(2.1882)\n",
      "test  tensor(2.0692)\n",
      "test  tensor(1.9492)\n",
      "test  tensor(2.6228)\n",
      "test  tensor(2.9913)\n",
      "test  tensor(3.1115)\n",
      "test  tensor(2.5546)\n",
      "test  tensor(2.3179)\n",
      "test  tensor(1.7750)\n",
      "test  tensor(2.8090)\n",
      "test  tensor(2.3288)\n",
      "test  tensor(-0.2044)\n",
      "train  tensor(1.9801, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8419, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5798, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5525, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7571, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2995, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5001, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5938, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2727, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8865, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0717, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2505, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6664, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3304, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8599, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6659, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0235, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2431, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0179, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3055, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8356, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4393, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4061, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8042, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7360, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3283, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1620, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3744, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9373, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5409, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5826, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6700, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8790, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0152, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9894, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7926, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1666, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2957, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3792, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9409, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5113, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0030, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3535)\n",
      "test  tensor(3.6689)\n",
      "test  tensor(3.4291)\n",
      "test  tensor(3.3293)\n",
      "test  tensor(2.1171)\n",
      "test  tensor(2.9067)\n",
      "test  tensor(2.6346)\n",
      "test  tensor(2.8354)\n",
      "test  tensor(2.1732)\n",
      "test  tensor(2.7366)\n",
      "test  tensor(2.7193)\n",
      "test  tensor(2.2488)\n",
      "test  tensor(2.4028)\n",
      "test  tensor(2.1814)\n",
      "test  tensor(2.6759)\n",
      "test  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  30%|███       | 30/100 [32:44<1:17:37, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2669)\n",
      "test  tensor(4.5238)\n",
      "train  tensor(1.7092, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3917, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0194, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4876, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9201, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2804, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3231, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3048, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0039, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3686, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1692, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2046, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7899, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7459, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7130, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7407, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9611, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9272, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4796, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3458, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3186, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0219, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5553, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9726, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2980, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8871, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4526, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1643, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6015, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3585, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8724, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5847, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1827, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8428, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2118, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1343, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9904, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2611, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6785, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3455, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8120, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5904, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1203, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.6219)\n",
      "test  tensor(2.0400)\n",
      "test  tensor(1.8319)\n",
      "test  tensor(2.5905)\n",
      "test  tensor(2.7916)\n",
      "test  tensor(2.8798)\n",
      "test  tensor(2.3739)\n",
      "test  tensor(1.9603)\n",
      "test  tensor(2.1132)\n",
      "test  tensor(3.1427)\n",
      "test  tensor(1.5805)\n",
      "test  tensor(2.4356)\n",
      "test  tensor(2.3319)\n",
      "test  tensor(2.0890)\n",
      "test  tensor(2.7078)\n",
      "test  tensor(1.9822)\n",
      "test  tensor(1.3182)\n",
      "train  tensor(1.6523, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9827, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5242, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2525, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3889, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1449, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7155, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5767, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6295, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8967, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6985, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8142, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  31%|███       | 31/100 [33:47<1:15:12, 65.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.5388, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7885, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7079, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1413, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2562, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8299, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3464, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4879, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2247, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3744, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4414, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9228, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9102, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0904, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5515, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0365, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2039, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4513, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1568, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3535, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8274, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5550, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4512, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9539, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8265, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6068, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2568, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6670, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7793)\n",
      "test  tensor(2.8746)\n",
      "test  tensor(2.7292)\n",
      "test  tensor(2.1685)\n",
      "test  tensor(4.0420)\n",
      "test  tensor(2.3799)\n",
      "test  tensor(4.2163)\n",
      "test  tensor(2.7593)\n",
      "test  tensor(3.4326)\n",
      "test  tensor(2.0057)\n",
      "test  tensor(2.8435)\n",
      "test  tensor(2.8700)\n",
      "test  tensor(3.5890)\n",
      "test  tensor(2.0132)\n",
      "test  tensor(3.0696)\n",
      "test  tensor(2.3478)\n",
      "test  tensor(0.6762)\n",
      "train  tensor(3.8951, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2416, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3590, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4950, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4900, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4200, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7264, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9050, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7791, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4381, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8821, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5308, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6792, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8094, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7009, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2705, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1735, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3436, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6371, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6967, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2460, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4825, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7959, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8163, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3188, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  32%|███▏      | 32/100 [34:49<1:13:00, 64.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.7900, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5939, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6005, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5338, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5029, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6591, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2059, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6888, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3959, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2771, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5408, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4960, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5972, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7495, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1772, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6511, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6499, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6078, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9525, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.3902)\n",
      "test  tensor(1.2360)\n",
      "test  tensor(2.6182)\n",
      "test  tensor(2.6282)\n",
      "test  tensor(2.4493)\n",
      "test  tensor(3.0319)\n",
      "test  tensor(2.7027)\n",
      "test  tensor(2.8077)\n",
      "test  tensor(2.0914)\n",
      "test  tensor(3.1388)\n",
      "test  tensor(2.9299)\n",
      "test  tensor(2.4200)\n",
      "test  tensor(2.5422)\n",
      "test  tensor(3.1599)\n",
      "test  tensor(2.6292)\n",
      "test  tensor(2.5459)\n",
      "test  tensor(5.9304)\n",
      "train  tensor(1.9063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0914, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4525, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1608, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3763, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8464, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4409, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2901, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7857, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3558, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1056, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0884, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1920, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5833, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6147, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1979, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9769, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6199, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4960, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2076, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8934, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1193, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7017, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4808, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9309, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0467, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6519, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3043, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9285, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5548, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6393, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2082, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3709, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7260, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9766, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8356, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  33%|███▎      | 33/100 [35:51<1:11:12, 63.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.7941, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1641, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6044, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0924, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4447, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7138, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7855)\n",
      "test  tensor(4.1304)\n",
      "test  tensor(2.2444)\n",
      "test  tensor(3.2427)\n",
      "test  tensor(2.4524)\n",
      "test  tensor(3.4174)\n",
      "test  tensor(3.2881)\n",
      "test  tensor(2.4510)\n",
      "test  tensor(1.4848)\n",
      "test  tensor(3.0361)\n",
      "test  tensor(2.9259)\n",
      "test  tensor(2.6783)\n",
      "test  tensor(3.3064)\n",
      "test  tensor(2.5769)\n",
      "test  tensor(1.6221)\n",
      "test  tensor(3.0233)\n",
      "test  tensor(6.3706)\n",
      "train  tensor(1.3563, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9638, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1902, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0183, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0876, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1533, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4674, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8629, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0501, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7123, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8136, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2497, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1991, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2731, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8734, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4392, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2748, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6895, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3002, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7093, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9058, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2183, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0632, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4997, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6492, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6065, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6612, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2149, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1494, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6273, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8899, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9459, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7292, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8129, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8318, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4027, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6823, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8373, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6593, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0798, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5587, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9419, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.7072)\n",
      "test  tensor(1.7076)\n",
      "test  tensor(1.4110)\n",
      "test  tensor(2.9219)\n",
      "test  tensor(2.1317)\n",
      "test  tensor(2.0202)\n",
      "test  tensor(1.3134)\n",
      "test  tensor(3.4455)\n",
      "test  tensor(2.3497)\n",
      "test  tensor(1.4942)\n",
      "test  tensor(2.2324)\n",
      "test  tensor(1.2743)\n",
      "test  tensor(2.4608)\n",
      "test  tensor(2.4971)\n",
      "test  tensor(2.1778)\n",
      "test  tensor(1.6227)\n",
      "test  tensor(4.0763)\n",
      "train  tensor(2.0713, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1793, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4287, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0873, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1957, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2349, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3545, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6704, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  34%|███▍      | 34/100 [37:00<1:11:41, 65.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.9906, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6095, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1457, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8004, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2422, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3669, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6124, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2241, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3461, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9299, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4378, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9022, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0575, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6865, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7750, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3432, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2927, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5120, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2023, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9346, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6452, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0611, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1878, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5253, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6235, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0800, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5402, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8488, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7303, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9614, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1069, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3624, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4042, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6091, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.7877)\n",
      "test  tensor(1.2908)\n",
      "test  tensor(2.0525)\n",
      "test  tensor(2.7365)\n",
      "test  tensor(1.3134)\n",
      "test  tensor(1.9165)\n",
      "test  tensor(1.2472)\n",
      "test  tensor(2.1715)\n",
      "test  tensor(1.0417)\n",
      "test  tensor(2.4835)\n",
      "test  tensor(2.2312)\n",
      "test  tensor(0.9908)\n",
      "test  tensor(1.6742)\n",
      "test  tensor(1.7549)\n",
      "test  tensor(3.0302)\n",
      "test  tensor(2.9654)\n",
      "test  tensor(3.8300)\n",
      "train  tensor(1.3054, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3304, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1825, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6900, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4862, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5561, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7054, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3589, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9072, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1648, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1261, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0678, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5455, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3625, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8913, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1782, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5545, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8315, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4368, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  35%|███▌      | 35/100 [38:03<1:09:49, 64.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.4040, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4210, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4621, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2493, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5894, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6345, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7631, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0376, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7339, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0177, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7678, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2960, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1746, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2011, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4135, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9595, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1970, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8189, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2193, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5533, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9168, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5456, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3784, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0157, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2398)\n",
      "test  tensor(3.3547)\n",
      "test  tensor(2.8030)\n",
      "test  tensor(2.6837)\n",
      "test  tensor(2.6170)\n",
      "test  tensor(2.7450)\n",
      "test  tensor(4.6991)\n",
      "test  tensor(3.3205)\n",
      "test  tensor(3.5646)\n",
      "test  tensor(2.9620)\n",
      "test  tensor(2.3969)\n",
      "test  tensor(2.3820)\n",
      "test  tensor(2.7881)\n",
      "test  tensor(3.7189)\n",
      "test  tensor(2.7742)\n",
      "test  tensor(1.8466)\n",
      "test  tensor(1.2351)\n",
      "train  tensor(3.3330, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4218, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8953, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9181, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7707, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2666, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7860, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9929, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5492, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5235, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8522, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4791, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3964, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4756, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6511, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8020, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8460, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5978, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6858, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3582, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4784, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8351, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1626, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2533, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8386, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2740, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0405, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1219, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4849, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2851, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8650, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3830, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2203, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8250, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6701, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  36%|███▌      | 36/100 [39:10<1:09:34, 65.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.2264, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7790, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9069, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1066, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4850, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2721, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9780, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7188, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0908, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.8270)\n",
      "test  tensor(3.5496)\n",
      "test  tensor(3.5262)\n",
      "test  tensor(4.4399)\n",
      "test  tensor(2.5996)\n",
      "test  tensor(2.9339)\n",
      "test  tensor(2.8440)\n",
      "test  tensor(3.6875)\n",
      "test  tensor(2.9858)\n",
      "test  tensor(3.0735)\n",
      "test  tensor(2.4066)\n",
      "test  tensor(2.2434)\n",
      "test  tensor(2.4809)\n",
      "test  tensor(2.8198)\n",
      "test  tensor(2.8289)\n",
      "test  tensor(3.3759)\n",
      "test  tensor(5.4011)\n",
      "train  tensor(2.5297, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.3645, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5576, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2206, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9365, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6070, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2105, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4345, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2761, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0177, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6941, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4206, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2842, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6604, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6285, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3762, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8495, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5318, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7183, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2893, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4265, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7327, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4995, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6101, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2981, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1055, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4337, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6385, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0570, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8519, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9470, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3819, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3545, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1937, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0798, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1434, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6196, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1975, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9869, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9048, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1277, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1764, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3260, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7128)\n",
      "test  tensor(2.9860)\n",
      "test  tensor(3.7735)\n",
      "test  tensor(2.5516)\n",
      "test  tensor(3.7847)\n",
      "test  tensor(1.6306)\n",
      "test  tensor(2.7383)\n",
      "test  tensor(3.8510)\n",
      "test  tensor(2.7620)\n",
      "test  tensor(2.9633)\n",
      "test  tensor(2.7928)\n",
      "test  tensor(2.2540)\n",
      "test  tensor(1.8472)\n",
      "test  tensor(3.3517)\n",
      "test  tensor(3.1720)\n",
      "test  tensor(1.8127)\n",
      "test  tensor(1.1881)\n",
      "train  tensor(3.0288, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0997, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0037, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7194, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  37%|███▋      | 37/100 [40:17<1:09:04, 65.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.6631, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4497, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9103, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9026, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4656, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1825, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7806, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7186, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5065, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8280, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1071, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1732, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8818, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9849, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2990, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1006, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0085, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6341, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2298, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8427, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1031, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0342, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5711, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1267, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0239, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3328, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5565, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9631, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1574, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2061, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4101, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7638, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7063, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5822, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6486, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3565, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2969, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9546, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2452, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2469, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6361, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4644)\n",
      "test  tensor(1.9406)\n",
      "test  tensor(2.2036)\n",
      "test  tensor(2.5561)\n",
      "test  tensor(3.0585)\n",
      "test  tensor(2.4616)\n",
      "test  tensor(2.2946)\n",
      "test  tensor(2.8258)\n",
      "test  tensor(2.8820)\n",
      "test  tensor(2.0245)\n",
      "test  tensor(2.6679)\n",
      "test  tensor(2.4913)\n",
      "test  tensor(1.4993)\n",
      "test  tensor(1.9065)\n",
      "test  tensor(2.8901)\n",
      "test  tensor(2.3755)\n",
      "test  tensor(1.3728)\n",
      "train  tensor(2.7780, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0367, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2315, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9425, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8643, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5902, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8429, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2261, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4674, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1302, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8554, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5051, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6313, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5179, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4967, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7727, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2035, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9525, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  38%|███▊      | 38/100 [41:20<1:07:08, 64.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(6.4323, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0945, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5538, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6399, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7711, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8661, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4687, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5059, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7413, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9122, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6646, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3363, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3332, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0774, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9883, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9222, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4096, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6389, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7836, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4606, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2188, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2657, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6388, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3389, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6748, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7550, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7434, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1512)\n",
      "test  tensor(3.3340)\n",
      "test  tensor(2.3381)\n",
      "test  tensor(2.6229)\n",
      "test  tensor(2.5648)\n",
      "test  tensor(2.2911)\n",
      "test  tensor(2.6928)\n",
      "test  tensor(2.7721)\n",
      "test  tensor(2.9848)\n",
      "test  tensor(2.2687)\n",
      "test  tensor(3.4870)\n",
      "test  tensor(2.1346)\n",
      "test  tensor(2.7251)\n",
      "test  tensor(2.5739)\n",
      "test  tensor(2.5173)\n",
      "test  tensor(2.6034)\n",
      "test  tensor(1.5525)\n",
      "train  tensor(2.1138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2613, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6558, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9649, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2989, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9802, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0245, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0971, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1914, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8881, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4649, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8065, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5067, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1990, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8946, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5751, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8695, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5046, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2060, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2830, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8858, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5749, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1693, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7461, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2991, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3429, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2670, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5541, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5150, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3658, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5057, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  39%|███▉      | 39/100 [42:22<1:05:22, 64.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.7484, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0696, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9807, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9079, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3515, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1865, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9657, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5025, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1606, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3466, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5269, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5227, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5682, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6312, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3480, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3151, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2277)\n",
      "test  tensor(1.6849)\n",
      "test  tensor(1.8228)\n",
      "test  tensor(1.8615)\n",
      "test  tensor(1.8627)\n",
      "test  tensor(2.1779)\n",
      "test  tensor(2.8202)\n",
      "test  tensor(2.4700)\n",
      "test  tensor(2.1702)\n",
      "test  tensor(2.3519)\n",
      "test  tensor(1.6984)\n",
      "test  tensor(1.7009)\n",
      "test  tensor(1.2752)\n",
      "test  tensor(1.1431)\n",
      "test  tensor(2.7316)\n",
      "test  tensor(1.3672)\n",
      "test  tensor(2.9092)\n",
      "train  tensor(2.5757, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0563, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3661, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5435, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4612, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9404, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4039, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0595, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8941, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2767, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6866, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5486, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4449, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7832, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2494, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9861, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3067, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5940, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2901, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7661, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6594, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2069, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9905, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5031, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5580, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1759, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1184, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1013, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5314, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1108, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2849, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0287, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7792, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9171, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4423, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1604, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0693, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.3201, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1325, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.2560, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1254, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5988, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0402, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8412, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1942)\n",
      "test  tensor(3.3845)\n",
      "test  tensor(2.4580)\n",
      "test  tensor(3.0409)\n",
      "test  tensor(2.2019)\n",
      "test  tensor(2.9466)\n",
      "test  tensor(2.6712)\n",
      "test  tensor(3.2168)\n",
      "test  tensor(2.9110)\n",
      "test  tensor(4.2577)\n",
      "test  tensor(2.6623)\n",
      "test  tensor(2.3640)\n",
      "test  tensor(2.7436)\n",
      "test  tensor(3.5308)\n",
      "test  tensor(2.9422)\n",
      "test  tensor(3.1628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  40%|████      | 40/100 [43:28<1:04:37, 64.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(0.2913)\n",
      "train  tensor(2.5874, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3018, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2134, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0939, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1623, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0757, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0573, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4513, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1034, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4237, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4214, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3412, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4284, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8554, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4100, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8090, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1818, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8099, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3871, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1277, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2467, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1207, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5919, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0470, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5156, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2696, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4708, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8514, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5236, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2000, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0103, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7812, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4323, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5812, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2562, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0954, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1016, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5522, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6720, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0401, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9282, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3873, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3694, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9876, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6330, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4119, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7855, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6482, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3507, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.9757)\n",
      "test  tensor(2.9380)\n",
      "test  tensor(2.9661)\n",
      "test  tensor(2.5312)\n",
      "test  tensor(2.9340)\n",
      "test  tensor(2.3373)\n",
      "test  tensor(2.4346)\n",
      "test  tensor(2.9821)\n",
      "test  tensor(2.4435)\n",
      "test  tensor(2.8132)\n",
      "test  tensor(3.4402)\n",
      "test  tensor(2.1126)\n",
      "test  tensor(2.9789)\n",
      "test  tensor(3.0719)\n",
      "test  tensor(1.7051)\n",
      "test  tensor(1.7497)\n",
      "test  tensor(0.5218)\n",
      "train  tensor(2.6776, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0491, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6317, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1177, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6134, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5126, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1683, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6385, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5136, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7730, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  41%|████      | 41/100 [44:33<1:03:41, 64.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.1091, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6808, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6557, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2827, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1581, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2921, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4869, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1417, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9400, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3964, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9384, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3392, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1621, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1247, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6065, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9979, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9898, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3765, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4854, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4594, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4074, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5655, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7530, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7973, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4318, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7652, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3511, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2266, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8115, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3458, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8681, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.5123)\n",
      "test  tensor(2.6438)\n",
      "test  tensor(1.6545)\n",
      "test  tensor(1.8712)\n",
      "test  tensor(2.6213)\n",
      "test  tensor(1.4053)\n",
      "test  tensor(1.2176)\n",
      "test  tensor(2.0032)\n",
      "test  tensor(2.0267)\n",
      "test  tensor(1.8084)\n",
      "test  tensor(1.9639)\n",
      "test  tensor(1.8270)\n",
      "test  tensor(0.4052)\n",
      "test  tensor(1.8154)\n",
      "test  tensor(1.6033)\n",
      "test  tensor(2.9745)\n",
      "test  tensor(2.1955)\n",
      "train  tensor(1.6063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9015, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0745, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3816, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9021, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1486, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5290, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7475, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5450, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5810, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3648, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1208, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7851, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1500, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7000, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8084, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3910, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0454, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0662, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9507, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6865, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2348, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7898, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9830, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6613, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5005, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  42%|████▏     | 42/100 [45:36<1:02:13, 64.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(4.8986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3164, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2186, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8385, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3734, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2882, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0607, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2461, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3244, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7445, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6323, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6473, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3792, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5008, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0575, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8104, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9539, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0168, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1874, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.7891)\n",
      "test  tensor(2.5249)\n",
      "test  tensor(1.8484)\n",
      "test  tensor(2.8173)\n",
      "test  tensor(1.9099)\n",
      "test  tensor(2.1682)\n",
      "test  tensor(2.4961)\n",
      "test  tensor(3.1388)\n",
      "test  tensor(2.4962)\n",
      "test  tensor(2.6057)\n",
      "test  tensor(2.7336)\n",
      "test  tensor(2.5435)\n",
      "test  tensor(1.9515)\n",
      "test  tensor(3.6045)\n",
      "test  tensor(2.7993)\n",
      "test  tensor(2.1202)\n",
      "test  tensor(1.7022)\n",
      "train  tensor(1.7101, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6908, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2616, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1500, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2780, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3850, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2767, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8064, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3079, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6905, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8401, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1688, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2437, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8909, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4465, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2866, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6990, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0357, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8030, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4626, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8749, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3560, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0984, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8861, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5029, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7197, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2565, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6681, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2433, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1740, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0364, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0211, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4574, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9265, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9865, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3875, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0420, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  43%|████▎     | 43/100 [46:38<1:00:30, 63.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8251, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1598, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4183, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6957, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6078, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9115, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.9129)\n",
      "test  tensor(3.1578)\n",
      "test  tensor(4.2916)\n",
      "test  tensor(2.7850)\n",
      "test  tensor(2.9374)\n",
      "test  tensor(3.5162)\n",
      "test  tensor(3.6613)\n",
      "test  tensor(2.5086)\n",
      "test  tensor(3.2442)\n",
      "test  tensor(2.6869)\n",
      "test  tensor(2.9140)\n",
      "test  tensor(2.4189)\n",
      "test  tensor(2.5350)\n",
      "test  tensor(3.5998)\n",
      "test  tensor(2.2868)\n",
      "test  tensor(4.0007)\n",
      "test  tensor(1.0702)\n",
      "train  tensor(4.0081, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5700, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4104, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2752, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6365, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8648, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7783, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4372, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1941, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1246, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9506, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5962, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5363, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0844, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4973, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0938, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1133, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4886, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9637, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4617, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3057, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5348, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3179, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2026, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4230, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1935, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6062, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4744, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3322, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8590, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0242, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4778, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9848, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8889, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8096, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3825, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4299, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9150, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6074, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9355, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1866, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7225, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4733, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0042, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0074, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8740, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3440)\n",
      "test  tensor(2.8427)\n",
      "test  tensor(2.4258)\n",
      "test  tensor(2.0369)\n",
      "test  tensor(3.1828)\n",
      "test  tensor(1.5161)\n",
      "test  tensor(2.4557)\n",
      "test  tensor(1.5695)\n",
      "test  tensor(2.3863)\n",
      "test  tensor(2.0978)\n",
      "test  tensor(2.2860)\n",
      "test  tensor(1.1982)\n",
      "test  tensor(2.1308)\n",
      "test  tensor(1.4941)\n",
      "test  tensor(2.1218)\n",
      "test  tensor(3.6029)\n",
      "test  tensor(0.3298)\n",
      "train  tensor(1.7802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6768, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7566, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3189, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2665, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3528, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5677, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5103, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  44%|████▍     | 44/100 [47:44<1:00:02, 64.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.6394, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6384, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1181, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1384, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0194, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8796, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2324, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2291, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0346, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2740, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0781, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7440, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9628, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1756, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9079, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3321, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4268, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5684, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1204, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4033, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6116, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6235, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5355, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6346, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0583, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5281, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.6321, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6700, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4970, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5800, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4534, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5703, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1563, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0418, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1670, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2905, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6891, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4374, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.4571)\n",
      "test  tensor(1.9360)\n",
      "test  tensor(2.2357)\n",
      "test  tensor(2.7977)\n",
      "test  tensor(3.0124)\n",
      "test  tensor(2.7244)\n",
      "test  tensor(1.9890)\n",
      "test  tensor(1.9145)\n",
      "test  tensor(1.8841)\n",
      "test  tensor(2.9688)\n",
      "test  tensor(4.0410)\n",
      "test  tensor(3.5086)\n",
      "test  tensor(2.5414)\n",
      "test  tensor(4.7921)\n",
      "test  tensor(1.4978)\n",
      "test  tensor(2.6896)\n",
      "test  tensor(3.0677)\n",
      "train  tensor(2.4593, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3822, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2048, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8307, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6603, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3362, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1280, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5500, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7601, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9593, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9990, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4196, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0920, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8575, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0028, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2697, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6668, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0413, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4337, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  45%|████▌     | 45/100 [48:50<59:17, 64.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.8609, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4958, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5122, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3257, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1457, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6920, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9182, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7707, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4090, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8840, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8522, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9773, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6290, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7335, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2186, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2726, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9192, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0264, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8418, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8126, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5652, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0990, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2276, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.5607)\n",
      "test  tensor(2.0498)\n",
      "test  tensor(2.9928)\n",
      "test  tensor(3.7707)\n",
      "test  tensor(3.1395)\n",
      "test  tensor(4.5808)\n",
      "test  tensor(2.4814)\n",
      "test  tensor(2.5867)\n",
      "test  tensor(3.2927)\n",
      "test  tensor(4.4246)\n",
      "test  tensor(5.7581)\n",
      "test  tensor(1.6059)\n",
      "test  tensor(3.0173)\n",
      "test  tensor(2.2353)\n",
      "test  tensor(3.2017)\n",
      "test  tensor(3.1087)\n",
      "test  tensor(1.1859)\n",
      "train  tensor(3.6926, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7182, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5885, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5840, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1061, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9919, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9756, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3920, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9487, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3141, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5446, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3349, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3863, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1440, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6524, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8287, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0215, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2374, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8240, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6449, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2276, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3908, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3706, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9756, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6161, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3135, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1694, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2077, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5431, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0834, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9980, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4124, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0969, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1217, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  46%|████▌     | 46/100 [49:55<58:15, 64.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.3300, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0024, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4191, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5945, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1933, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1269, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4527, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6462, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1896, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.6215)\n",
      "test  tensor(1.7324)\n",
      "test  tensor(1.9957)\n",
      "test  tensor(2.7888)\n",
      "test  tensor(2.0198)\n",
      "test  tensor(2.5188)\n",
      "test  tensor(1.8632)\n",
      "test  tensor(1.5130)\n",
      "test  tensor(1.6012)\n",
      "test  tensor(2.4765)\n",
      "test  tensor(1.6736)\n",
      "test  tensor(3.5078)\n",
      "test  tensor(2.7774)\n",
      "test  tensor(0.6440)\n",
      "test  tensor(2.8868)\n",
      "test  tensor(2.0434)\n",
      "test  tensor(0.7671)\n",
      "train  tensor(1.9585, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2998, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3904, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2164, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2952, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9259, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0392, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9437, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1420, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0218, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7097, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5151, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5780, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0750, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4503, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1619, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1060, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4761, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7888, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9523, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6725, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5705, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8933, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8384, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1725, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7503, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6320, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9703, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0153, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5363, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3545, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6999, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6093, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0590, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0429, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8898, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9146, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3662, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2172, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5896, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4308, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3409, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1282)\n",
      "test  tensor(3.8314)\n",
      "test  tensor(3.6610)\n",
      "test  tensor(1.9080)\n",
      "test  tensor(1.7782)\n",
      "test  tensor(3.3139)\n",
      "test  tensor(3.7711)\n",
      "test  tensor(2.2201)\n",
      "test  tensor(3.4374)\n",
      "test  tensor(3.0588)\n",
      "test  tensor(2.0109)\n",
      "test  tensor(2.5035)\n",
      "test  tensor(2.4872)\n",
      "test  tensor(4.2703)\n",
      "test  tensor(2.7221)\n",
      "test  tensor(2.6275)\n",
      "test  tensor(1.7605)\n",
      "train  tensor(2.0842, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3989, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5528, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5050, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  47%|████▋     | 47/100 [51:05<58:42, 66.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.5491, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9556, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4896, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2386, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0120, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4354, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1014, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3139, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9731, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3596, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8375, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6352, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6288, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7321, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4197, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6240, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5982, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8898, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6125, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6891, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1774, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0764, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5581, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6158, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1038, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5940, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6889, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0471, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2158, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9994, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7675, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0141, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4406, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3637, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4841, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7383, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5838, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1357, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5805, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8972, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.8833)\n",
      "test  tensor(1.6612)\n",
      "test  tensor(3.0709)\n",
      "test  tensor(4.3238)\n",
      "test  tensor(2.1000)\n",
      "test  tensor(3.6746)\n",
      "test  tensor(2.4780)\n",
      "test  tensor(2.6273)\n",
      "test  tensor(2.1618)\n",
      "test  tensor(1.8475)\n",
      "test  tensor(2.3215)\n",
      "test  tensor(2.2393)\n",
      "test  tensor(2.3489)\n",
      "test  tensor(2.0241)\n",
      "test  tensor(2.3391)\n",
      "test  tensor(2.6989)\n",
      "test  tensor(2.5681)\n",
      "train  tensor(3.2318, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4008, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5799, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8582, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2925, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9505, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9667, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5931, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4001, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4656, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8398, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1051, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7281, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7671, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0405, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7389, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  48%|████▊     | 48/100 [52:08<56:36, 65.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.0635, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4923, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4246, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3741, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4874, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4690, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7056, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4547, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5567, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6524, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4771, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5706, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0214, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4490, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3223, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2660, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5762, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6604, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5734, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7042, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9914, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2295, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8828, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9311, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2693, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5229, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4368, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.6754)\n",
      "test  tensor(2.3789)\n",
      "test  tensor(2.3628)\n",
      "test  tensor(2.1569)\n",
      "test  tensor(0.8014)\n",
      "test  tensor(1.9048)\n",
      "test  tensor(2.5437)\n",
      "test  tensor(2.9823)\n",
      "test  tensor(1.8450)\n",
      "test  tensor(2.5156)\n",
      "test  tensor(3.9676)\n",
      "test  tensor(2.5952)\n",
      "test  tensor(2.8678)\n",
      "test  tensor(2.6520)\n",
      "test  tensor(2.3886)\n",
      "test  tensor(3.1246)\n",
      "test  tensor(5.4681)\n",
      "train  tensor(2.2700, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8075, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8514, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4981, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7549, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5094, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6703, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3201, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0842, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2420, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0674, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5160, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0272, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7666, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3811, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4163, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8652, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8157, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6902, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8220, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2596, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1427, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8537, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0534, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1531, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6980, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3967, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1362, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4379, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6064, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0280, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  49%|████▉     | 49/100 [53:16<56:12, 66.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.9011, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3128, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3763, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9558, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7530, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1965, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6988, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5089, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3546, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5687, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0923, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1539, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6601, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4259, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2281)\n",
      "test  tensor(2.2957)\n",
      "test  tensor(3.0266)\n",
      "test  tensor(-0.1081)\n",
      "test  tensor(3.2833)\n",
      "test  tensor(2.4059)\n",
      "test  tensor(2.4831)\n",
      "test  tensor(3.5756)\n",
      "test  tensor(2.2354)\n",
      "test  tensor(1.8019)\n",
      "test  tensor(4.0932)\n",
      "test  tensor(3.4180)\n",
      "test  tensor(1.8658)\n",
      "test  tensor(3.1592)\n",
      "test  tensor(2.1891)\n",
      "test  tensor(2.1912)\n",
      "test  tensor(0.6303)\n",
      "train  tensor(2.4091, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5778, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2322, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2417, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0154, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8139, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0723, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5009, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1866, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0781, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4561, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6889, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4102, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8431, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4670, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4213, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4224, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9920, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2349, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6448, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4215, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5266, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0785, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7833, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8090, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0233, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8667, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5414, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1765, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1617, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6057, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2528, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5981, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1889, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0302, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3396, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7847, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7632, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1724, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9239, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3043, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2811, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4048, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0823, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1259, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1557, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9597, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.6129)\n",
      "test  tensor(1.5507)\n",
      "test  tensor(2.8384)\n",
      "test  tensor(3.2099)\n",
      "test  tensor(2.3337)\n",
      "test  tensor(2.3147)\n",
      "test  tensor(2.6972)\n",
      "test  tensor(2.9071)\n",
      "test  tensor(1.5407)\n",
      "test  tensor(2.9746)\n",
      "test  tensor(2.2187)\n",
      "test  tensor(2.3333)\n",
      "test  tensor(2.7315)\n",
      "test  tensor(1.8546)\n",
      "test  tensor(2.3286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  50%|█████     | 50/100 [54:23<55:18, 66.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.8568)\n",
      "test  tensor(0.9267)\n",
      "train  tensor(2.6636, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4385, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5504, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5468, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8933, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4876, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9987, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7305, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4431, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3052, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2290, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3051, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0807, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0887, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6947, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6420, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7390, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3175, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0116, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2916, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0667, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8974, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5661, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3946, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0160, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6823, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4720, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6008, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1586, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4089, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7984, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2432, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4237, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7929, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0769, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3854, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3762, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1540, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7359, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1599, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9836, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4121)\n",
      "test  tensor(2.7547)\n",
      "test  tensor(4.2741)\n",
      "test  tensor(2.3431)\n",
      "test  tensor(3.1346)\n",
      "test  tensor(2.8016)\n",
      "test  tensor(2.9336)\n",
      "test  tensor(2.3838)\n",
      "test  tensor(1.7357)\n",
      "test  tensor(3.3375)\n",
      "test  tensor(0.8455)\n",
      "test  tensor(3.1325)\n",
      "test  tensor(1.9363)\n",
      "test  tensor(2.8727)\n",
      "test  tensor(1.6614)\n",
      "test  tensor(2.5123)\n",
      "test  tensor(1.2729)\n",
      "train  tensor(4.0858, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1833, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2766, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6991, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0922, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7321, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4852, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3101, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4918, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6968, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7370, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  51%|█████     | 51/100 [55:32<54:54, 67.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(6.3481, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7881, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1087, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8881, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9781, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8854, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3325, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3452, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9204, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7877, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9125, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1177, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1799, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2121, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7308, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5027, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8385, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5228, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3644, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8342, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.1565, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5323, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5489, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4292, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1114, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9361, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5009, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6700, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1283, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2763, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7756, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.3158)\n",
      "test  tensor(1.3640)\n",
      "test  tensor(0.8255)\n",
      "test  tensor(2.0002)\n",
      "test  tensor(2.1003)\n",
      "test  tensor(1.9834)\n",
      "test  tensor(1.5576)\n",
      "test  tensor(1.1318)\n",
      "test  tensor(1.1610)\n",
      "test  tensor(0.8112)\n",
      "test  tensor(2.8123)\n",
      "test  tensor(2.7614)\n",
      "test  tensor(0.6198)\n",
      "test  tensor(1.8448)\n",
      "test  tensor(1.7684)\n",
      "test  tensor(1.8663)\n",
      "test  tensor(5.0138)\n",
      "train  tensor(1.5200, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4937, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1267, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5837, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5390, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3519, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2469, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0812, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7323, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8470, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4377, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2297, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4547, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7184, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1378, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3212, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5747, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1277, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8540, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4382, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4311, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6745, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3000, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  52%|█████▏    | 52/100 [56:35<52:48, 66.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.0820, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7251, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3135, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4838, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0088, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5839, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2792, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2608, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6724, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1447, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9946, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.2558, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7041, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2373, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7030, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8770, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7458, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0954, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7088)\n",
      "test  tensor(1.7420)\n",
      "test  tensor(2.6853)\n",
      "test  tensor(1.9155)\n",
      "test  tensor(4.6188)\n",
      "test  tensor(2.5323)\n",
      "test  tensor(3.0625)\n",
      "test  tensor(1.9404)\n",
      "test  tensor(2.1107)\n",
      "test  tensor(2.0520)\n",
      "test  tensor(1.9483)\n",
      "test  tensor(2.3401)\n",
      "test  tensor(2.7355)\n",
      "test  tensor(3.1541)\n",
      "test  tensor(2.1321)\n",
      "test  tensor(1.3466)\n",
      "test  tensor(0.4223)\n",
      "train  tensor(2.3366, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8743, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1453, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6357, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3198, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3379, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7866, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1963, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2797, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7244, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1219, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.2983, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8340, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9057, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0833, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3919, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1625, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1793, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4960, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4416, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0093, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6755, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2721, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4369, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3970, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5678, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2546, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4505, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9992, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7708, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5535, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9531, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8443, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3104, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9542, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1721, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5911, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3826, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0871, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2549, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  53%|█████▎    | 53/100 [57:38<50:56, 65.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.1415, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1256, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7296, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8435, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7284, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1401)\n",
      "test  tensor(2.9329)\n",
      "test  tensor(2.3585)\n",
      "test  tensor(2.1893)\n",
      "test  tensor(2.8652)\n",
      "test  tensor(2.3028)\n",
      "test  tensor(1.7449)\n",
      "test  tensor(2.6313)\n",
      "test  tensor(2.1595)\n",
      "test  tensor(3.5624)\n",
      "test  tensor(2.5343)\n",
      "test  tensor(2.4211)\n",
      "test  tensor(2.5010)\n",
      "test  tensor(1.7972)\n",
      "test  tensor(2.5481)\n",
      "test  tensor(0.9156)\n",
      "test  tensor(-0.1486)\n",
      "train  tensor(3.6518, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2496, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7325, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9613, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3578, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7591, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1478, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1817, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4155, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0469, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3373, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4052, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3888, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3962, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5577, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5072, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9431, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8963, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4565, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0204, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4257, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7617, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8801, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1969, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8818, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0370, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7548, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5221, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2790, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4326, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4469, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6805, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4926, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4475, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1695, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3532, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8431, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4241, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1150, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3819, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9899, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2532, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4443, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7639, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4754, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1379)\n",
      "test  tensor(2.7066)\n",
      "test  tensor(3.5010)\n",
      "test  tensor(1.8159)\n",
      "test  tensor(1.9621)\n",
      "test  tensor(3.1595)\n",
      "test  tensor(2.5708)\n",
      "test  tensor(3.3912)\n",
      "test  tensor(0.9241)\n",
      "test  tensor(2.2547)\n",
      "test  tensor(2.2835)\n",
      "test  tensor(1.4199)\n",
      "test  tensor(2.4920)\n",
      "test  tensor(1.1357)\n",
      "test  tensor(1.2502)\n",
      "test  tensor(1.9154)\n",
      "test  tensor(-0.4621)\n",
      "train  tensor(3.0306, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1783, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6536, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9434, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8339, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5668, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1817, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.2027, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  54%|█████▍    | 54/100 [58:45<50:16, 65.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.7010, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9582, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4740, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0254, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4020, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7542, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9609, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9163, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3188, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6016, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6920, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3622, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3607, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5193, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7911, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0889, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0705, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3961, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3711, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9518, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0623, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1959, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4154, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9632, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9145, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4900, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6874, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1568, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0493, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5101, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8588, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8097, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6890, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9511, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5368, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0280, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3903)\n",
      "test  tensor(1.4726)\n",
      "test  tensor(1.9733)\n",
      "test  tensor(2.3571)\n",
      "test  tensor(2.9928)\n",
      "test  tensor(2.8766)\n",
      "test  tensor(3.2284)\n",
      "test  tensor(2.4114)\n",
      "test  tensor(2.3742)\n",
      "test  tensor(2.7717)\n",
      "test  tensor(1.4907)\n",
      "test  tensor(1.9284)\n",
      "test  tensor(2.8598)\n",
      "test  tensor(2.7748)\n",
      "test  tensor(3.8853)\n",
      "test  tensor(2.0309)\n",
      "test  tensor(2.8422)\n",
      "train  tensor(2.8556, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8441, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7620, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8470, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1751, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8257, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8038, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0676, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3432, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0213, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1350, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6860, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2456, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9776, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1633, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0153, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6514, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7984, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4953, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8550, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1277, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  55%|█████▌    | 55/100 [59:53<49:47, 66.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.1954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3518, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0923, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2096, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0180, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8477, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4215, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6652, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5790, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4441, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5423, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1258, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3060, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1684, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2973, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9061, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1534, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9992, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6972, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6973, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.5886)\n",
      "test  tensor(2.9289)\n",
      "test  tensor(3.8646)\n",
      "test  tensor(2.1820)\n",
      "test  tensor(2.6647)\n",
      "test  tensor(3.0668)\n",
      "test  tensor(2.4508)\n",
      "test  tensor(1.6675)\n",
      "test  tensor(2.0579)\n",
      "test  tensor(2.8840)\n",
      "test  tensor(2.5155)\n",
      "test  tensor(2.0843)\n",
      "test  tensor(2.9353)\n",
      "test  tensor(1.4554)\n",
      "test  tensor(2.8439)\n",
      "test  tensor(2.0121)\n",
      "test  tensor(3.5338)\n",
      "train  tensor(2.5085, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0353, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4410, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6134, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8633, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2303, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8899, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7396, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2662, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9552, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7341, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6446, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2489, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8381, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.0377, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9158, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1969, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0368, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2236, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1538, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0982, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9869, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6760, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9264, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4129, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1958, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3611, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1700, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5801, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7330, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6632, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2419, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4945, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4004, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  56%|█████▌    | 56/100 [1:01:11<51:09, 69.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(4.0039, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0031, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8568, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4816, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4909, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2993, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3261, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1605, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1168, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.8222)\n",
      "test  tensor(2.5005)\n",
      "test  tensor(1.8200)\n",
      "test  tensor(2.3122)\n",
      "test  tensor(2.3056)\n",
      "test  tensor(2.3195)\n",
      "test  tensor(2.4650)\n",
      "test  tensor(2.3713)\n",
      "test  tensor(2.3853)\n",
      "test  tensor(3.0954)\n",
      "test  tensor(2.0667)\n",
      "test  tensor(2.3068)\n",
      "test  tensor(2.4296)\n",
      "test  tensor(2.1869)\n",
      "test  tensor(2.0970)\n",
      "test  tensor(3.8844)\n",
      "test  tensor(0.2070)\n",
      "train  tensor(2.2763, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7672, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3398, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7179, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5056, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6644, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7625, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0557, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6908, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4743, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5439, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2238, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6177, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9532, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8851, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3683, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0618, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3742, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2682, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6930, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3398, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3684, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4555, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0754, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6384, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5466, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6225, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4291, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7091, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9682, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2992, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4535, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1383, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7965, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5795, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9773, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8615, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6066, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0932, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6467, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5361, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6406, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2573, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1555)\n",
      "test  tensor(3.3019)\n",
      "test  tensor(1.7993)\n",
      "test  tensor(2.9399)\n",
      "test  tensor(3.7154)\n",
      "test  tensor(1.1063)\n",
      "test  tensor(2.1878)\n",
      "test  tensor(3.9175)\n",
      "test  tensor(2.5956)\n",
      "test  tensor(3.4064)\n",
      "test  tensor(2.4894)\n",
      "test  tensor(2.1571)\n",
      "test  tensor(2.7837)\n",
      "test  tensor(3.2804)\n",
      "test  tensor(3.8377)\n",
      "test  tensor(1.5326)\n",
      "test  tensor(1.0862)\n",
      "train  tensor(3.0991, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1933, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5908, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2254, grad_fn=<SubBackward0>)\n",
      "train  tensor(9.9564, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  57%|█████▋    | 57/100 [1:02:25<50:55, 71.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.5966, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0456, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1823, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2505, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2714, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6129, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8882, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9677, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3687, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2949, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2308, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7604, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8332, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9315, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5797, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9270, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5846, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2434, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2436, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2601, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4692, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6923, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4660, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4386, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3091, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3072, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9426, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0011, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5573, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5252, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4055, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7445, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0528, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9981, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1964, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4137, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6875, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4738, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5560, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.6802)\n",
      "test  tensor(1.3978)\n",
      "test  tensor(1.9177)\n",
      "test  tensor(5.0451)\n",
      "test  tensor(2.7928)\n",
      "test  tensor(1.2870)\n",
      "test  tensor(1.8872)\n",
      "test  tensor(2.1658)\n",
      "test  tensor(1.3433)\n",
      "test  tensor(2.6517)\n",
      "test  tensor(4.3098)\n",
      "test  tensor(2.6258)\n",
      "test  tensor(1.2852)\n",
      "test  tensor(2.3082)\n",
      "test  tensor(1.8271)\n",
      "test  tensor(1.9853)\n",
      "test  tensor(1.4027)\n",
      "train  tensor(3.6234, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5138, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8722, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9935, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6392, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1984, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9938, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2789, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0097, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4576, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1865, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6648, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0544, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1572, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9391, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9488, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0016, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0390, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  58%|█████▊    | 58/100 [1:04:14<57:40, 82.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.9808, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4627, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1139, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1770, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7987, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9466, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0099, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9582, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1918, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3856, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2969, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0077, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8972, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9513, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3649, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5829, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0771, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5352, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9462, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4658, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6501, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.4843, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0706, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7362, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8512, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6958, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3569, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.9271)\n",
      "test  tensor(2.5543)\n",
      "test  tensor(2.6927)\n",
      "test  tensor(1.4413)\n",
      "test  tensor(3.3190)\n",
      "test  tensor(3.3590)\n",
      "test  tensor(2.8923)\n",
      "test  tensor(2.5634)\n",
      "test  tensor(2.2808)\n",
      "test  tensor(3.6280)\n",
      "test  tensor(2.5186)\n",
      "test  tensor(4.1212)\n",
      "test  tensor(1.5460)\n",
      "test  tensor(1.6015)\n",
      "test  tensor(2.2828)\n",
      "test  tensor(2.4232)\n",
      "test  tensor(-0.2061)\n",
      "train  tensor(2.1876, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4817, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6942, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2388, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8911, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3796, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5522, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2977, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2913, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3863, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7000, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2546, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2161, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9590, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4900, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8314, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4659, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7284, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9504, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0583, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1167, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5135, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2586, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.7777, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0969, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6421, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8616, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4460, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0058, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6303, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2190, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  59%|█████▉    | 59/100 [1:05:21<53:09, 77.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.5503, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8919, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2371, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1724, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6717, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9438, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6268, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0002, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0279, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7674, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0265, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5449, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1251, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1410)\n",
      "test  tensor(2.2910)\n",
      "test  tensor(2.7918)\n",
      "test  tensor(2.1793)\n",
      "test  tensor(2.8923)\n",
      "test  tensor(2.2227)\n",
      "test  tensor(3.6222)\n",
      "test  tensor(3.0302)\n",
      "test  tensor(3.8914)\n",
      "test  tensor(1.6299)\n",
      "test  tensor(1.6511)\n",
      "test  tensor(3.2886)\n",
      "test  tensor(2.9135)\n",
      "test  tensor(1.3634)\n",
      "test  tensor(2.5800)\n",
      "test  tensor(3.0805)\n",
      "test  tensor(7.3197)\n",
      "train  tensor(2.8599, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9618, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6781, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2682, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0199, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5805, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7421, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6766, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9677, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9010, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3530, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5891, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7293, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0541, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6564, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8476, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8360, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7173, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3764, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7619, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9384, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2388, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9698, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5777, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2908, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5898, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9225, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9108, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6970, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8942, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6304, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2019, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8250, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8630, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9697, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3521, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9253, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1292, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5834, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7164, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6265, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7628, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8102, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0014, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8886, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4671, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4026)\n",
      "test  tensor(3.2889)\n",
      "test  tensor(3.7103)\n",
      "test  tensor(2.7907)\n",
      "test  tensor(2.7690)\n",
      "test  tensor(3.8961)\n",
      "test  tensor(2.1079)\n",
      "test  tensor(3.0615)\n",
      "test  tensor(2.1975)\n",
      "test  tensor(3.1905)\n",
      "test  tensor(3.9979)\n",
      "test  tensor(2.0784)\n",
      "test  tensor(2.4460)\n",
      "test  tensor(-1.3635)\n",
      "test  tensor(-0.9097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  60%|██████    | 60/100 [1:06:31<50:23, 75.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.6255)\n",
      "test  tensor(1.3898)\n",
      "train  tensor(3.2529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8697, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3098, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9472, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1732, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5056, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1535, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6132, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0358, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1228, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0054, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7841, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8013, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7956, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7890, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0922, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2209, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9935, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4830, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3715, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0713, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4079, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5721, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3598, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8764, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.2349, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9013, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7493, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3158, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8285, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7563, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0151, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4021, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1597, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7684, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2087, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4816, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9877, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2691, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3918, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5118, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7445, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9189, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0944, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7292, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1994, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1713)\n",
      "test  tensor(2.9347)\n",
      "test  tensor(2.7662)\n",
      "test  tensor(2.2825)\n",
      "test  tensor(3.5357)\n",
      "test  tensor(2.5220)\n",
      "test  tensor(3.0591)\n",
      "test  tensor(2.9064)\n",
      "test  tensor(3.3677)\n",
      "test  tensor(2.5968)\n",
      "test  tensor(2.4793)\n",
      "test  tensor(2.6920)\n",
      "test  tensor(2.2701)\n",
      "test  tensor(0.6177)\n",
      "test  tensor(3.8161)\n",
      "test  tensor(2.9634)\n",
      "test  tensor(0.8562)\n",
      "train  tensor(1.9201, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4957, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6335, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8636, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3987, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5974, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7405, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9131, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7550, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4082, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6950, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6794, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9158, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6873, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  61%|██████    | 61/100 [1:07:37<47:12, 72.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.3367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8257, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2809, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6295, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7434, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9462, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5953, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3563, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1502, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2033, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9809, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5767, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3644, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0792, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6115, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7025, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0175, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4363, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7030, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5799, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4380, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7388, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0416, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2222, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1996, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7801, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9951, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4288, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1238, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.9335)\n",
      "test  tensor(1.5069)\n",
      "test  tensor(1.3809)\n",
      "test  tensor(2.5158)\n",
      "test  tensor(3.1272)\n",
      "test  tensor(1.9633)\n",
      "test  tensor(2.2943)\n",
      "test  tensor(2.7897)\n",
      "test  tensor(1.4041)\n",
      "test  tensor(-0.0251)\n",
      "test  tensor(1.5565)\n",
      "test  tensor(1.4199)\n",
      "test  tensor(2.1595)\n",
      "test  tensor(1.3281)\n",
      "test  tensor(1.9704)\n",
      "test  tensor(1.6678)\n",
      "test  tensor(0.4539)\n",
      "train  tensor(1.9649, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2559, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4282, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6324, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5352, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1518, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1716, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5657, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7141, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2701, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7228, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0444, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3884, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8512, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5139, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0446, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7868, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8579, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6789, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2751, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7736, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4200, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  62%|██████▏   | 62/100 [1:08:44<45:00, 71.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.4715, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8524, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1857, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7772, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9039, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5629, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1552, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7121, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6041, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2876, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8230, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0601, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7938, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5741, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4702, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6642, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.7284)\n",
      "test  tensor(3.1171)\n",
      "test  tensor(3.7161)\n",
      "test  tensor(2.9371)\n",
      "test  tensor(3.0837)\n",
      "test  tensor(2.6793)\n",
      "test  tensor(3.8213)\n",
      "test  tensor(2.1956)\n",
      "test  tensor(2.4393)\n",
      "test  tensor(3.4391)\n",
      "test  tensor(2.2287)\n",
      "test  tensor(3.8335)\n",
      "test  tensor(2.8444)\n",
      "test  tensor(2.4896)\n",
      "test  tensor(2.6587)\n",
      "test  tensor(3.3522)\n",
      "test  tensor(1.0471)\n",
      "train  tensor(2.3828, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9055, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9545, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6598, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9667, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9708, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5206, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8019, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1050, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8352, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2026, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1114, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9496, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4428, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6259, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4071, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7613, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4109, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8017, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0487, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4268, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6907, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3462, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4967, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5347, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5719, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4512, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0073, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8889, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8938, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7078, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5238, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9495, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7379, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0016, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5586, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6157, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6466, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5361, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1793, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7697, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  63%|██████▎   | 63/100 [1:09:48<42:25, 68.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.5027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5587, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7308, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0622, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9115, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1673, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.6858)\n",
      "test  tensor(1.4579)\n",
      "test  tensor(2.2192)\n",
      "test  tensor(1.6401)\n",
      "test  tensor(2.1595)\n",
      "test  tensor(2.7619)\n",
      "test  tensor(0.1625)\n",
      "test  tensor(1.8607)\n",
      "test  tensor(1.6492)\n",
      "test  tensor(2.2492)\n",
      "test  tensor(1.1399)\n",
      "test  tensor(1.6316)\n",
      "test  tensor(2.0531)\n",
      "test  tensor(1.7811)\n",
      "test  tensor(2.0220)\n",
      "test  tensor(2.0842)\n",
      "test  tensor(3.8557)\n",
      "train  tensor(1.4957, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1831, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9826, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8211, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8695, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5435, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1832, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3270, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9807, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8026, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1658, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5071, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5129, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2083, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8762, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7512, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4091, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4306, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7675, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2275, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1227, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7746, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6112, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5129, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2936, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1383, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0861, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9705, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9670, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3962, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7012, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6968, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4782, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6737, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9925, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1575, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.1545, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5121, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4520, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4770, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5487, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7177, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5213, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2829, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5074, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3680, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.5944)\n",
      "test  tensor(2.6642)\n",
      "test  tensor(2.7450)\n",
      "test  tensor(3.7652)\n",
      "test  tensor(0.3641)\n",
      "test  tensor(4.1187)\n",
      "test  tensor(3.7200)\n",
      "test  tensor(2.3530)\n",
      "test  tensor(2.4542)\n",
      "test  tensor(3.6458)\n",
      "test  tensor(2.2798)\n",
      "test  tensor(1.0676)\n",
      "test  tensor(3.9378)\n",
      "test  tensor(3.2376)\n",
      "test  tensor(2.2711)\n",
      "test  tensor(3.8509)\n",
      "test  tensor(-0.3526)\n",
      "train  tensor(1.8449, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2473, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0654, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9058, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8691, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2884, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4507, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4985, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9386, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  64%|██████▍   | 64/100 [1:10:54<40:44, 67.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.4927, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0403, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9287, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6783, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3625, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3012, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0181, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6279, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3978, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8025, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4964, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5424, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4847, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2390, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5333, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0653, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0832, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6431, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7374, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0841, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5641, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9873, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7110, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2215, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2618, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0131, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1190, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8992, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4032, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0094, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7828, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0443, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0212, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4768, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2078, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4838, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5872, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7453, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.8207)\n",
      "test  tensor(3.7583)\n",
      "test  tensor(3.2112)\n",
      "test  tensor(3.2554)\n",
      "test  tensor(2.5928)\n",
      "test  tensor(1.9424)\n",
      "test  tensor(2.6955)\n",
      "test  tensor(3.2659)\n",
      "test  tensor(3.9263)\n",
      "test  tensor(3.4311)\n",
      "test  tensor(2.8480)\n",
      "test  tensor(2.8239)\n",
      "test  tensor(3.6686)\n",
      "test  tensor(3.4306)\n",
      "test  tensor(4.2444)\n",
      "test  tensor(4.6001)\n",
      "test  tensor(0.3716)\n",
      "train  tensor(2.5315, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2638, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6391, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3665, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8157, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4870, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6116, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1973, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5139, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1341, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2521, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5785, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6945, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8527, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2393, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7533, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3243, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9200, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1024, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2875, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5430, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4085, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5222, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3955, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5641, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  65%|██████▌   | 65/100 [1:11:57<38:54, 66.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.8173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0921, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7092, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0660, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0201, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7702, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3193, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8711, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3562, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5393, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2023, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2121, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5773, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4851, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9947, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7229, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1885, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6915, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7884, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0220, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8768, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1513, grad_fn=<SubBackward0>)\n",
      "train  tensor(-3.1140, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9342)\n",
      "test  tensor(3.2696)\n",
      "test  tensor(1.8873)\n",
      "test  tensor(1.9383)\n",
      "test  tensor(2.6905)\n",
      "test  tensor(2.4724)\n",
      "test  tensor(2.9131)\n",
      "test  tensor(3.1216)\n",
      "test  tensor(2.2053)\n",
      "test  tensor(2.7772)\n",
      "test  tensor(2.2868)\n",
      "test  tensor(2.0358)\n",
      "test  tensor(1.3417)\n",
      "test  tensor(3.5945)\n",
      "test  tensor(2.7629)\n",
      "test  tensor(2.3957)\n",
      "test  tensor(-0.0384)\n",
      "train  tensor(1.3137, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4723, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1653, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5052, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5333, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0394, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0535, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8579, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0803, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0394, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2360, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7248, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6478, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0692, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7200, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7023, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8440, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6848, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3437, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8404, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6643, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4192, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5904, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7226, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2427, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7047, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5504, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0047, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5503, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0715, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4663, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2763, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4205, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1684, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1690, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  66%|██████▌   | 66/100 [1:13:03<37:40, 66.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.4936, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5991, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4386, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2558, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4902, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2876, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9058, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0110, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0319, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9110, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.9797)\n",
      "test  tensor(2.5345)\n",
      "test  tensor(2.4796)\n",
      "test  tensor(2.9270)\n",
      "test  tensor(2.8900)\n",
      "test  tensor(4.4450)\n",
      "test  tensor(2.6844)\n",
      "test  tensor(2.2922)\n",
      "test  tensor(2.7967)\n",
      "test  tensor(2.8128)\n",
      "test  tensor(2.4765)\n",
      "test  tensor(2.9043)\n",
      "test  tensor(2.5780)\n",
      "test  tensor(2.4390)\n",
      "test  tensor(2.0615)\n",
      "test  tensor(2.7537)\n",
      "test  tensor(1.1869)\n",
      "train  tensor(2.6608, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5573, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9311, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5781, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7868, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0383, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8366, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3145, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8866, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6266, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7311, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5011, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4276, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1191, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8673, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2738, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4317, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6296, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6720, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2591, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9835, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7545, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3722, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7520, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0332, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6615, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4136, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2636, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3012, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0613, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6905, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9464, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.8199, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9135, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7737, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4842, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5398, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0301, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6322, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0149, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4239, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6176, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6742, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5430, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7872, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7430, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.6133)\n",
      "test  tensor(2.4837)\n",
      "test  tensor(2.6257)\n",
      "test  tensor(4.1490)\n",
      "test  tensor(3.2746)\n",
      "test  tensor(3.5029)\n",
      "test  tensor(3.5002)\n",
      "test  tensor(2.5436)\n",
      "test  tensor(2.3908)\n",
      "test  tensor(3.7977)\n",
      "test  tensor(4.0723)\n",
      "test  tensor(2.7755)\n",
      "test  tensor(2.6137)\n",
      "test  tensor(1.8749)\n",
      "test  tensor(3.9304)\n",
      "test  tensor(3.2340)\n",
      "test  tensor(3.0492)\n",
      "train  tensor(3.3222, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1634, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9603, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6708, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  67%|██████▋   | 67/100 [1:14:09<36:28, 66.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8559, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6870, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9229, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4460, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5617, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3133, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0612, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0951, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2696, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4845, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4680, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7457, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0592, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0982, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3981, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5643, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7808, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3945, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4842, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5725, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4704, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7933, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5968, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5632, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2603, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6092, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2957, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9531, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9558, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0239, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5495, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4606, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9671, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8050, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1363, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3366, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6899, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6674, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5231, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.4337)\n",
      "test  tensor(1.8966)\n",
      "test  tensor(1.9718)\n",
      "test  tensor(2.6406)\n",
      "test  tensor(2.9209)\n",
      "test  tensor(3.1013)\n",
      "test  tensor(2.6308)\n",
      "test  tensor(4.2973)\n",
      "test  tensor(3.1462)\n",
      "test  tensor(3.8959)\n",
      "test  tensor(1.9629)\n",
      "test  tensor(3.3246)\n",
      "test  tensor(3.4342)\n",
      "test  tensor(2.5295)\n",
      "test  tensor(2.2688)\n",
      "test  tensor(2.8931)\n",
      "test  tensor(4.1807)\n",
      "train  tensor(2.5422, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8439, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8451, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7916, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8529, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7614, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4928, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2103, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6431, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0111, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4793, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3657, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7207, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4969, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2030, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0144, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3395, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6666, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  68%|██████▊   | 68/100 [1:15:12<34:50, 65.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.5269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9152, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6288, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5491, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3259, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6877, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6841, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1992, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6945, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0427, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0203, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9321, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2064, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4873, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2570, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7420, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4220, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4141, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5529, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9926, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0118, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3692, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4432, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0582, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3608, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9058, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2561, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2246, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.0815)\n",
      "test  tensor(4.5976)\n",
      "test  tensor(3.0779)\n",
      "test  tensor(2.8920)\n",
      "test  tensor(2.3773)\n",
      "test  tensor(2.1323)\n",
      "test  tensor(2.6629)\n",
      "test  tensor(2.6263)\n",
      "test  tensor(2.3075)\n",
      "test  tensor(2.9527)\n",
      "test  tensor(2.9754)\n",
      "test  tensor(3.1673)\n",
      "test  tensor(4.7256)\n",
      "test  tensor(3.7873)\n",
      "test  tensor(3.2639)\n",
      "test  tensor(3.3874)\n",
      "test  tensor(0.3696)\n",
      "train  tensor(2.9378, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1366, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6335, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3641, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4466, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5399, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8346, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9108, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9650, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3482, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8126, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4485, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6374, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4893, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9556, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8208, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0536, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7056, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5980, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5987, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8231, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4911, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3166, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1528, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2997, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6507, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2482, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1834, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0091, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2961, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2770, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3972, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  69%|██████▉   | 69/100 [1:16:16<33:32, 64.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.0130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5110, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0565, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.5311, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8209, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4630, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9215, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1778, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9689, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7091, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3066, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8674, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6106, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8593, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1395, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.9155)\n",
      "test  tensor(1.8797)\n",
      "test  tensor(1.7108)\n",
      "test  tensor(2.0632)\n",
      "test  tensor(4.0041)\n",
      "test  tensor(1.6798)\n",
      "test  tensor(2.0359)\n",
      "test  tensor(1.4924)\n",
      "test  tensor(1.9466)\n",
      "test  tensor(2.3460)\n",
      "test  tensor(2.1832)\n",
      "test  tensor(2.5263)\n",
      "test  tensor(2.9495)\n",
      "test  tensor(1.9464)\n",
      "test  tensor(2.6271)\n",
      "test  tensor(3.5363)\n",
      "test  tensor(1.4638)\n",
      "train  tensor(3.7387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5810, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4027, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2210, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8643, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2244, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5372, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.8121, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7401, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6347, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0095, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4911, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2563, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4015, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3529, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9295, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1744, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1818, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1186, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2222, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7699, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8783, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7797, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3836, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1550, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9725, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5355, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1742, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1457, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3446, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1265, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3264, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6166, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7415, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8607, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9543, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3416, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9262, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7654, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4101, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7795, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8018, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5603, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5329, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4864, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.4357)\n",
      "test  tensor(1.5597)\n",
      "test  tensor(2.2770)\n",
      "test  tensor(1.9624)\n",
      "test  tensor(2.2801)\n",
      "test  tensor(2.1240)\n",
      "test  tensor(2.0742)\n",
      "test  tensor(1.2170)\n",
      "test  tensor(2.0429)\n",
      "test  tensor(2.3139)\n",
      "test  tensor(2.4746)\n",
      "test  tensor(2.2337)\n",
      "test  tensor(4.0917)\n",
      "test  tensor(2.1432)\n",
      "test  tensor(3.5088)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  70%|███████   | 70/100 [1:17:21<32:28, 64.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.9307)\n",
      "test  tensor(1.9916)\n",
      "train  tensor(2.3769, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3451, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4464, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5828, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6602, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6078, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4518, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2940, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6314, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0402, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4754, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4688, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2728, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9652, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9949, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9113, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2589, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3617, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3985, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4305, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0390, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9505, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6733, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1017, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3916, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8251, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9038, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7758, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3535, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4731, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7268, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6746, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3322, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4877, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0986, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2307, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9736, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3860, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9490, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9391, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2571, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3972, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5154, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7035, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6496, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6500, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.8295)\n",
      "test  tensor(3.2982)\n",
      "test  tensor(2.8267)\n",
      "test  tensor(3.5520)\n",
      "test  tensor(3.8680)\n",
      "test  tensor(2.8782)\n",
      "test  tensor(3.5318)\n",
      "test  tensor(2.7404)\n",
      "test  tensor(2.5293)\n",
      "test  tensor(4.7487)\n",
      "test  tensor(2.1323)\n",
      "test  tensor(2.4294)\n",
      "test  tensor(3.1118)\n",
      "test  tensor(2.3512)\n",
      "test  tensor(2.8682)\n",
      "test  tensor(3.1137)\n",
      "test  tensor(1.2591)\n",
      "train  tensor(2.6438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5175, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3630, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9476, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6887, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5999, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2207, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9044, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5860, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4861, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7419, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  71%|███████   | 71/100 [1:18:27<31:26, 65.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.1421, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8396, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9987, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8484, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8829, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5317, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5567, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1760, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8920, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3351, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2615, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5518, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6749, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3899, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8127, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2065, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9433, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6109, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2122, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4555, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6239, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8115, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3664, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0608, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8455, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9486, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1731, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0271, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3556, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3394, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4948, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2818, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3213)\n",
      "test  tensor(2.6114)\n",
      "test  tensor(3.3260)\n",
      "test  tensor(2.0904)\n",
      "test  tensor(2.7071)\n",
      "test  tensor(3.8407)\n",
      "test  tensor(2.1804)\n",
      "test  tensor(3.0118)\n",
      "test  tensor(3.3565)\n",
      "test  tensor(4.0291)\n",
      "test  tensor(2.8132)\n",
      "test  tensor(3.6199)\n",
      "test  tensor(2.3167)\n",
      "test  tensor(2.5013)\n",
      "test  tensor(3.0539)\n",
      "test  tensor(2.8412)\n",
      "test  tensor(0.2486)\n",
      "train  tensor(2.8775, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9412, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3284, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0896, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9426, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2599, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3507, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8061, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2777, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0860, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1335, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5060, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2465, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7206, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3366, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0576, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1353, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3045, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7399, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5476, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1016, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3982, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1245, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2250, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3812, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0422, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  72%|███████▏  | 72/100 [1:19:31<30:14, 64.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.8593, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5944, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0981, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9647, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4991, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3614, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5058, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5267, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3889, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1709, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4793, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9094, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0816, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1071, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7169, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9474, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.9065)\n",
      "test  tensor(3.5354)\n",
      "test  tensor(2.8462)\n",
      "test  tensor(3.5468)\n",
      "test  tensor(3.3681)\n",
      "test  tensor(3.9717)\n",
      "test  tensor(2.9088)\n",
      "test  tensor(3.1470)\n",
      "test  tensor(2.9619)\n",
      "test  tensor(1.8715)\n",
      "test  tensor(2.5385)\n",
      "test  tensor(3.5434)\n",
      "test  tensor(2.5916)\n",
      "test  tensor(2.4292)\n",
      "test  tensor(3.1628)\n",
      "test  tensor(2.4058)\n",
      "test  tensor(4.7758)\n",
      "train  tensor(2.4914, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2738, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6323, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3956, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3193, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3896, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5789, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8197, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3062, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2429, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2615, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2078, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0183, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4020, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6050, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0653, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5881, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3856, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2078, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8353, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5750, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5457, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4136, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6119, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4422, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2568, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7697, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0224, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7984, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3749, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2248, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0811, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.7062, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3772, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7378, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6536, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2408, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  73%|███████▎  | 73/100 [1:20:36<29:13, 64.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(-0.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8218, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3506, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6608, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3623, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9196, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.3372)\n",
      "test  tensor(1.8037)\n",
      "test  tensor(2.6193)\n",
      "test  tensor(2.7122)\n",
      "test  tensor(2.9967)\n",
      "test  tensor(2.1379)\n",
      "test  tensor(2.5914)\n",
      "test  tensor(0.1789)\n",
      "test  tensor(2.2093)\n",
      "test  tensor(2.6362)\n",
      "test  tensor(2.4693)\n",
      "test  tensor(3.5334)\n",
      "test  tensor(5.0878)\n",
      "test  tensor(3.4974)\n",
      "test  tensor(4.8901)\n",
      "test  tensor(3.2287)\n",
      "test  tensor(1.1653)\n",
      "train  tensor(2.6054, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1168, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5719, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0558, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3288, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7833, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3059, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6179, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2013, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4244, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0009, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0576, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0087, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4253, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1708, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9430, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5049, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1096, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0518, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1358, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4350, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8116, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9380, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9329, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1398, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2812, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1517, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9219, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1031, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9422, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0123, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9328, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5151, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0198, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5892, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5243, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3384, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9330, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9412, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7469, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4252, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2938, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3761, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2838, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2269, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2848, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.9320)\n",
      "test  tensor(2.1220)\n",
      "test  tensor(1.8370)\n",
      "test  tensor(1.8757)\n",
      "test  tensor(4.2084)\n",
      "test  tensor(3.0863)\n",
      "test  tensor(3.0740)\n",
      "test  tensor(3.8548)\n",
      "test  tensor(2.2197)\n",
      "test  tensor(2.6613)\n",
      "test  tensor(2.6783)\n",
      "test  tensor(2.1481)\n",
      "test  tensor(3.2813)\n",
      "test  tensor(2.1603)\n",
      "test  tensor(2.4344)\n",
      "test  tensor(2.6050)\n",
      "test  tensor(7.5641)\n",
      "train  tensor(2.4256, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9923, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0747, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7025, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3353, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0741, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2353, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5071, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  74%|███████▍  | 74/100 [1:21:46<28:47, 66.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(4.2072, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9472, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7302, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7845, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5184, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2056, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5072, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4720, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5220, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2590, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2704, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7450, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0296, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6990, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9977, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0029, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8991, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2107, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2627, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4345, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0213, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3667, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2812, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7173, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7221, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5862, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8878, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5034, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5308, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4374, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5834, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5659, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0232, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1013, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3022, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0378, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8104, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8859, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.0761)\n",
      "test  tensor(2.6970)\n",
      "test  tensor(2.0402)\n",
      "test  tensor(3.0894)\n",
      "test  tensor(2.7422)\n",
      "test  tensor(2.8114)\n",
      "test  tensor(3.2857)\n",
      "test  tensor(2.7382)\n",
      "test  tensor(2.5190)\n",
      "test  tensor(1.2944)\n",
      "test  tensor(1.8139)\n",
      "test  tensor(1.6072)\n",
      "test  tensor(3.6300)\n",
      "test  tensor(2.6896)\n",
      "test  tensor(2.2240)\n",
      "test  tensor(3.4478)\n",
      "test  tensor(0.4964)\n",
      "train  tensor(3.8815, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0812, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9750, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1494, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9599, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7920, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8507, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3507, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9297, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5261, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4511, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5596, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7907, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0202, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9187, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6867, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5236, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4177, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1375, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7360, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9150, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4047, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  75%|███████▌  | 75/100 [1:22:50<27:24, 65.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(8.9031, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8739, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7426, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3274, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6649, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2400, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5770, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8110, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6241, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.4303, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1520, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1975, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0518, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7566, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1377, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6541, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8797, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8948, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0356, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5658, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0263, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1362, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8479, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1540, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7712, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2480)\n",
      "test  tensor(2.3431)\n",
      "test  tensor(3.0208)\n",
      "test  tensor(3.2045)\n",
      "test  tensor(2.7339)\n",
      "test  tensor(3.7892)\n",
      "test  tensor(3.8502)\n",
      "test  tensor(2.9311)\n",
      "test  tensor(3.1663)\n",
      "test  tensor(3.9454)\n",
      "test  tensor(3.0988)\n",
      "test  tensor(2.5734)\n",
      "test  tensor(2.9117)\n",
      "test  tensor(2.9599)\n",
      "test  tensor(3.3540)\n",
      "test  tensor(3.9796)\n",
      "test  tensor(7.9180)\n",
      "train  tensor(3.0002, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2240, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9867, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1375, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0056, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1017, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0693, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3245, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6399, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0270, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2365, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2692, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7471, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7167, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3158, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3742, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0701, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8452, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2665, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7839, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6939, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3070, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6266, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1808, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4140, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6925, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5654, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9434, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1791, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2580, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4921, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1065, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8476, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3758, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8456, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8519, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0790, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1129, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6026, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  76%|███████▌  | 76/100 [1:23:54<26:04, 65.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(4.0391, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7724, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9166, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5535, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2967, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6893, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9029, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1543, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2483, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4351, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2561)\n",
      "test  tensor(3.1718)\n",
      "test  tensor(3.5389)\n",
      "test  tensor(2.4870)\n",
      "test  tensor(4.4836)\n",
      "test  tensor(3.8227)\n",
      "test  tensor(3.8333)\n",
      "test  tensor(2.4700)\n",
      "test  tensor(3.1838)\n",
      "test  tensor(3.2781)\n",
      "test  tensor(5.6401)\n",
      "test  tensor(2.7551)\n",
      "test  tensor(3.8801)\n",
      "test  tensor(3.3898)\n",
      "test  tensor(2.6544)\n",
      "test  tensor(5.6840)\n",
      "test  tensor(0.9975)\n",
      "train  tensor(3.9606, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2031, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1634, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0132, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3942, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4116, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2146, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4139, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4007, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7634, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5263, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7435, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8200, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7865, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7908, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3008, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9786, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8830, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6168, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4506, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4302, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6228, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5473, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6503, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9651, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0129, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9072, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9884, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8315, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4094, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6455, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4319, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3311, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9102, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7820, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7203, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4840, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2762, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6377, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5951, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9685, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1627, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8159, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2288, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9023, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1095, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.4953)\n",
      "test  tensor(2.3334)\n",
      "test  tensor(1.4787)\n",
      "test  tensor(2.3302)\n",
      "test  tensor(2.6239)\n",
      "test  tensor(3.6064)\n",
      "test  tensor(3.5101)\n",
      "test  tensor(3.8016)\n",
      "test  tensor(2.2764)\n",
      "test  tensor(4.3086)\n",
      "test  tensor(3.6345)\n",
      "test  tensor(2.3202)\n",
      "test  tensor(3.8750)\n",
      "test  tensor(2.9864)\n",
      "test  tensor(3.9074)\n",
      "test  tensor(2.6818)\n",
      "test  tensor(-0.1324)\n",
      "train  tensor(3.3669, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9398, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5766, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6229, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  77%|███████▋  | 77/100 [1:25:01<25:11, 65.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.0313, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4846, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0795, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6814, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5764, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6023, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.9814, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0587, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9170, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2274, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3949, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3873, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1335, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0965, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3868, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4815, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2649, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3287, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2586, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4681, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2536, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.1058, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4975, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5607, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.0673, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6578, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8286, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2062, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5165, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6182, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5180, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6171, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9643, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2141, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8227, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6808, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0667, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7093, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3055, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5179, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3932, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2067)\n",
      "test  tensor(3.1756)\n",
      "test  tensor(2.4095)\n",
      "test  tensor(2.9630)\n",
      "test  tensor(2.6235)\n",
      "test  tensor(2.8962)\n",
      "test  tensor(1.9247)\n",
      "test  tensor(1.6307)\n",
      "test  tensor(1.4433)\n",
      "test  tensor(5.8320)\n",
      "test  tensor(1.6839)\n",
      "test  tensor(3.7444)\n",
      "test  tensor(1.9549)\n",
      "test  tensor(2.4154)\n",
      "test  tensor(2.6442)\n",
      "test  tensor(3.6093)\n",
      "test  tensor(5.8307)\n",
      "train  tensor(3.5467, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4673, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9842, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4628, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6814, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4081, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4552, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0670, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0146, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9865, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7243, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9840, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4943, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7479, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0435, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0913, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3962, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8433, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1470, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  78%|███████▊  | 78/100 [1:26:05<23:53, 65.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.4070, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4387, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2057, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3230, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8800, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7894, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6247, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9145, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8326, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4854, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1305, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6473, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8542, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6866, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9670, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7935, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3168, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0110, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0408, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8471, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7062, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4431, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1226, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0890, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3706, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5702, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5597, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.3082, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6709, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2134, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.7184)\n",
      "test  tensor(3.6392)\n",
      "test  tensor(2.3274)\n",
      "test  tensor(2.6175)\n",
      "test  tensor(0.3828)\n",
      "test  tensor(2.4602)\n",
      "test  tensor(4.6956)\n",
      "test  tensor(1.8550)\n",
      "test  tensor(2.5626)\n",
      "test  tensor(2.1807)\n",
      "test  tensor(4.3096)\n",
      "test  tensor(3.0218)\n",
      "test  tensor(3.1213)\n",
      "test  tensor(3.8857)\n",
      "test  tensor(3.8579)\n",
      "test  tensor(2.7908)\n",
      "test  tensor(9.8926)\n",
      "train  tensor(2.1159, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7972, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9531, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3494, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2172, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1408, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3550, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6528, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7072, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4296, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8973, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1241, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2722, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5103, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0461, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6281, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0319, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2632, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1987, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2752, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.6929, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3877, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9294, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7709, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6956, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1013, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3764, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2971, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1549, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5016, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6607, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7099, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  79%|███████▉  | 79/100 [1:27:10<22:46, 65.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(-0.4568, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4548, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1944, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7122, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3370, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1507, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1772, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3976, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8812, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7363, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8227, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4238, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7134, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6013, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3573)\n",
      "test  tensor(3.3691)\n",
      "test  tensor(2.2872)\n",
      "test  tensor(2.0610)\n",
      "test  tensor(2.3197)\n",
      "test  tensor(3.8702)\n",
      "test  tensor(3.8818)\n",
      "test  tensor(2.2944)\n",
      "test  tensor(1.3992)\n",
      "test  tensor(3.0693)\n",
      "test  tensor(1.1921)\n",
      "test  tensor(2.2817)\n",
      "test  tensor(2.0346)\n",
      "test  tensor(2.4994)\n",
      "test  tensor(1.7822)\n",
      "test  tensor(1.7084)\n",
      "test  tensor(0.6282)\n",
      "train  tensor(3.5291, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8432, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3226, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9244, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6823, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2051, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3253, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6357, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0451, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6480, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6204, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6206, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5894, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1367, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7859, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9916, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1283, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6026, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9430, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2611, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6878, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6238, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8868, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9535, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9468, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1417, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1498, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.4333, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2404, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2688, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0545, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0756, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7029, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1139, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9239, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5275, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8086, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9649, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3499, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6164, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.4924)\n",
      "test  tensor(4.2929)\n",
      "test  tensor(2.3502)\n",
      "test  tensor(2.8578)\n",
      "test  tensor(3.2552)\n",
      "test  tensor(2.3367)\n",
      "test  tensor(3.7401)\n",
      "test  tensor(2.6109)\n",
      "test  tensor(2.8620)\n",
      "test  tensor(5.5440)\n",
      "test  tensor(2.2001)\n",
      "test  tensor(2.7996)\n",
      "test  tensor(2.9533)\n",
      "test  tensor(2.3255)\n",
      "test  tensor(3.8742)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  80%|████████  | 80/100 [1:28:19<22:06, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(3.2834)\n",
      "test  tensor(-0.3367)\n",
      "train  tensor(5.3148, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7735, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6756, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2253, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8157, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2531, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0712, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6520, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6071, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3750, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8798, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2511, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2963, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8152, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0038, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6693, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6032, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3216, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9925, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2063, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2532, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4462, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8756, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0559, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1390, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3584, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9650, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9191, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2738, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3676, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4365, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0023, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.6150, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9585, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7295, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2633, grad_fn=<SubBackward0>)\n",
      "train  tensor(-3.7705, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9264, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1734, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8524, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5868, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7214, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5532, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2423, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.4847, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6048, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1916)\n",
      "test  tensor(2.2871)\n",
      "test  tensor(2.3211)\n",
      "test  tensor(2.6751)\n",
      "test  tensor(2.4168)\n",
      "test  tensor(3.3735)\n",
      "test  tensor(3.0018)\n",
      "test  tensor(2.7803)\n",
      "test  tensor(1.8060)\n",
      "test  tensor(2.3565)\n",
      "test  tensor(1.9421)\n",
      "test  tensor(1.9726)\n",
      "test  tensor(1.1957)\n",
      "test  tensor(1.5421)\n",
      "test  tensor(3.4819)\n",
      "test  tensor(3.0961)\n",
      "test  tensor(0.6134)\n",
      "train  tensor(2.0342, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4460, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5720, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2737, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1883, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2585, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7255, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0273, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3554, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9276, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6811, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5281, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7112, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8424, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1857, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  81%|████████  | 81/100 [1:29:28<21:12, 66.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.7358, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4042, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1373, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8558, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4570, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6817, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4540, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8479, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0309, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6576, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7522, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0514, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5275, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4138, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8166, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0815, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9160, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2593, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0438, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8349, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2066, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1710, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8293, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7336, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2518, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1849, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4172, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3286, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3168, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3780, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4763, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0107, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0787, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.1403)\n",
      "test  tensor(1.5034)\n",
      "test  tensor(1.8015)\n",
      "test  tensor(2.3242)\n",
      "test  tensor(2.0752)\n",
      "test  tensor(1.8589)\n",
      "test  tensor(2.0521)\n",
      "test  tensor(1.1180)\n",
      "test  tensor(1.0509)\n",
      "test  tensor(2.6549)\n",
      "test  tensor(2.0105)\n",
      "test  tensor(1.2893)\n",
      "test  tensor(1.1047)\n",
      "test  tensor(0.9604)\n",
      "test  tensor(3.0842)\n",
      "test  tensor(2.3742)\n",
      "test  tensor(2.5779)\n",
      "train  tensor(2.3091, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7879, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8151, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5065, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7870, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4303, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9214, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5440, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1119, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1513, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7317, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7458, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3454, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7017, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1382, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4386, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9460, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7199, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6736, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6940, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9109, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9043, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0158, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4943, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6244, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3012, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2571, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9259, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  82%|████████▏ | 82/100 [1:30:36<20:13, 67.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.0235, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9917, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0655, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9894, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9130, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7881, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7155, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2788, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4913, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9773, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1747, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0664, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4877, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6233, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2056, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0179, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3919, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4882, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8436, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3868, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3584)\n",
      "test  tensor(2.1822)\n",
      "test  tensor(2.7293)\n",
      "test  tensor(2.7175)\n",
      "test  tensor(2.2813)\n",
      "test  tensor(2.2236)\n",
      "test  tensor(4.4386)\n",
      "test  tensor(2.2100)\n",
      "test  tensor(3.0479)\n",
      "test  tensor(3.1473)\n",
      "test  tensor(3.0039)\n",
      "test  tensor(1.5845)\n",
      "test  tensor(2.4346)\n",
      "test  tensor(2.0127)\n",
      "test  tensor(1.6738)\n",
      "test  tensor(1.4750)\n",
      "test  tensor(6.5288)\n",
      "train  tensor(2.1551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9212, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2314, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9330, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6549, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5942, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6539, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1448, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2451, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8270, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6286, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1030, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5101, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8553, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0076, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3085, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0199, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.5197, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5077, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1755, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4277, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0111, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8015, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6793, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0882, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9862, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5385, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5221, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0869, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.4704, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8842, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4942, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9746, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7105, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5627, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7573, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6812, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4251, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9555, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1877, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0276, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  83%|████████▎ | 83/100 [1:31:43<19:04, 67.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.1862, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0955, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1474, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6113, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.9893, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5344, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3180)\n",
      "test  tensor(2.6819)\n",
      "test  tensor(3.1114)\n",
      "test  tensor(2.2651)\n",
      "test  tensor(2.8058)\n",
      "test  tensor(4.9963)\n",
      "test  tensor(1.8125)\n",
      "test  tensor(3.4129)\n",
      "test  tensor(2.8221)\n",
      "test  tensor(4.9927)\n",
      "test  tensor(2.8014)\n",
      "test  tensor(3.5889)\n",
      "test  tensor(2.4906)\n",
      "test  tensor(3.3200)\n",
      "test  tensor(2.5596)\n",
      "test  tensor(3.6159)\n",
      "test  tensor(1.2121)\n",
      "train  tensor(3.6643, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7399, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7808, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1491, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9360, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1795, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0903, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6413, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7205, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8743, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1566, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1996, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8253, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9884, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2272, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6217, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0108, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9301, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5035, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0667, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0522, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6240, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7420, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6671, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4250, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0464, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7488, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8969, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0986, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5158, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5413, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3251, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5073, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8065, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7243, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5967, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4604, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8598, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3421, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9574, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6766, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2124, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9064, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5079, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6890, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7166, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1630, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1250, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8957, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3649, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.8855)\n",
      "test  tensor(3.2745)\n",
      "test  tensor(3.2474)\n",
      "test  tensor(3.1308)\n",
      "test  tensor(2.7251)\n",
      "test  tensor(2.7843)\n",
      "test  tensor(3.6279)\n",
      "test  tensor(4.0763)\n",
      "test  tensor(2.6784)\n",
      "test  tensor(3.5080)\n",
      "test  tensor(2.2558)\n",
      "test  tensor(3.5595)\n",
      "test  tensor(2.8663)\n",
      "test  tensor(2.3441)\n",
      "test  tensor(2.4384)\n",
      "test  tensor(2.0865)\n",
      "test  tensor(0.2898)\n",
      "train  tensor(2.8116, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4780, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8682, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9403, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7840, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0508, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3497, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2856, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  84%|████████▍ | 84/100 [1:32:52<18:04, 67.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.8449, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8747, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2522, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7692, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2454, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2787, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0808, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8321, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.6717, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8326, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6036, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8686, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0744, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3933, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9621, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5892, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.3791, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6411, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1912, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5536, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4495, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8574, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0423, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4727, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5378, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8553, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2225, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0462, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6610, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8718, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6952, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8876, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6100, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9588, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.7837, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5976, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6939, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2400, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4560, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2633, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2789)\n",
      "test  tensor(2.1711)\n",
      "test  tensor(2.3140)\n",
      "test  tensor(1.5967)\n",
      "test  tensor(4.5762)\n",
      "test  tensor(4.5927)\n",
      "test  tensor(2.9903)\n",
      "test  tensor(2.1447)\n",
      "test  tensor(2.5132)\n",
      "test  tensor(2.6778)\n",
      "test  tensor(1.9660)\n",
      "test  tensor(1.5805)\n",
      "test  tensor(2.3770)\n",
      "test  tensor(3.7099)\n",
      "test  tensor(3.3421)\n",
      "test  tensor(6.2587)\n",
      "test  tensor(28.7747)\n",
      "train  tensor(3.4005, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0731, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1525, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9502, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8130, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9097, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0558, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0508, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3162, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2280, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9926, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3344, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1768, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3314, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0184, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.7691, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8030, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.0382, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4287, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9565, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6575, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1064, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  85%|████████▌ | 85/100 [1:33:56<16:38, 66.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.9554, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7586, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7156, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9639, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7501, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3546, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1651, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4879, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3273, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1867, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3473, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8657, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6889, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1557, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0651, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5875, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1715, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4965, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5598, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5944, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5675, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6339, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4253, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6390, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2929, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.5710)\n",
      "test  tensor(3.1923)\n",
      "test  tensor(1.9510)\n",
      "test  tensor(1.7651)\n",
      "test  tensor(3.5634)\n",
      "test  tensor(3.2254)\n",
      "test  tensor(2.0755)\n",
      "test  tensor(1.1385)\n",
      "test  tensor(3.1490)\n",
      "test  tensor(3.0763)\n",
      "test  tensor(1.4040)\n",
      "test  tensor(2.9723)\n",
      "test  tensor(2.7489)\n",
      "test  tensor(1.9830)\n",
      "test  tensor(1.9574)\n",
      "test  tensor(3.2807)\n",
      "test  tensor(4.8823)\n",
      "train  tensor(2.0817, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9780, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5513, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9997, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5759, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3164, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7150, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8813, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9905, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1996, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2977, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8621, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7641, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7775, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6446, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5053, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6473, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3780, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0435, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1478, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3139, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6871, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5279, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5921, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1270, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3814, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9068, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6689, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3464, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3824, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2070, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2121, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8982, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1815, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9338, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2531, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0902, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7433, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6763, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  86%|████████▌ | 86/100 [1:34:59<15:18, 65.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.5457, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7419, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1640, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5306, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0391, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9238, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5843, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3083, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9452, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6761, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.5091)\n",
      "test  tensor(2.2396)\n",
      "test  tensor(1.8520)\n",
      "test  tensor(3.6937)\n",
      "test  tensor(2.5173)\n",
      "test  tensor(2.7185)\n",
      "test  tensor(2.1544)\n",
      "test  tensor(1.6687)\n",
      "test  tensor(2.2079)\n",
      "test  tensor(1.6436)\n",
      "test  tensor(3.0486)\n",
      "test  tensor(2.8826)\n",
      "test  tensor(2.1877)\n",
      "test  tensor(1.8383)\n",
      "test  tensor(2.5367)\n",
      "test  tensor(2.7811)\n",
      "test  tensor(6.5411)\n",
      "train  tensor(1.9002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5577, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9554, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9867, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5965, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4104, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5230, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7114, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.7814, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1988, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1236, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7559, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4737, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4838, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9727, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7745, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1878, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4672, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9577, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4817, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0029, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6414, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1397, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5773, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7956, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5136, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0537, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6374, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9087, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0507, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5014, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2206, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0197, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7660, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2502, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8123, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9142, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0172, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9858, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6884, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2480, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3404, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0296, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3508, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8339, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7862, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.9600)\n",
      "test  tensor(3.1142)\n",
      "test  tensor(3.4516)\n",
      "test  tensor(2.2302)\n",
      "test  tensor(3.1325)\n",
      "test  tensor(4.0633)\n",
      "test  tensor(3.1063)\n",
      "test  tensor(2.6140)\n",
      "test  tensor(3.4049)\n",
      "test  tensor(2.7995)\n",
      "test  tensor(2.5348)\n",
      "test  tensor(2.5008)\n",
      "test  tensor(2.5377)\n",
      "test  tensor(2.2985)\n",
      "test  tensor(2.2514)\n",
      "test  tensor(4.2619)\n",
      "test  tensor(1.6341)\n",
      "train  tensor(4.5933, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8916, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3278, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8948, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  87%|████████▋ | 87/100 [1:36:06<14:16, 65.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.2589, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0180, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6304, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4613, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5883, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4131, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7480, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6623, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7035, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5109, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8051, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.6798, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5707, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1337, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2865, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9882, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6620, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1560, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7196, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3233, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5341, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5471, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9861, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1917, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8643, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2630, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7295, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2121, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7100, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6529, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1393, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2130, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1342, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3524, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7787, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8665, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8174, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1053, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0287, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7621, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4928, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5943, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.2381)\n",
      "test  tensor(2.4533)\n",
      "test  tensor(1.8703)\n",
      "test  tensor(2.5224)\n",
      "test  tensor(2.0473)\n",
      "test  tensor(2.1470)\n",
      "test  tensor(4.2039)\n",
      "test  tensor(2.3380)\n",
      "test  tensor(2.0210)\n",
      "test  tensor(2.0785)\n",
      "test  tensor(2.2057)\n",
      "test  tensor(1.6876)\n",
      "test  tensor(3.3140)\n",
      "test  tensor(1.6165)\n",
      "test  tensor(2.7982)\n",
      "test  tensor(2.3003)\n",
      "test  tensor(0.1684)\n",
      "train  tensor(2.3916, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9472, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8417, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7037, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1924, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0313, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2511, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3489, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6303, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5321, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2966, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6994, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3899, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4863, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9022, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7567, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7774, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  88%|████████▊ | 88/100 [1:37:07<12:53, 64.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.2070, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7847, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8137, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3258, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0895, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7423, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7000, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5898, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3971, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8130, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7341, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0479, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6919, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0742, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4267, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6994, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0113, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2569, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1453, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6345, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9117, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5439, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7727, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5328, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0086, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5025, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1492, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1998, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6734, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7301, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.2875)\n",
      "test  tensor(2.5498)\n",
      "test  tensor(3.3381)\n",
      "test  tensor(2.3870)\n",
      "test  tensor(1.8513)\n",
      "test  tensor(4.0490)\n",
      "test  tensor(4.2209)\n",
      "test  tensor(2.6497)\n",
      "test  tensor(3.1115)\n",
      "test  tensor(2.6236)\n",
      "test  tensor(2.8121)\n",
      "test  tensor(4.8054)\n",
      "test  tensor(2.4555)\n",
      "test  tensor(1.7884)\n",
      "test  tensor(3.2208)\n",
      "test  tensor(2.3277)\n",
      "test  tensor(0.6779)\n",
      "train  tensor(2.4241, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1554, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1879, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8960, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7003, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8564, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4624, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6810, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1044, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0894, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6338, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3480, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6037, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6880, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1818, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6028, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7555, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7798, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3698, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5645, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4245, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9354, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4676, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4196, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6271, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7035, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6987, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8077, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5612, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2808, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4839, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4483, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5699, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  89%|████████▉ | 89/100 [1:38:08<11:39, 63.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.9909, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5399, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0625, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6059, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6767, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9517, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7175, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2129, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4319, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5547, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5886, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0065, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2449, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1263, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1527, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8650, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.4819)\n",
      "test  tensor(2.7666)\n",
      "test  tensor(3.8496)\n",
      "test  tensor(2.7887)\n",
      "test  tensor(2.0786)\n",
      "test  tensor(1.7438)\n",
      "test  tensor(3.6489)\n",
      "test  tensor(3.8621)\n",
      "test  tensor(2.7468)\n",
      "test  tensor(1.1889)\n",
      "test  tensor(2.9923)\n",
      "test  tensor(1.8720)\n",
      "test  tensor(5.5567)\n",
      "test  tensor(2.5656)\n",
      "test  tensor(2.9106)\n",
      "test  tensor(3.8656)\n",
      "test  tensor(0.6155)\n",
      "train  tensor(2.1944, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0749, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1880, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3429, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8938, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1276, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2217, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9555, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8980, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8141, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1192, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6552, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9193, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7285, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1779, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.4727, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5540, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5602, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9471, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0456, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5131, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0235, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6630, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2370, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5671, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8014, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3428, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0112, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1229, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9681, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2437, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9596, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6985, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.2176, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9287, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6596, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7405, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7757, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2159, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3603, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9383, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1442, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9258, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2078, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3910, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8221, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0885, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1589, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5097, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.1330)\n",
      "test  tensor(2.4088)\n",
      "test  tensor(3.5784)\n",
      "test  tensor(3.2627)\n",
      "test  tensor(2.5404)\n",
      "test  tensor(2.3648)\n",
      "test  tensor(3.0656)\n",
      "test  tensor(3.4406)\n",
      "test  tensor(3.9500)\n",
      "test  tensor(4.9733)\n",
      "test  tensor(4.1982)\n",
      "test  tensor(2.9926)\n",
      "test  tensor(4.5204)\n",
      "test  tensor(2.4486)\n",
      "test  tensor(2.6028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  90%|█████████ | 90/100 [1:39:14<10:42, 64.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(2.2403)\n",
      "test  tensor(5.9537)\n",
      "train  tensor(2.2747, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4606, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4787, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7020, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0356, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.2088, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9534, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2614, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9758, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8457, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3081, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4919, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8778, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5963, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2232, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0185, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9368, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9322, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5735, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1398, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2039, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8819, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1164, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5373, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5472, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9199, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2766, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5605, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8928, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9500, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2379, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7113, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2054, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6265, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0004, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1498, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6335, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9958, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4641, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6088, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0806, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5636, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8217, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0450, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0092, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9301, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0824, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.6930)\n",
      "test  tensor(2.8452)\n",
      "test  tensor(3.4400)\n",
      "test  tensor(2.7936)\n",
      "test  tensor(3.2666)\n",
      "test  tensor(3.2761)\n",
      "test  tensor(1.7089)\n",
      "test  tensor(2.3240)\n",
      "test  tensor(2.7359)\n",
      "test  tensor(1.0583)\n",
      "test  tensor(1.0702)\n",
      "test  tensor(1.6126)\n",
      "test  tensor(3.2640)\n",
      "test  tensor(2.0489)\n",
      "test  tensor(3.3204)\n",
      "test  tensor(2.9690)\n",
      "test  tensor(-0.0070)\n",
      "train  tensor(3.1956, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7679, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0952, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3565, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3085, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3367, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4773, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5166, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4000, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0826, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1625, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5493, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6860, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  91%|█████████ | 91/100 [1:40:18<09:36, 64.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.2872, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4791, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8637, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0689, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9119, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5386, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3491, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5419, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2583, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3740, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3174, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5573, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6019, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6403, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1778, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8007, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6611, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4246, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2000, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5171, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1668, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0819, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9796, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9849, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4033, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6456, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5537, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8221, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7004, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1832, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4153, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7909, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0691, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8992, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9137, grad_fn=<SubBackward0>)\n",
      "test  tensor(6.3681)\n",
      "test  tensor(3.4773)\n",
      "test  tensor(2.6543)\n",
      "test  tensor(2.0368)\n",
      "test  tensor(3.5320)\n",
      "test  tensor(2.2691)\n",
      "test  tensor(2.5609)\n",
      "test  tensor(2.3316)\n",
      "test  tensor(3.7557)\n",
      "test  tensor(4.7572)\n",
      "test  tensor(2.8276)\n",
      "test  tensor(2.9510)\n",
      "test  tensor(3.4564)\n",
      "test  tensor(3.2197)\n",
      "test  tensor(2.1310)\n",
      "test  tensor(3.5193)\n",
      "test  tensor(-0.0978)\n",
      "train  tensor(2.7910, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2080, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8230, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5359, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6118, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4535, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9316, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9147, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7516, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6080, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2036, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5728, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3824, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8962, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0203, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4941, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5965, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5281, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8436, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7919, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6699, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2583, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4750, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6295, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  92%|█████████▏| 92/100 [1:41:21<08:30, 63.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(0.7393, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7800, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5350, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.6316, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6890, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2300, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4847, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0807, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9843, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3172, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2080, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9369, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4355, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7053, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5509, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5866, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2027, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6588, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1653, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9695, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1157)\n",
      "test  tensor(3.6493)\n",
      "test  tensor(1.9255)\n",
      "test  tensor(4.0371)\n",
      "test  tensor(2.1299)\n",
      "test  tensor(3.1153)\n",
      "test  tensor(3.2078)\n",
      "test  tensor(-0.7760)\n",
      "test  tensor(1.4083)\n",
      "test  tensor(6.6292)\n",
      "test  tensor(2.4761)\n",
      "test  tensor(3.0017)\n",
      "test  tensor(1.7728)\n",
      "test  tensor(1.3429)\n",
      "test  tensor(2.5997)\n",
      "test  tensor(2.4461)\n",
      "test  tensor(2.9183)\n",
      "train  tensor(3.4431, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4322, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3905, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0213, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3908, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5320, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8083, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8539, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5883, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6400, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3803, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9037, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3601, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8040, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1363, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5645, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5915, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5672, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8759, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.8800, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3068, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.2774, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2897, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5572, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4288, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9024, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3595, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1567, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4153, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1189, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9071, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2730, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2104, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7224, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1687, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5970, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9856, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0832, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8261, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9539, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5576, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7305, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9565, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3783, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2168, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  93%|█████████▎| 93/100 [1:42:27<07:31, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.9030, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7185, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8266, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5102, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8231, grad_fn=<SubBackward0>)\n",
      "test  tensor(0.9379)\n",
      "test  tensor(3.3454)\n",
      "test  tensor(1.7853)\n",
      "test  tensor(3.9236)\n",
      "test  tensor(3.1551)\n",
      "test  tensor(1.4031)\n",
      "test  tensor(0.2511)\n",
      "test  tensor(2.0219)\n",
      "test  tensor(1.4722)\n",
      "test  tensor(2.9436)\n",
      "test  tensor(2.1219)\n",
      "test  tensor(1.7118)\n",
      "test  tensor(4.6135)\n",
      "test  tensor(2.7177)\n",
      "test  tensor(1.6217)\n",
      "test  tensor(3.2629)\n",
      "test  tensor(2.3848)\n",
      "train  tensor(2.4258, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1386, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8445, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7113, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0544, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1370, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7808, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5810, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5580, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4094, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5530, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5954, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5184, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1526, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2246, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8804, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2425, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1865, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3141, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9734, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4432, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1615, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4567, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2176, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7686, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7569, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0886, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2163, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0605, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3434, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1934, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2669, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8926, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8744, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4659, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6855, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8341, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5728, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8755, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9806, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6665, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7813, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5302, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9355, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1642, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0590, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1799, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7202, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6672, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.4730)\n",
      "test  tensor(2.1636)\n",
      "test  tensor(2.0216)\n",
      "test  tensor(3.0293)\n",
      "test  tensor(2.2031)\n",
      "test  tensor(3.0775)\n",
      "test  tensor(3.4846)\n",
      "test  tensor(3.0585)\n",
      "test  tensor(2.9344)\n",
      "test  tensor(3.1876)\n",
      "test  tensor(1.9250)\n",
      "test  tensor(3.1096)\n",
      "test  tensor(2.3603)\n",
      "test  tensor(2.1522)\n",
      "test  tensor(2.8640)\n",
      "test  tensor(3.3138)\n",
      "test  tensor(5.3268)\n",
      "train  tensor(4.1487, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9399, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1911, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.4165, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2136, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0215, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5388, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5483, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0907, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7782, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  94%|█████████▍| 94/100 [1:43:43<06:47, 67.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.9828, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4409, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3307, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2302, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8835, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7063, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5369, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2544, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6989, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3721, grad_fn=<SubBackward0>)\n",
      "train  tensor(5.1195, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3151, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8077, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9772, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2290, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2747, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8732, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6829, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.7617, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4720, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5002, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2864, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7173, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6156, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8777, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4927, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9512, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2925, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4977, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3252, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9532, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1244, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6266, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8731, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0914, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6358, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0543, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1806, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.7031)\n",
      "test  tensor(1.9470)\n",
      "test  tensor(2.8834)\n",
      "test  tensor(3.3171)\n",
      "test  tensor(1.5772)\n",
      "test  tensor(2.9767)\n",
      "test  tensor(3.1268)\n",
      "test  tensor(2.8941)\n",
      "test  tensor(2.8886)\n",
      "test  tensor(3.2557)\n",
      "test  tensor(2.3535)\n",
      "test  tensor(2.3656)\n",
      "test  tensor(2.1794)\n",
      "test  tensor(2.7666)\n",
      "test  tensor(2.6634)\n",
      "test  tensor(3.8288)\n",
      "test  tensor(4.2958)\n",
      "train  tensor(3.8644, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4315, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4796, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8569, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2038, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0765, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8660, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8297, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1209, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1341, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4340, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3362, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1141, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6851, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4628, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5859, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8445, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6968, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3116, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0040, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5705, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9889, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9243, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4817, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7329, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  95%|█████████▌| 95/100 [1:45:06<06:01, 72.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.6077, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9489, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4748, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5785, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4837, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8334, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4556, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3418, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5066, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9233, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6496, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8439, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7476, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4237, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5923, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8298, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3285, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4127, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2547, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7817, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6873, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6314, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2252, grad_fn=<SubBackward0>)\n",
      "test  tensor(5.4132)\n",
      "test  tensor(3.5225)\n",
      "test  tensor(3.6908)\n",
      "test  tensor(3.3566)\n",
      "test  tensor(3.4644)\n",
      "test  tensor(2.5095)\n",
      "test  tensor(6.3781)\n",
      "test  tensor(3.0189)\n",
      "test  tensor(2.8015)\n",
      "test  tensor(4.7407)\n",
      "test  tensor(3.3793)\n",
      "test  tensor(1.6576)\n",
      "test  tensor(2.4880)\n",
      "test  tensor(3.0352)\n",
      "test  tensor(2.1623)\n",
      "test  tensor(2.8322)\n",
      "test  tensor(4.4750)\n",
      "train  tensor(2.4021, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6540, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9086, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7073, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6807, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0475, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9527, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2618, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0945, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7777, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3158, grad_fn=<SubBackward0>)\n",
      "train  tensor(-3.8980, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8451, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9238, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0557, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6056, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6089, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0172, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0423, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0340, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4630, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6017, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9373, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1582, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6968, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9838, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8848, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2462, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5733, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1658, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3430, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3683, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1611, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1089, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1818, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4925, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5065, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  96%|█████████▌| 96/100 [1:46:33<05:07, 76.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(1.3863, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4505, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7373, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7310, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4429, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0030, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5333, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.1277, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4591, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1872, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.0897)\n",
      "test  tensor(2.7816)\n",
      "test  tensor(3.1549)\n",
      "test  tensor(3.2337)\n",
      "test  tensor(2.4546)\n",
      "test  tensor(1.8949)\n",
      "test  tensor(2.8223)\n",
      "test  tensor(2.6713)\n",
      "test  tensor(2.1818)\n",
      "test  tensor(2.6234)\n",
      "test  tensor(2.8918)\n",
      "test  tensor(3.1517)\n",
      "test  tensor(4.5977)\n",
      "test  tensor(1.4660)\n",
      "test  tensor(2.9509)\n",
      "test  tensor(2.8116)\n",
      "test  tensor(2.6722)\n",
      "train  tensor(2.1339, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6879, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8650, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8249, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.3185, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3393, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2519, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1642, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6299, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7802, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6550, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8840, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3408, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4632, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2662, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6040, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3266, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3438, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3601, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5374, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5128, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9297, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1551, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1462, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2225, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8482, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.1363, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2513, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2677, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5417, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1387, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3773, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.3229, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6410, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7874, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6093, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4140, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0733, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7450, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8838, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9251, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6277, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6342, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1425, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9452, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9633, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6130, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5621, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.1960)\n",
      "test  tensor(3.9582)\n",
      "test  tensor(2.6643)\n",
      "test  tensor(3.1116)\n",
      "test  tensor(4.6896)\n",
      "test  tensor(2.3649)\n",
      "test  tensor(3.2722)\n",
      "test  tensor(2.5541)\n",
      "test  tensor(2.6679)\n",
      "test  tensor(3.6799)\n",
      "test  tensor(2.4279)\n",
      "test  tensor(2.6915)\n",
      "test  tensor(4.1759)\n",
      "test  tensor(3.4815)\n",
      "test  tensor(2.6060)\n",
      "test  tensor(3.5867)\n",
      "test  tensor(7.1113)\n",
      "train  tensor(5.5255, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7178, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5478, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6003, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5420, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  97%|█████████▋| 97/100 [1:48:00<03:59, 79.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.7510, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4995, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7503, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3869, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2748, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.8323, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5998, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3020, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6572, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8269, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6454, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0454, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0206, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7796, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7235, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4907, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8637, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7278, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5211, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9068, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.4116, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6101, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3595, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9935, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5583, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3510, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6030, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7998, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1408, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.6601, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5173, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5978, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1455, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7811, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6500, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9655, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7678, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1715, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3469, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9260, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8749, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1443, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9124, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8564, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5582, grad_fn=<SubBackward0>)\n",
      "test  tensor(1.5210)\n",
      "test  tensor(2.5236)\n",
      "test  tensor(1.3710)\n",
      "test  tensor(3.1273)\n",
      "test  tensor(5.7154)\n",
      "test  tensor(3.2532)\n",
      "test  tensor(3.0725)\n",
      "test  tensor(2.9465)\n",
      "test  tensor(2.7378)\n",
      "test  tensor(1.3670)\n",
      "test  tensor(3.4272)\n",
      "test  tensor(3.4132)\n",
      "test  tensor(2.7221)\n",
      "test  tensor(1.4199)\n",
      "test  tensor(3.3402)\n",
      "test  tensor(4.6569)\n",
      "test  tensor(6.2590)\n",
      "train  tensor(1.9786, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4887, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6003, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6463, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4039, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7754, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2562, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1885, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9003, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0312, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6719, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0801, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9600, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2559, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.2030, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4335, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5784, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5726, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9230, grad_fn=<SubBackward0>)\n",
      "train  tensor(6.5265, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  98%|█████████▊| 98/100 [1:49:26<02:43, 81.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(2.1809, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6436, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.5945, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3429, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0022, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2947, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.7272, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5802, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2276, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9318, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4504, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6705, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3344, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6543, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7940, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7040, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2209, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7358, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8206, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5852, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0009, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4699, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1915, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3792, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5567, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9772, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0306, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8597, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7478, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8273, grad_fn=<SubBackward0>)\n",
      "test  tensor(3.4512)\n",
      "test  tensor(2.2553)\n",
      "test  tensor(1.9552)\n",
      "test  tensor(2.4243)\n",
      "test  tensor(2.4517)\n",
      "test  tensor(4.0151)\n",
      "test  tensor(2.3834)\n",
      "test  tensor(2.4485)\n",
      "test  tensor(2.9322)\n",
      "test  tensor(2.4302)\n",
      "test  tensor(1.7022)\n",
      "test  tensor(2.5759)\n",
      "test  tensor(2.3716)\n",
      "test  tensor(3.2129)\n",
      "test  tensor(3.1475)\n",
      "test  tensor(1.4966)\n",
      "test  tensor(0.9229)\n",
      "train  tensor(2.5094, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.8417, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7217, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.0144, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6490, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2674, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9719, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9831, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3433, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9517, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9043, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3893, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.3847, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0090, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3605, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4094, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2364, grad_fn=<SubBackward0>)\n",
      "train  tensor(-0.0094, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2349, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8051, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3933, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9739, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2891, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9142, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1356, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3335, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.0200, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4857, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7881, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8676, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3735, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9343, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8418, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0600, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9910, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:  99%|█████████▉| 99/100 [1:51:04<01:26, 86.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  tensor(3.8406, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1415, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7348, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.8233, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2883, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.6996, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4016, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.7846, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3033, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2163, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4643, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0896, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8605, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3376, grad_fn=<SubBackward0>)\n",
      "test  tensor(4.5507)\n",
      "test  tensor(2.4138)\n",
      "test  tensor(2.9915)\n",
      "test  tensor(3.3604)\n",
      "test  tensor(4.3452)\n",
      "test  tensor(3.2403)\n",
      "test  tensor(2.3274)\n",
      "test  tensor(2.7441)\n",
      "test  tensor(3.6690)\n",
      "test  tensor(2.5150)\n",
      "test  tensor(3.5307)\n",
      "test  tensor(3.5343)\n",
      "test  tensor(2.7162)\n",
      "test  tensor(2.9786)\n",
      "test  tensor(1.7448)\n",
      "test  tensor(4.1076)\n",
      "test  tensor(8.9062)\n",
      "train  tensor(2.3151, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.9407, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6394, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2466, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3889, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.1769, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8352, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3961, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4527, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5112, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1647, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9560, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.2117, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4747, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.9278, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2036, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.2680, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.5620, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.8056, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.5673, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4633, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.3204, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6955, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9462, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.7045, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0611, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.4340, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.5742, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.8661, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.1714, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.0880, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0434, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9515, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.4808, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.5765, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9432, grad_fn=<SubBackward0>)\n",
      "train  tensor(0.9290, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6874, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.0782, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.1573, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4526, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.4449, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.9151, grad_fn=<SubBackward0>)\n",
      "train  tensor(4.2351, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.6984, grad_fn=<SubBackward0>)\n",
      "train  tensor(3.3929, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7429, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.7440, grad_fn=<SubBackward0>)\n",
      "train  tensor(2.9155, grad_fn=<SubBackward0>)\n",
      "train  tensor(1.6453, grad_fn=<SubBackward0>)\n",
      "test  tensor(2.3459)\n",
      "test  tensor(3.2201)\n",
      "test  tensor(3.0496)\n",
      "test  tensor(-1.8067)\n",
      "test  tensor(3.0612)\n",
      "test  tensor(3.0436)\n",
      "test  tensor(2.1042)\n",
      "test  tensor(3.6502)\n",
      "test  tensor(1.6803)\n",
      "test  tensor(2.6227)\n",
      "test  tensor(1.5146)\n",
      "test  tensor(2.7308)\n",
      "test  tensor(2.2073)\n",
      "test  tensor(2.4970)\n",
      "test  tensor(3.1233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 100/100 [1:52:48<00:00, 67.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  tensor(3.2963)\n",
      "test  tensor(0.4764)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MyDataset(X=inputs_ecg,Y=outputs1,labels=torch.tensor(labels))\n",
    "batch_size = 64\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for the training and testing sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model =  MINE(zd_dim=32)\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "epochs = 100\n",
    "mi_est_values = []\n",
    "test_mi_est_values = []\n",
    "test_mean_mi_est_values = []\n",
    "step = 0\n",
    "for epoch in tqdm(range(epochs), 'epoch'):\n",
    "            # rho = mi_to_rho(mi_value, sample_dim)\n",
    "            for batch_x, batch_y, batch_label in train_loader:\n",
    "                # print(batch_x.shape)\n",
    "                # print(batch_y.shape)\n",
    "            # for step in tqdm(range(training_steps), 'Training Loop', position=0, leave=True):\n",
    "            #     batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size=batch_size,\n",
    "            #                                                     to_cuda=torch.cuda.is_available(), cubic=cubic)\n",
    "                # batch_x = torch.tensor(batch_x).float().to(device)\n",
    "                # batch_y = torch.tensor(batch_y).float().to(device)\n",
    "                model.eval()\n",
    "                mi_est, _, _ = model(batch_x, batch_y, batch_label)\n",
    "                mi_est_values.append(mi_est.item())\n",
    "                print('train ', mi_est)\n",
    "                model.train()\n",
    "\n",
    "                model_loss = model.learning_loss(batch_x, batch_y, batch_label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                model_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                del batch_x, batch_y, batch_label\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    step = 0\n",
    "                    with torch.no_grad():\n",
    "                        s = 0.\n",
    "                        n = 0\n",
    "                        for batch_x, batch_y, batch_label in test_loader:\n",
    "                            n += 1\n",
    "                            model.eval()\n",
    "                            mi_est, _, _ = model(batch_x, batch_y, batch_label)\n",
    "                            s += mi_est\n",
    "                            print('test ', mi_est )\n",
    "                            test_mi_est_values.append(mi_est.item())\n",
    "                        \n",
    "                        test_mean_mi_est_values.append(s/n)\n",
    "                    del batch_x, batch_y, batch_label\n",
    "\n",
    "            #print(\"finish training for %s with true MI value = %f\" % (model.__class__.__name__, mi_value))\n",
    "            # torch.save(model.state_dict(), \"./model/%s_%d.pt\" % (model.__class__.__name__, int(mi_value)))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        # end_time = time.time()\n",
    "        # time_cost = end_time - start_time\n",
    "        # print(\"model %s average time cost is %f s\" % (model_name, time_cost / total_steps))\n",
    "        # mi_results[model_name] = mi_est_values\n",
    "        # plt.plot(mi_est_values)\n",
    "        # plt.plot(test_mi_est_values)\n",
    "plt.plot(test_mean_mi_est_values,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLUB(nn.Module):  # CLUB: Mutual Information Contrastive Learning Upper Bound\n",
    "    '''\n",
    "        This class provides the CLUB estimation to I(X,Y)\n",
    "        Method:\n",
    "            forward() :      provides the estimation with input samples\n",
    "            loglikeli() :   provides the log-likelihood of the approximation q(Y|X) with input samples\n",
    "        Arguments:\n",
    "            zc_dim, zd_dim :         the dimensions of samples from X, Y respectively\n",
    "            hidden_size :          the dimension of the hidden layer of the approximation network q(Y|X)\n",
    "            z_c, z_d : samples from X and Y, having shape [sample_size, zc_dim/zd_dim]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, zc_dim, zd_dim): # args,\n",
    "        super(CLUB, self).__init__()\n",
    "        self.use_tanh = False\n",
    "        # self.p_mu = FF(args, zc_dim, zc_dim, zd_dim)\n",
    "        # self.p_logvar = FF(args, zc_dim, zc_dim, zd_dim)\n",
    "        self.p_mu = nn.Sequential(nn.Linear(zc_dim, zd_dim),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(zd_dim, zd_dim),\n",
    "                                    )\n",
    "        self.p_logvar = nn.Sequential(nn.Linear(zc_dim, zd_dim),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(zd_dim, zd_dim),\n",
    "                                      nn.Tanh())\n",
    "\n",
    "    def get_mu_logvar(self, z_c):\n",
    "        mu = self.p_mu(z_c)\n",
    "        logvar = self.p_logvar(z_c)\n",
    "        if self.use_tanh:\n",
    "            logvar = logvar.tanh()\n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, z_c, z_d):\n",
    "        mu, logvar = self.get_mu_logvar(z_c)\n",
    "\n",
    "        # log of conditional probability of positive sample pairs\n",
    "        positive = - (mu - z_d) ** 2 / 2. / logvar.exp()\n",
    "\n",
    "        prediction_1 = mu.unsqueeze(1)  # shape [nsample,1,dim]\n",
    "        z_d_1 = z_d.unsqueeze(0)  # shape [1,nsample,dim]\n",
    "\n",
    "        # log of conditional probability of negative sample pairs\n",
    "        negative = - ((z_d_1 - prediction_1) ** 2).mean(dim=1) / 2. / logvar.exp()\n",
    "        mi = (positive.sum(-1) - negative.sum(-1)).mean()\n",
    "        return mi, 0., 0.\n",
    "\n",
    "    def learning_loss(self, z_c, z_d):  # unnormalized loglikelihood\n",
    "        mu, logvar = self.get_mu_logvar(z_c)\n",
    "        return -(-(mu - z_d) ** 2 / logvar.exp() - logvar).sum(1).mean(0)\n",
    "\n",
    "    def I(self, *args, **kwargs):\n",
    "        return self.forward(*args[:2], **kwargs)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClub(nn.Module):\n",
    "    def __init__(self,zc_dim, zd_dim, sample=False, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = ConvNet()\n",
    "        if sample:\n",
    "            # self.club = CLUBSample(x_dim=x_dim, y_dim=y_dim, hidden_size=32)\n",
    "            self.club = CLUB(zc_dim=zc_dim, zd_dim=zd_dim)\n",
    "        else:\n",
    "            self.club = CLUB(zc_dim=zc_dim, zd_dim=zd_dim)\n",
    "\n",
    "    def get_mu_logvar(self, z_c):\n",
    "        z_c = self.conv(z_c)\n",
    "        return self.club.get_mu_logvar(z_c)\n",
    "\n",
    "    def forward(self, z_c, z_d):\n",
    "        mu, logvar = self.get_mu_logvar(z_c)\n",
    "\n",
    "        # log of conditional probability of positive sample pairs\n",
    "        positive = - (mu - z_d) ** 2 / 2. / logvar.exp()\n",
    "\n",
    "        prediction_1 = mu.unsqueeze(1)  # shape [nsample,1,dim]\n",
    "        z_d_1 = z_d.unsqueeze(0)  # shape [1,nsample,dim]\n",
    "\n",
    "        # log of conditional probability of negative sample pairs\n",
    "        negative = - ((z_d_1 - prediction_1) ** 2).mean(dim=1) / 2. / logvar.exp()\n",
    "        mi = (positive.sum(-1) - negative.sum(-1)).mean()\n",
    "        return mi, 0., 0.\n",
    "\n",
    "    def learning_loss(self, z_c, z_d):  # unnormalized loglikelihood\n",
    "        mu, logvar = self.get_mu_logvar(z_c)\n",
    "        return -(-(mu - z_d) ** 2 / logvar.exp() - logvar).sum(1).mean(0)\n",
    "\n",
    "    def I(self, *args, **kwargs):\n",
    "        return self.forward(*args[:2], **kwargs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_to_mi(rho, dim):\n",
    "    result = -dim / 2 * np.log(1 - rho ** 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def mi_to_rho(mi, dim):\n",
    "    result = np.sqrt(1 - np.exp(-2 * mi / dim))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myknife import MyKNIFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cubic=True):\n",
    "    # import os\n",
    "    # os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "    #for seed in [1, 2 ,3, 4, 5, 6, 7, 8]:\n",
    "    # set_seed(seed)\n",
    "    lambda_ = 2\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    # suffix = '9.07_{}_{}_{}'.format(cubic, lambda_, seed)\n",
    "    suffix = \"test\"\n",
    "    # sample_dim = 20\n",
    "    batch_size = 64\n",
    "    # hidden_size = 15\n",
    "    learning_rate = 0.001\n",
    "    training_steps = 50_000\n",
    "    model_list =  [\"MyKnife\"]# [\"MyClub\"]  #\"TUBA\", \"KNIFE\" # CLUBSample\n",
    "\n",
    "    mi_list = [2.0] #, 4.0, 6.0, 8.0, 10.0]  # , 12.0, 14.0, 16.0, 18.0, 20.0]\n",
    "\n",
    "    total_steps = training_steps * len(mi_list)\n",
    "    \n",
    "    dataset = MyDataset(X=inputs_ecg,Y=outputs1,labels=torch.tensor(labels))\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # Create DataLoaders for the training and testing sets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_iter = iter(test_loader)\n",
    "    # train MI estimators with samples\n",
    "\n",
    "    # train MI estimators with samples\n",
    "\n",
    "    mi_results = dict()\n",
    "    for model_name in tqdm(model_list, 'Models'):\n",
    "        if model_name == \"MyClub\":\n",
    "            model = MyClub(zc_dim=32,zd_dim=32)\n",
    "            model.conv = convnet\n",
    "        if model_name == \"MyKnife\":\n",
    "            model = MyKNIFE(32,4)\n",
    "            model.kernel_marg = copy.deepcopy(convnet)\n",
    "            model.kernel_cond = copy.deepcopy(convnet)\n",
    "        # elif model_name == 'Kernel_F':\n",
    "        #     model = MIKernelEstimator(device, sample_dim // 2, sample_dim).to(device)\n",
    "        # elif model_name == 'KNIFE':\n",
    "        #     model = MIKernelEstimator(device, batch_size // 6, sample_dim, sample_dim, use_joint=True).to(device)\n",
    "        # elif model_name == 'DOE':\n",
    "        #     model = eval(model_name)(sample_dim, sample_dim).to(device)\n",
    "        # else:\n",
    "        #     model = eval(model_name)(sample_dim, sample_dim, hidden_size).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "        mi_est_values = []\n",
    "        test_mi_est_values = []\n",
    "        test_mean_mi_est_values = []\n",
    "        step = 0\n",
    "        start_time = time.time()\n",
    "        epochs = 60\n",
    "        for epoch in tqdm(range(epochs), 'epoch'):\n",
    "            # rho = mi_to_rho(mi_value, sample_dim)\n",
    "            for batch_x, batch_y, batch_label in train_loader:\n",
    "                # print(batch_x.shape)\n",
    "                # print(batch_y.shape)\n",
    "            # for step in tqdm(range(training_steps), 'Training Loop', position=0, leave=True):\n",
    "            #     batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size=batch_size,\n",
    "            #                                                     to_cuda=torch.cuda.is_available(), cubic=cubic)\n",
    "                # batch_x = torch.tensor(batch_x).float().to(device)\n",
    "                # batch_y = torch.tensor(batch_y).float().to(device)\n",
    "                model.eval()\n",
    "                mi_est, _, _ = model(batch_x, batch_y, batch_label)\n",
    "                mi_est_values.append(mi_est.item())\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                model_loss = model.learning_loss(batch_x, batch_y, batch_label)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                model_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                del batch_x, batch_y, batch_label\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                step += 1\n",
    "                if step % 50 == 0:\n",
    "                    step = 0\n",
    "                    with torch.no_grad():\n",
    "                        s = 0.\n",
    "                        n = 0\n",
    "                        for batch_x, batch_y, batch_label in test_loader:\n",
    "                            n += 1\n",
    "                            model.eval()\n",
    "                            mi_est, _, _ = model(batch_x, batch_y, batch_label)\n",
    "                            s += mi_est\n",
    "                            test_mi_est_values.append(mi_est.item())\n",
    "                        test_mean_mi_est_values.append(s/n)\n",
    "                    del batch_x, batch_y, batch_label\n",
    "\n",
    "            #print(\"finish training for %s with true MI value = %f\" % (model.__class__.__name__, mi_value))\n",
    "            # torch.save(model.state_dict(), \"./model/%s_%d.pt\" % (model.__class__.__name__, int(mi_value)))\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        end_time = time.time()\n",
    "        time_cost = end_time - start_time\n",
    "        print(\"model %s average time cost is %f s\" % (model_name, time_cost / total_steps))\n",
    "        mi_results[model_name] = mi_est_values\n",
    "        # plt.plot(mi_est_values)\n",
    "        # plt.plot(test_mi_est_values)\n",
    "        plt.plot(test_mean_mi_est_values,color='r')\n",
    "        plt.show()\n",
    "\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "\n",
    "    colors = sns.color_palette()\n",
    "\n",
    "    EMA_SPAN = 200\n",
    "\n",
    "    ncols = len(model_list)\n",
    "    nrows = 1\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(3.1 * ncols, 3.4 * nrows))\n",
    "    axs = np.ravel(axs)\n",
    "\n",
    "    xaxis = np.array(list(range(total_steps)))\n",
    "    yaxis_mi = np.repeat(mi_list, training_steps)\n",
    "\n",
    "    for i, model_name in enumerate(model_list):\n",
    "        plt.sca(axs[i])\n",
    "        p1 = plt.plot(mi_results[model_name], alpha=0.4, color=colors[0])[0]  # color = 5 or 0\n",
    "        plt.locator_params(axis='y', nbins=5)\n",
    "        plt.locator_params(axis='x', nbins=4)\n",
    "        mis_smooth = pd.Series(mi_results[model_name]).ewm(span=EMA_SPAN).mean()\n",
    "\n",
    "        if i == 0:\n",
    "            plt.plot(mis_smooth, c=p1.get_color(), label='$\\\\hat{I}$')\n",
    "            plt.plot(yaxis_mi, color='k', label='True')\n",
    "            plt.xlabel('Steps', fontsize=25)\n",
    "            plt.ylabel('MI', fontsize=25)\n",
    "            plt.legend(loc='upper left', prop={'size': 15})\n",
    "        else:\n",
    "            plt.plot(mis_smooth, c=p1.get_color())\n",
    "            plt.yticks([])\n",
    "            plt.plot(yaxis_mi, color='k')\n",
    "            plt.xlabel('Steps', fontsize=25)\n",
    "\n",
    "        # plt.ylim(0, 15.5)\n",
    "        plt.xlim(0, total_steps)\n",
    "        plt.title(model_name, fontsize=35)\n",
    "        import matplotlib.ticker as ticker\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "        plt.xticks(horizontalalignment=\"right\")\n",
    "        # plt.subplots_adjust( )\n",
    "\n",
    "    plt.gcf().tight_layout()\n",
    "    # plt.savefig('mi_est_Gaussian_{}_copy.pdf'.format(suffix), bbox_inches=None)\n",
    "    # plt.show()\n",
    "\n",
    "    print('Second part')\n",
    "\n",
    "    bias_dict = dict()\n",
    "    var_dict = dict()\n",
    "    mse_dict = dict()\n",
    "    for i, model_name in tqdm(enumerate(model_list)):\n",
    "        bias_list = []\n",
    "        var_list = []\n",
    "        mse_list = []\n",
    "        for j in range(len(mi_list)):\n",
    "            mi_est_values = mi_results[model_name][training_steps * (j + 1) - 500:training_steps * (j + 1)]\n",
    "            est_mean = np.mean(mi_est_values)\n",
    "            bias_list.append(np.abs(mi_list[j] - est_mean))\n",
    "            var_list.append(np.var(mi_est_values))\n",
    "            mse_list.append(bias_list[j] ** 2 + var_list[j])\n",
    "        bias_dict[model_name] = bias_list\n",
    "        var_dict[model_name] = var_list\n",
    "        mse_dict[model_name] = mse_list\n",
    "\n",
    "    # %%\n",
    "\n",
    "    plt.style.use('default')  # ('seaborn-notebook')\n",
    "\n",
    "    colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "    col_idx = [2, 4, 5, 1, 3, 0, 6, 7]\n",
    "\n",
    "    ncols = 1\n",
    "    nrows = 3\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(4.5 * ncols, 3. * nrows))\n",
    "    axs = np.ravel(axs)\n",
    "\n",
    "    for i, model_name in enumerate(model_list):\n",
    "        plt.sca(axs[0])\n",
    "        plt.plot(mi_list, bias_dict[model_name], label=model_name, marker='d', color=colors[col_idx[i]][\"color\"])\n",
    "\n",
    "        plt.sca(axs[1])\n",
    "        plt.plot(mi_list, var_dict[model_name], label=model_name, marker='d', color=colors[col_idx[i]][\"color\"])\n",
    "\n",
    "        plt.sca(axs[2])\n",
    "        plt.plot(mi_list, mse_dict[model_name], label=model_name, marker='d', color=colors[col_idx[i]][\"color\"])\n",
    "\n",
    "    ylabels = ['Bias', 'Variance', 'MSE']\n",
    "    for i in range(3):\n",
    "        plt.sca(axs[i])\n",
    "        plt.ylabel(ylabels[i], fontsize=15)\n",
    "\n",
    "        if i == 0:\n",
    "            if cubic:\n",
    "                plt.title('Cubic', fontsize=17)\n",
    "            else:\n",
    "                plt.title('Gaussian', fontsize=17)\n",
    "        if i == 1:\n",
    "            plt.yscale('log')\n",
    "        if i == 2:\n",
    "            plt.legend(loc='upper left', prop={'size': 12})\n",
    "            plt.xlabel('MI Values', fontsize=15)\n",
    "\n",
    "    plt.gcf().tight_layout()\n",
    "    # plt.savefig('bias_variance_Gaussian_{}.pdf'.format(suffix), bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100%|██████████| 60/60 [2:17:35<00:00, 137.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MyKnife average time cost is 0.165101 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 1/1 [2:17:35<00:00, 8255.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3747: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "1it [00:00, 124.96it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAFKCAYAAACn0GIyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1L0lEQVR4nO3de1wUVf8H8M+yC8tycRFBFpQEFRQveUH0pSniDbUssUwfb3ipvEE9ZOUvHy1NfbSszHpMLfNKZlr55CVNMRFTs1BBDc0rKIaEKMIidzi/P3yYGHbZG7OX2f2+X699uTN75sx3B/kyc+bMORLGGAMhhIiAk7UDIIQQQ1HCIoSIBiUsQohoUMIihIgGJSxCiGhQwiKEiAYlLEKIaFDCIoSIBiUsQohoUMIixEqOHj0KiUTCe2VlZRldT1lZGTZu3Ihx48YhNDQU3t7ekEqlvHpjYmIEj98aZNYOgBBiugMHDmDKlCnIy8uzdigWQWdYFqTtL2rtSy6X4969e43ex5UrVxrch6l/wc1typQpgsa5cOFCrd99woQJqKqqEi5wK9u7dy9GjBjhMMkKoDMsm1FRUYGvvvoKL7/8cqPq2bhxo0ARiQ9jDK+88gpWr16t8Vl8fDw++eQTSCQSK0QmPLVajalTp6Kmpoa3vlmzZujSpQu8vLx437Vnz56WDtEsKGHZkI0bNzYqYVVXVyMxMVHAiMSjqqoKU6dOxZdffqnx2VtvvYXFixdbISrzSUxM1DgjX7FiBRISEuDs7GylqMyPEpYNSU9PR3p6Orp27WrS9gcOHEBOTo6wQYlAWVkZxowZg7179/LWSyQSrFq1Cq+88oqVItMtKioKpo7utGfPHt7y0KFD8cYbbwgRlk2jNiwrCwgI4C1v2rTJ5LrqXw7Wr9seqdVqDBs2TCNZyWQybNmyxWaTVWOdPn2atzxixAgrRWJZlLCsbNKkSbzlbdu2oaKiwuh67t69i3379nHLcrkcY8eObXR8tiw/Px8DBgxASkoKb72rqyu+++47jWNrL0pLSzUuB1u3bm2laCyLEpaVderUCREREdzyvXv3NE73DZGYmIjKykpueeTIkfD29hYkRluUnZ2Nfv364cyZM7z1TZo0wY8//ohnnnnGSpGZX2FhocY6Nzc3K0RieZSwbMDUqVN5y6ZcFtbfpn6d9uTKlSvo27cv/vjjD956X19fJCcno3///laKzDLKysqsHYLVUKO7DRg/fjxee+01lJaWAgAOHjyInJwcg9ugfvvtN/z+++/ccsuWLREdHa3RzmEP0tLSMGzYMI2+R4GBgUhKSkK7du3Msl+1Wo2TJ0/i6tWrKCwshIeHB3x9fdGjRw+EhoaaZZ/WUllZidTUVGRnZ+Pu3bsoKiqCt7c3fH190aVLF7Rt29Z6wTFiMcnJyQwA75WYmMgYY2z8+PG89cuXLze43hkzZvC2nT9/PmOMsSVLlmjsLzMzU2P7VatWaZRLS0tr1HedNm0arz53d3dWWFiotezkyZMNivPYsWNMqVRqlG3fvj27deuWSXFq+5nU3XdGRgb7xz/+wVxcXDTK1b5at27N1q9fz6qqqgTdt65yxrwWLlxoUDz79u1jI0aMYB4eHjrrCwoKYvPmzWP379836vsKgRKWBelKWElJSbz1oaGhBtVZUlKi8Ut89epVxpjhCevBgwca/0lnzJhh8vd88OABc3Nz49X30ksvNVjekIT1ww8/MIVCoVEuPDyc3b171+RYdSWNFStWMGdnZ4MTQ1RUVINJ2dh96ysnZMJKS0tjffr0MbpepVLJNmzYYMTRbjxqw7IRgwYNQqtWrbjlK1eu4MSJE3q3++6773iNsJGRkUafsiuVSkycOJG3btu2bVCr1UbVU2vr1q0oKSnhrZs1a5ZJdQHA9u3bERMTw10y14qKikJycjJ8fHxMrrshr732GubOncu7kaHP0aNH8eSTT6K6ulrweMzlv//9L5544gmcPHnS6G0LCwvxwgsvWLT/F7Vh2QiJRILJkyfzemRv2rQJTzzxhM7t6ve9MrWxPS4uDuvWreOWi4uL8eWXX5qUaOrWAwC9evVCt27dTIpr7dq1iI+P13gEZeTIkdixYwfkcrlJ9eqybt06rFy5klvu1asXYmJi0L17d/j4+ODhw4e4dOkStm/fjqNHj/K2PXHiBFauXCnoL7Gvry+ee+45brmkpAQHDhzglYmMjISvr6/W7Tt06KB1/TfffIOxY8dqdF4NDAzE6NGj0atXL7Ro0QIeHh548OABLl68iB9++AEHDhzgbfPBBx+gRYsWSEhIMPEbGsGi53MOTtclIWOMZWZmMolEwn3m6enJiouLG6zvxo0bOssbeklYq3///ryynTt3Nvo7pqSkaOxz8+bNOrdp6JJw6dKlWi9FJk+ebHR7UUO0/Uxqj6m3tzfbs2ePzu3Xr1/PnJyceNv7+Piw8vJyk/at6+dTKzMzU2O75ORkA7/xI5cvX2aenp4al3hffPGF3mN7+vRp1rZtW962zs7O7MyZM0bFYAq6JLQhQUFBGDBgALesVqvx7bffNlh+06ZNvL90Y8aMgbu7u8n7j4uL4y1fuHDBoMvSutauXctb9vb2NqkD65tvvokFCxZorE9ISMCmTZsglUqNrtNQjDF4eXnhxIkTePrpp3WWffHFF/H666/z1uXn52P37t1mi08IU6dO5V3yN2/eHCdPnsQLL7yg99iGh4fjl19+4XVWraystMjzmpSwbIyhfbJqamqwZcsWndsaa9SoUWjRogVvXf3LO13u3r2LXbt28dZNnjwZrq6uRseyY8cOjXWLFy/GRx99ZJERF9auXYv27dsbVHbevHkal6bHjh0zR1iCOHr0qEabVWJiYoOXjtr4+Phg8+bNvHV79uzBlStXhAixQZSwbMxzzz0HpVLJLR87dgzXr1/XKHf48GHcunWLWw4NDdXb3qWPTCbD9OnTeeu++eYbg8fp2rhxI++xIolEgpkzZzYqplohISGYM2eOIHXpExYWZtRZoZeXFwYOHMhbV78Hvi2p2z4HAEOGDEF0dLTR9fTr14/3lAZjTKNtTWiUsGyMQqHg/bIwxjT+kgHCNbbXN336dN7wJOXl5Qb1vGeM4fPPP+etGzhwoGCdKq9evYonn3wSxcXFgtSny5gxY4w+i6s/wkZ2draAEQmnsrISP/30E2/dhAkTTK5v0KBBvOX6z3UKjRKWDZo2bRpvecuWLby7ZAUFBfj++++5ZalUitjYWEH2rVKpeHekAOCzzz7TOwzKwYMHcePGDd66xnRlmDx5ssa6Y8eOYfjw4WZPWr179zZ6G5VKxVvW9ryfLUhNTdXoctKjRw+T62vZsiVv+dKlSybXZQhKWDaoV69evPaE7OxsHD58mFvetm0bysvLueVhw4YJOpRMfHw8b/natWtISkrSuU39xnZ/f3+MHDnS5BgWLVqEt99+W2P98ePHMWzYMJP7iBmifvIxhKenJ2/ZEmeCpjh79qzGuk6dOukcVlvXq/7/lfv375s1fkpYNkpX47u5LgdrPfHEExqXOLoa32/fvo0ffviBt+6ll16CTNa4bn7vvPMOFi1apLH+xIkTGDp0KIqKihpVf0OaNGli9Db1LyH1nZFaS35+vlnrp4TloGJjY3m/8N9//z0KCgpw7tw5pKWlcet9fHz03no3Rf0uDnv37sWff/6ptez69et5vbulUileeuklQeJYuHAhlixZorH+l19+MVvSspdx37Uxd0Ix9yQf1NPdRjVv3hxPPvkkNzZWWVkZtm/frjGkyoQJE+Di4iL4/sePH4+5c+eioKAAwKP/iF988QUWLlzIK1e7vq4RI0ZotG00xoIFC+Dk5IT58+fz1p86dQpDhgzBoUOHeHdWScPqNiUAj/64iGnOQkpYNmzatGm8wfzWr1+vcfepfgO9UNzc3DB16lTeLfD169dj/vz5vDO/PXv2aIwj35jG9ob861//gpOTE+bNm8db/9tvv3FJy8vLS/D92pv6gzpWV1djy5YtjepwbEl0SWjDnnrqKfj5+XHL6enpvD5R4eHhePzxx822/9mzZ/Muj/7880+NsdPrN7a3bt3apD49hnjzzTexYsUKjfWpqakYMmQIdzZIGqbtecP6d3dtGSUsGyaTyTRGUajL3KOKtmnTBsOGDeOtq9v4fu3aNY0+PTNnzjRrG9Abb7yBDz74QGP96dOnMXjwYEpaemgb4NDcfaeERAnLxjV0ySeXyzF+/Hiz779+43tSUhLX875+/yy5XG6RoZlfe+01jd7awKNb9oMGDTJ7w7KY9e/fX2PeQlt/7rEuSlg2rkOHDlpn7Y2JiUHTpk3Nvv/hw4fzHnJljOGzzz7T2gP++eefN8vYVNq8+uqr+PjjjzXWp6WlYdCgQQY/TuRoPDw8NB7hOnz4MFJTU60UkXGo0V0EEhMTNdoZOnbsaJF9Ozk5YdasWbzxnTZt2oTQ0FCNpCDUc4OGeuWVV+Dk5KQxW3Z6ejoGDhyIn376yWIJVExee+01jXG84uPjcezYMbOMLyYkOsMSgdDQUAwbNoz3CgwMtNj+X3jhBSgUCm45Pz8fr776Kq9M586dG/3wtSni4+Px6aefarSbnT9/HgMHDsTdu3ctHpOtGzFiBHr16sVb99tvv2HSpEkmz8hTVlam0b3FHChhEb2aNm2q0V5W/9ETc3RlMNTs2bOxZs0ajaR14cIFDBw4UGOGHfLoaYn6Pfq/+eYb9O7dGz///LPB9Vy4cAFvvfUWWrVqZZEzbLokJAaJi4vDhg0btH7m4eGh826mJcycORNOTk6YOXMm70bA77//joEDB+LIkSNo3ry5FSO0LR06dMDXX3+Np59+mveUQnp6OiIjIxEeHo7o6GhERETA19cXHh4eKC4uxoMHD3D9+nWkpaVx057VMuegirUoYRGDdOvWDX369NE6WcHEiRM1Hv61hunTp8PJyQnTp0/nJa2MjAxuwoq6/doc3fDhw3Hw4EGMGzdO49L5zJkzNjmmF10SEoPV7+JQy9KN7bq8+OKL2LBhA5yc+P+1L126hKioKOTm5lopMts0aNAgpKWl4dlnn21U/zmFQoFx48YJGJl2lLCIwUaPHq1xF6l3797o0qWLlSLSburUqVqT1h9//IGoqCiNR4kcXYsWLfDdd98hIyMDM2fORHBwsEHbBQQEYNKkSUhMTMRff/2FxMREM0cKSJitjoNBbM6RI0c0RpjcunUrJk2aZKWIiLncunUL586dQ35+Pu7du4fy8nJ4enqiSZMmCA4ORvv27a1yeU0Jixhs7Nix2LlzJ7fcrFkz3L5926RJJggxBV0SEoPcuXMH//3vf3nrpk6dSsmKWBQlLGKQDz74gDdtu5OTU4ON8ISYCyUsote1a9ewZs0a3rqYmBgEBQVZJyDisChhEZ3Onj2LZ555hvfIhpOTk9ax1gkxN+o4SjgZGRncEMjl5eXIzMzExYsXNSZUmDZtGjp37myNEImDo7uEhHP06FEMGDBAZ5nWrVsjLS3NpJllCGksuiQkBuvQoQMOHz5MyYpYDV0SGqmmpgY5OTnw9PS0u+mgHj58yFuWyWRo2rQpOnXqhJEjR2L8+PGQy+Vmmw+QOCbGGNRqNQICAjSeTqiPLgmNdPv2bYuORUWIo8jOztY7PRydYRmpdlSC7OxsujQiRABFRUUIDAw0aMQPSlhGqr0MbNKkCSUsQgRkSBMLNboTQkSDEhYhRDQoYRFCRMOuEtby5csREREBT09PNG/eHDExMbh8+TKvDGMMixYtQkBAABQKBaKiopCRkWGliAkhxrCrhJWSkoK4uDicOnUKSUlJqKqqQnR0NK9/0YoVK7By5UqsXr0aqampUKlUGDJkCNRqtRUjJ4QYhNmxvLw8BoClpKQwxhirqalhKpWKvfvuu1yZsrIyplQq2bp16wyqs7CwkAFgFzJzzBIzIY6m9neqsLBQb1m77tZQWFgIAPD29gYAZGZmIjc3F9HR0VwZuVyO/v374+TJk5gxY4ZGHeXl5SgvL+eWa3t5n7pxH52C/A2OhTGGyspK1NTUmPRdiG2QyWSQyez618am2e2RZ4xhzpw56Nu3Lzp16gQA3Iwp9cei9vPzw82bN7XWs3z5crzzzjsmx1FdXY38/Hyo1WreAHhEvNzd3eHj4wM3Nzdrh+Jw7DZhxcfH4/z58zh+/LjGZ/U7qDHGGuy0Nm/ePMyZM4dbru2Va4jq6mpkZ2ejvLwcSqUSHh4ekEqldvcMoqNgjKG8vBz3799HdnY2goOD4eLiYu2wHIpdJqyXX34Ze/bswbFjx3jPJqlUKgCPzrT8/f++nMvLy2twBhC5XK4xtZWh8vPzUV5ejsceewwKhcKkOohtUSgU8PT0RGZmJvLy8vQ++0aEZVd3CRljiI+Px65du3DkyBGN+dWCg4OhUqmQlJTErauoqEBKSgr69OkjeCxqtRpKpZKSlZ2RSqVQKpUoKSnRGNyQmJddnWHFxcXhq6++wu7du+Hp6cm1WdUmDYlEgoSEBCxbtgwhISEICQnBsmXL4ObmhvHjxwsaS2VlJSorK+Hh4SFovcQ2KBQK5Ofno7Kyki4LLciuEtbatWsBAFFRUbz1mzZtwpQpUwAAc+fORWlpKWbPno2CggL06tULhw4dMuhJcWPU3g2USqWC1ktsQ+3Ple76WpZdJSxDTs8lEgkWLVpksUkUqIHdPtHP1Trsqg2LEGLfKGERi/rxxx8hkUjQsWNH6pdGjEYJi1hMaWkp4uLi0Lt3b2RmZuKDDz6wdkhEZChhEYtZsmQJ1Go1du3ahffeew9LlizBjRs3rB0WERFKWMQiLl68iA8//BBffPEFVCoV4uPjERkZibi4OGuHRkTEru4SEtvVoUMH3kPkEokEP/74oxUjImJEZ1iEENGghEUIEQ1KWMQq4uPjIZFI8O9//9vaoRARoYRFrOLcuXMAgC5dulg5EiImlLCIxTHGcP78eQCUsIhxKGERi8vMzERRURG8vb0NHgyREIASFrECuhwkpqKERSyOEhYxFSUsYnGUsIipKGERi0tPTwdACYsYjx7NsRLGGEorq60dhsEUzsLM9lNUVISsrCzIZDJ07NhRgMiII6GEZSWlldXo8PZBa4dhsIuLh8LNpfH/XWovB8PCwmgsdGI0uiQkFkXtV6Qx6AzLShTOUlxcPNTaYRhM4SzMZBrUfkUagxKWlUgkEkEuscSm9gyra9eu1g2EiBJdEhKLqa6uRkZGBgA6wyKmoYRFLObKlSsoLS2Fv78/fH19rR0OESFKWMRiqMGdNBYlLGIx//jHP8AYw4EDB6wdChEpSliN8PPVu9YOgRCHQgmrEbLvl1o7BEIcCiUsQohoUMIihIgGJSxCiGhQwiKEiAYlLEKIaFDCIoSIBiUsQohoUMIihIgGJSxCiGhQwiKEiAYlLEKIaFDCIoSIBiUsQohoUMIiFiGRSIx6BQUFWTtkYoMcbxYEYhWTJ0/WWHf8+HFcv34dXbp00ZiUwsfHx0KRETGhhEUsYvPmzRrrpkyZguvXryMmJgaLFi2yeExEfOiSkBAiGpSwGikz/6G1Q7A7R48ehUQiwZQpU5Cbm4sXX3wRLVu2hEwmw6pVqwAAUVFRkEgkyMrK0tg+KysLEokEUVFRWuvfu3cvhg4dimbNmsHV1RWhoaF46623UFxcbL4vRQRBl4SN9Mv1ewj2cbd2GHbp7t27iIiIQFVVFfr27YuysjK4ubk1qs7XXnsNK1euhKurK3r27AkfHx+cOXMGS5cuxYEDB5CSkgJ3d/p52ipKWFbCGENJSYm1wzCYm5sbJBKJRfe5f/9+jBo1Cl999RVcXV0bXd/OnTuxcuVKdOvWDbt27eLuRFZWViI+Ph6ff/45Fi1ahPfff7/R+yLmQQnLSkpKSuDh4WHtMAxWXFxs8TMPuVyO//znP4IkKwBYtmwZAGD79u28bhPOzs74+OOPsWfPHnzxxRd477334ORErSW2iH4qxGZ1794dLVq0EKSuvLw8nDt3DmFhYWjXrp3G566urujRowcePHiAq1evCrJPIjw6w7ISNzc3UTXyNrbtyBSPPfaYYHXdvHkTAHDp0iW9l7b5+flakxqxPkpYViKRSKhxVw9TLwVramo01lVXVwMA/P39ER0drXP7Zs2ambRfYn6UsIgoubi4AIDWs9Ts7GyNdS1btgQAqFQqrZ1YiThQGxYRJX9/fwDAlStXND47dOiQxrqWLVuiXbt2OH/+PDIzM80eHzEPSlhElPr37w8A+PDDD3ndQw4fPsx1Lq1vwYIFqK6uxnPPPYfff/9d4/Pr169j48aNZomXCIMSFhGlcePGoV27djh58iTCwsIwevRo9OrVC0OHDsXs2bO1bjNx4kTMnTsXaWlp6Nq1KyIiIjBmzBgMGzYMYWFhaNu2LT755BMLfxNiDEpYRJQUCgV++uknjBs3Dmq1Gvv370dNTQ127NiBuLi4Brd777338NNPP+GZZ57B7du38f333yMtLQ1ubm5444036AzLxkkYY8zaQYhJUVERlEol1v/0O9zcPQEA43tp3n4vKytDZmYmgoODBev4SGwH/XyFU/s7VVhYiCZNmugsa1dnWMeOHcPTTz+NgIAASCQSfP/997zPGWNYtGgRAgICoFAoEBUVhYyMDOsESwgxml0lrIcPH6JLly5YvXq11s9XrFiBlStXYvXq1UhNTYVKpcKQIUOgVqstHCkhxBR21Q9r+PDhGD58uNbPGGNYtWoV5s+fj2effRYAsGXLFvj5+eGrr77CjBkzLBkqIcQEdnWGpUtmZiZyc3N5vZzlcjn69++PkydPNrhdeXk5ioqKeC9CiHU4TMLKzc0FAPj5+fHW+/n5cZ9ps3z5ciiVSu4VGBho1jgJIQ1zmIRVq/6Dr4wxnQ/Dzps3D4WFhdxL22MfhBDLsKs2LF1UKhWAR2datY91AI+GHal/1lWXXC6HXC43e3yEEP0c5gwrODgYKpUKSUlJ3LqKigqkpKSgT58+ZtsvdXOzT/RztQ67OsMqLi7GtWvXuOXMzEykp6fD29sbjz32GBISErBs2TKEhIQgJCQEy5Ytg5ubG8aPHy94LDLZo0NbXl4OhUIheP3EuiorKwEAUqnUypE4FrtKWKdPn8aAAQO45Tlz5gB4NInn5s2bMXfuXJSWlmL27NkoKChAr169cOjQIXh6egoei0wmg7u7O+7fvw9PT0/6j21HGGMoLCyEXC6Hs7OztcNxKPRojpEMfTQHeDRue3Z2NqRSKZRKJRQKBaRSqcUncyDCYIyhsrIShYWFKC4uRosWLfQ+SkL0M+bRHLs6w7I1bm5uCA4ORl5eHgoKCpCfn2/tkIgA5HI5JSsroYRlZi4uLmjZsiX311nb8L1EPKRSKV0GWhElLAuRSCTcsL6EENOYlLCmTZsmdBwaJBIJNmzYYPb9EELEw6SEtXnzZrM2HNf2PqeERQipq1GXhHSDkRBiSSYlrMjISLo1X8elO0UI86c7RoSYm0kJ6+jRowKHIW5ptx5QwiLEAhzmWUJCiPhRwiKEiAYlLEKIaFDCIoSIhkmN7osXLxY6Dq3efvtti+xHCPeKy9HMgwb6I8ScTBqtwcnJySLdGqqrq82+D2NpG60BAML8PdHtsaZWjIwQcbLYRKqMMbO9xCbnQZm1QyDE7jWqp7tEIkFgYCBvjHRH8XHSFcyLCeeWC0srrRgNIY6h0aM1/Pnnn2jXrh1iY2Px7LPPOsxwwIVlVfjkp6t4ZVCItUMhxGGYdEnYv39/AI8uCaurq3H48GHExsZCpVJh2rRpDtMTPreILgMJsSSTElZycjKysrKwZMkStGvXjmt3UqvV2LJlCwYNGoRWrVphwYIFuHz5stAxE0IclMmN7oGBgZg/fz4uXbqEU6dOYdasWWjWrBmXvG7fvo3ly5ejQ4cO6NWrF9asWYP79+8LGTshxMEI0nG0Z8+e+PTTT5GTk4Ndu3YhJiYGzs7OXPI6ffo0Xn75ZQQEBCAmJga7du3ipkkSu8pqGvKYEEsRtKe7s7Mzl5BycnLwn//8Bz179uQSV0VFBfbu3Yvnn38e/v7+iIuLw6lTp4QMweJuF5RaOwRCHIZFpvm6cuUKtmzZgm3btuHWrVt/7/x/nU9DQkLwxx9/mDsMQdR2cgtM2AknuRtmRLZGq2buAIDHvN3QtrkHVEpXK0dJiHhYrOOooUJDQ/Hvf/8bWVlZOHLkCKZMmQJPT0/uzOvq1auinU2mrPLvuG/dL8GRP/KsGA0h9s3iDz8HBQUhKCgIPj4+djFqaXmV7T0+RIi9ssg0X2q1Gjt37sTWrVtx4sQJ7tGb2n+VSqVok1fdM6z6ch6UoqCkAh0DlBaMiBD7ZbaEVVNTgx9//BFbt27F3r17UVb2qJNlbZKSyWSIjo5GbGwsRo4cKdqEVVSmebfzzM0ChLdqiqOX7wIAvN1d4K90jCcACDEnwRNWWloaEhMTsX37duTlPWrPqduu37VrV8TGxmLChAnw9fUVevcWd+SPPAwO8+Otu5yrRnirv0dueFhOl42ECEGQhHXnzh18+eWXSExMREZGBgB+kgoICMCECRMQGxuLjh07CrFLm+EipTEQCbEUkxNWaWkpvvvuO2zduhXJycncXb7aROXm5oZRo0YhNjYWgwcPFu0lX0OauTujoApo7++pvzAhRBAmJawpU6Zg165dePjwIYC/k5REIsGAAQMQGxuL0aNHw93dXbhIbYyz1AmoAqqqDenGxnD2VgFcZVJ0CKDpwAgxlUkJa+vWrZBIJFyiCgsLw6RJkzBx4kS0bNlS0ABtldxZCpQDFQY8mlNUVoU/7qgBgBIWIY3Q6AH8WrVqhY4dO+Ls2bM4e/asUHFBIpFgx44dgtUnNFdnKYBqlFdqb1Avqaji3ht2FkYI0afRje43b97EzZs3hYiFwxiz+TYvudQJQDWyG3iWsFxH/yxCiGlMTlhiHHddSJV1HiWqYQxO9RLsnw/ooWhChGZSwpo8ebLQcYhOW18PXL5fCODR2ZTCRcr7/PztQq3bXb9bjDa+HmaPjxB7ZFLC2rRpk9BxiI6sTv+rnMJSg5PQrzfuU8IixETU69FETnWuAH+5fk9nWUe/fCZEKJSwTFT3psDFO0U6y1K6IkQYlLBMZNv3MAmxT5SwTFS/18X1u8XWCYQQB0IJy0QSSDB3aDtuecPxzAbLllbQaA2ECIESlomcJICXmwtv3b7zOVrL3inkT7j6W+Z9Xk94QohhKGGZSFtH/JN67hbWupZXjONX8wWOiBD7RwnLRLV3CZeN6sxbX11j2D3BB6X2MS8jIZZECUsA7fz+HhPrRr6Bje/U14EQo1lkEgp7dPH4QRRdfjS5hH9FFc5k3AEAHMz3RF6gl97tnZwkqLzSzJwhEiIKJSUlBpe1yESq9qR20kdCiLAMmUiVzrBMFPx4T7i7yrnla3l/Xwq2bW7Ys4L+NEM0IaiqqkJycrJBZSlhmWjCgtUIe+zv2XL+9d8L3Pt59RriGzK+12OCx0WI2Bhz1UKN7iZyqtetYXq/1tx76mNFiHlQwjJR/W5Ygd5u3PvLuWrLBkOIg6CEZaL6QzhL65xypWYVWDocQhwCJSwT6RqtIeveQ4vFQYgjoYRlIlufJIMQe0QJy0Ta0tWwjirufaUB8xUSQoxDCctE9WfJAfjT1j8spzuFhAjNIRPWmjVrEBwcDFdXV4SHh+Pnn382vhItp1jNPf/uCJqnLm9EhIQQbRwuYe3YsQMJCQmYP38+0tLS0K9fPwwfPhy3bt0yqp6KKt2D8m0+mdWIKAkh2jhcwlq5ciVeeOEFvPjiiwgLC8OqVasQGBiItWvXGlWPSinXX4gQIiiHSlgVFRU4c+YMoqOjeeujo6Nx8uRJrduUl5ejqKiI9wIeDZGszeMt/37EgJ4rJ0RYDpWw8vPzUV1dDT8/P956Pz8/5Obmat1m+fLlUCqV3CswMBAAUN1AMmri6sy9f1BCg/QRIiSHSli16vehYow12K9q3rx5KCws5F7Z2dkAAGep9kPXP9SXe//+ocu48hc9pkOIUBwqYfn4+EAqlWqcTeXl5WmcddWSy+Vo0qQJ7wUAPVp5aS3vLucPgEGN74QIx6ESlouLC8LDw5GUlMRbn5SUhD59+hhVl1xm+Mg8dwpLjaqbEKKdw42HNWfOHEyaNAk9evRA79698fnnn+PWrVuYOXOmYPtYMrIT3tr9O7f8nyPXeJ8vfqYjZA1cUhJCGuZwCWvs2LG4d+8eFi9ejDt37qBTp07Yv38/WrVqZVQ9uu7/SZ0kGNk1ALvTtc9T+PaeDCyN6WTU/gghDnZJWGv27NnIyspCeXk5zpw5g8jISKPrYHqmvekW2FTn59+czjZ6n4Q4OodMWEJwqtMPa1S3Fhqfu8icED+gbYPbn7tdaJa4CLFnDndJKBS5sxO6PeYFJ4kEChep1jIBXgp4u7vg/sMKjc+UCmctWxBCdKGE1Qhh/rqnJAKA16PbgTGGw5fyEOrngce83fCgtJISFiEmoIRlKiOeupFIJBjS4e9+Xk3dXMwQECH2j9qwCCGiQQnLRPRYMyGWRwmLECIalLAIIaJBCUsgEUG6O4oSQhqPEpaJ6g+HFeLnqb0gIUQwlLBMRNMSEmJ5lLBM5OupOaZ7oLfCCpEQ4jgoYZlI2wilfdv6WCESQhwHJSwB0fT1hJgXJSxCiGhQwiKEiAYlLEKIaFDCIoSIBiUsQohoUMIihIgGJSxCiGhQwiKEiAYNkWxhUqdH09n3aOVt7VAIER1KWBbWuYUXOgTon7yCEKKJLgktjJ7eIcR0lLAIIaJBCYsQIhqUsAghokEJy8KoDYsQ01HCsjCZEx1yQkxFvz0W5O/limAfd2uHQYhoUT8sCxrQrrm1QyBE1ChhWYC3u4vWSSsIIcahhGUBwzqprB0CIXaB2rDMJNjHHe5yKTrSYziECIbOsMzEReaEkV1bWDsMQuwKnWERQkSDEpaZeMjp5JUQodFvlcAGtPdFzoMyhDT3sHYohNgdSlgC81cq4K9UWDsMQuwSXRISQkSDEhYhRDQoYRFCRIMSFiFENChhEUJEgxIWIUQ0qFuDkRhjAICioiIrR0KIfaj9Xar93dKFEpaR7t27BwAIDAy0ciSE2Be1Wg2lUqmzDCUsI3l7P5qx+datW3oPLjFMUVERAgMDkZ2djSZNaHQLIYjpmDLGoFarERAQoLcsJSwjOf1vTHalUmnz/xHEpkmTJnRMBSaWY2roH39qdCeEiAYlLEKIaFDCMpJcLsfChQshl9MY7UKhYyo8ez2mEmbIvURCCLEBdIZFCBENSliEENGghEUsZsqUKYiJibF2GHbF0Y4pJSwd1qxZg+DgYLi6uiI8PBw///yztUOyiOXLlyMiIgKenp5o3rw5YmJicPnyZV4ZxhgWLVqEgIAAKBQKREVFISMjw0oRi8vy5cshkUiQkJDAW0/HVD9KWA3YsWMHEhISMH/+fKSlpaFfv34YPnw4bt26Ze3QzC4lJQVxcXE4deoUkpKSUFVVhejoaDx8+JArs2LFCqxcuRKrV69GamoqVCoVhgwZArVabcXIbV9qaio+//xzPP744xqf0TE1ACNa9ezZk82cOZO3rn379uzNN9+0UkTWk5eXxwCwlJQUxhhjNTU1TKVSsXfffZcrU1ZWxpRKJVu3bl2D9UyePJmNHDmSWz59+jTz9fVlS5cuNVvstkStVrOQkBCWlJTE+vfvz/75z39yn9ExNQydYWlRUVGBM2fOIDo6mrc+OjoaJ0+etFJU1lNYWAjg7+coMzMzkZubyzs+crkc/fv3N/j4HD16FIMGDcI777yD+fPnCx+0DYqLi8NTTz2FwYMHa3xGx9Qw9CyhFvn5+aiuroafnx9vvZ+fH3Jzc60UlXUwxjBnzhz07dsXnTp1AgDuGGg7Pjdv3tRb5+7duzFp0iR89tlnGDdunPBB26Cvv/4aZ8+eRWpqqtbP6ZgahhKWDhKJhLfMGNNYZ+/i4+Nx/vx5HD9+XOMzU47Pr7/+in379uGbb77BqFGjBI3VVmVnZ+Of//wnDh06BFdXV51l6ZjqRpeEWvj4+EAqlWqcTeXl5Wn8BbRnL7/8Mvbs2YPk5GS0bNmSW69SqQDApOPTpk0btG/fHhs3bkRFRYXwQdugM2fOIC8vD+Hh4ZDJZJDJZEhJScEnn3wCmUyG6upqOqYGooSlhYuLC8LDw5GUlMRbn5SUhD59+lgpKsthjCE+Ph67du3CkSNHEBwczPs8ODgYKpWKd3wqKiqQkpKi9/j4+PjgyJEjuH79OsaOHYvKykqzfAdbMmjQIFy4cAHp6encq0ePHpgwYQLS09MhlUrpmBrKqk3+Nuzrr79mzs7ObMOGDezixYssISGBubu7s6ysLGuHZnazZs1iSqWSHT16lN25c4d7lZSUcGXeffddplQq2a5du9iFCxfYuHHjmL+/PysqKmqw3rp3tO7cucPat2/PnnvuOVZZWWnur2Rz6t8lZIyOqSEoYenw6aefslatWjEXFxfWvXt37ra+vQOg9bVp0yauTE1NDVu4cCFTqVRMLpezyMhIduHCBZ311r8Fn5OTw0JDQ9mYMWNYVVWVmb6NbdKWsOiY6kejNRBCRIPasAghokEJixAiGpSwCCGiQQmLECIalLAIIaJBCYsQIhqUsAghokEJixAiGpSwCCGiQcPLEKNdv34diYmJOHHiBC5duoSCggJUVFTA3d0d/v7+aNOmDbp06YKePXsiKioKSqXS2iETO0GP5hCDPXjwAHPmzMHmzZth6H8bmUyGJUuW4M0339T4LCgoiBucLjk5GVFRUUKGS+wQnWERg9y7dw9RUVH4/fffeeubNWuGkJAQuLu7Q61WIzs7G3fu3OE+r6qqwu3bty0dLrFTlLCIQaZOncpLViNGjMDbb7+NiIgIjbI5OTk4ePAgvv32W/z444+WDJPYOUpYRK9ff/0Ve/fu5ZZnzJiBdevWNVg+ICAAU6dOxdSpU3Hjxg1cv37dEmESB0AJi+j1/fffc+8VCgXef/99g7dt3bo1WrdubYaoiCOibg1ErytXrnDvO3bsCE9PT5PrysrKgkQigUQi4c0GM2DAAG593Ze+hvj79+/jk08+wbBhw9CqVSsoFAoolUqEhYVh1qxZBk+RFRQUxO3z6NGjAB7dZFi1ahX69OkDlUoFhUKB4OBgxMbGGjULeHl5ORITE/Hss8+idevW8PDwgEwmg6enJ9q0aYPo6GgsWLAAJ06cMPhmhsOy5uiBRByGDBnCjTravn37RtWVmZnZ4Iim2l79+/dvsK41a9awpk2b6q1j7NixrLi4WGdcrVq14sonJyez06dP89Zpe82cOVPvUMTp6eksNDTU4O+7Y8cOUw6rw6BLQqJXs2bNuPfXrl3D7du3ebPoGEOhUGDo0KEAgJSUFJSVlQEAIiIiuIla69I2pTsAJCQk4OOPP+ata9OmDVq2bImKigpkZGSgqKgIALBjxw7cvHkTycnJeqfZAv6elqugoAAAEBISghYtWiAvLw8XL17kyq1btw4PHz7E1q1btdaTm5uLQYMG4d69e9w6Ly8vtGvXDp6enigpKcGdO3eQlZXFnVnV1NTojc+hWTtjEtv30Ucf8c4CIiMjWX5+fqPrrX9WY6jVq1fz4pkyZQq7ceMGr0xFRQVbv349c3d358q9/PLLBsXi4+PDALAePXqw9PR0XrkrV66wqKgo3v43b96stc74+HiuTEBAANu3bx+rrq7WKFdQUMC2b9/OhgwZwr7++muDj4MjooRF9Prrr7+Ym5sb75fUw8ODTZs2jX377bfszp07JtVrSsLKzs5mrq6u3Hbvv/++zvI///wzk8lkDABzcnLSSGzaYgHAOnfu3OBsNWVlZeyJJ57gyvr6+rKysjKNcq1bt+bKHD582KDvZ48TRwiJEhYxyIYNG3S2vbRo0YLFxMSwDz/8UO9ML7VMSVhz587lthk8eLBB28yaNYvb5v/+7//0xgKAnThxQmedFy9eZFKplCu/bds2jTIuLi7c56WlpQbFSnSjhEUMtnPnTubr62tQ43HXrl3Zzp07ddZnSsIKCAjgttm7d69B2xw/fpzbpmfPnnpj6dq1q0H11r0Z8fzzz2t83qRJE+7zU6dOGVQn0Y26NRCDPf/887hx4wY++ugjdO/eHRKJpMGy6enpGDNmDJ555hmo1WpB9n/jxg3k5ORwy4Y+e9ipUyfufVpamt6uA7U3BfQZPnw49z41NVXj8x49enDvJ0yYYFRXCKId3SUkRvHw8EBCQgISEhJw9+5dHD9+HKmpqTh79ixOnDiB4uJiXvm9e/dizJgx+OGHH+Dk1Li/jxkZGdx7mUyG0aNHG11HZWUlioqKdI4gUTfB6dKxY0fufVZWFqqqqiCT/f0r9eqrr+LIkSMAHo1wERkZidDQUDz55JOIjIxEnz594OfnZ/R3cGjWPsUj9qOyspLt27eP9evXT+MS8csvv9Qob+wl4aZNm4zqw9XQ6+bNmzpj2b9/v0Hf9/Tp07x67969q1HmvffeY05OTg3G0rlzZ7Z48WKWk5Nj0D4dHV0SEsHIZDI89dRTSElJweuvv8777LPPPmt0/Q8fPmx0HYD+vk4uLi4G1SOXy3nL5eXlGmXmzp2LtLQ0TJgwAe7u7hqfX7hwAW+//Tbatm2LDz/80KD9OjJKWERwEokE7777LkJCQrh1v/76K6qqqhpVr5eXF/c+KCgI7NFNI6NfQUFBOvdjaJtb/XINXWY+/vjj+PLLL3H//n2kpKRg6dKlGDx4MC/hlZSU4PXXX8dHH31k0L4dFSUsYhZSqRTR0dHcckVFBa/HtymaN2/Ovc/OzuZ6yQstKyvLoHKZmZncezc3N3h4eOgs7+LigsjISMyfPx9JSUnIz8/H2rVreU8SLFy4ULAzSXtECYuYTf2HpJ2dnXnLdRvhmQEP/UZERHDbVFdXIyUlRYAoNWm746evXLdu3Yzej4eHB2bOnIlvv/2WW6dWq3Hq1Cmj63IUlLCI2dQd5UEul6Np06a8z+u26ZSWluqtz8vLCz179uSWdY3J1Rj79u1DSUmJzjJVVVW8RNO3b1+T91d/3Pu//vrL5LrsHSUsoteBAweQn59v1DY3btzA/v37ueWoqCiNflsqlYp7b+ggfwkJCdz73bt388bqEkpRURHee+89nWXWrl3LG/p58uTJvM8NOWOsVVFRgcrKSm5Z20Pg5H8sf2OSiM2ECROYh4cHe/3119nFixf1lr9w4QILCQnh3b7/7rvvNMrVfcyma9eu7MGDB3rrrq6uZr179+a2UygUbOvWrXq3y8jIYNOnT2ebNm3S+nn9R3OkUmmDQ70cPHiQyeVyruzIkSM1ymRmZrK+ffuyPXv26B2C5l//+hdXl4uLCysoKND7fRwVzZpD9Jo4cSK2bdvGLXft2hX9+vVDeHg4/Pz84OnpieLiYly9ehVJSUnYv38/747gqFGjsGvXLo1609PT0b17d+5sxN3dHd27d0fTpk25s7FOnTph6dKlvO3+/PNPRERE8Ca76NatG0aPHo0uXbpAqVSipKQEubm5SEtLw+HDh7nx6NeuXYuZM2dqxFJ3Bp8xY8Zg586dAIBnn30Wzz//PAICApCXl4fdu3fjq6++4rpGeHl54fz58wgMDOTVl5WVheDgYACAj48PnnrqKURERCA4OBhKpRKlpaX4448/8PXXX+PEiRPcdgkJCXSnUBcrJ0wiArGxsSZ30pwwYQIrLy9vsO4FCxbo3L6hAfxu3rzJunbtanQ8a9eu1Vpf/U6sEydO1FuXu7t7gw9JGztQIQD29NNP00PSelDCInqVl5ezH374gb300kusbdu2en/xnJ2d2YgRI1hSUpJB9R85coRNnDiRtWvXjnl4eDCJRKI3YTH2aMyrdevWaVx+1n95eHiwp59+mm3fvr3BhKCt1/2KFStYs2bNtNY5YMAAdvny5QZjKykpYStWrGD9+vXjjdqg7dWuXTu2fv16VlNTY9DxcmR0SUiMVjvy5vXr11FQUICysjK4ubnBy8sL7du3R5cuXbT26janGzdu4Ndff0VeXh7UajXc3d3h5+eH9u3bo3PnzhpdKupraFLXiooKHDlyBJmZmSgsLIRKpULfvn3Rtm1bg2MrKyvDuXPncPXqVeTm5qK0tBTu7u5QqVTo1q0bwsLCTP7ejoYSFiGgWajFgro1EEJEgxIWIUQ0KGERQkSDEhYhRDQoYRFCRIPuEhJCRIPOsAghokEJixAiGpSwCCGiQQmLECIalLAIIaJBCYsQIhqUsAghokEJixAiGpSwCCGi8f+wPLaBK65JZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 310x340 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x900 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
