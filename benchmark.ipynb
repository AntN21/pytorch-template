{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark for signal representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from apyori import apriori\n",
    "\n",
    "# import pywt\n",
    "\n",
    "# import pymultifracs.mfa as mfa\n",
    "# from pymultifracs.utils import build_q_log\n",
    "# from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import PatientData, DictObj, PatientDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\Users\\aejog\\Documents\\stage-inria\\projets\\bits2beat-tests\\src\\benchmark\\..\\data\\transformations.ipynb\n",
      "importing Jupyter notebook from c:\\Users\\aejog\\Documents\\stage-inria\\projets\\bits2beat-tests\\src\\benchmark\\..\\data\\prep_synth_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../')\n",
    "import config\n",
    "# # sys.path.append('data/')\n",
    "# import data.dataset as dataset\n",
    "# # from dataset import PatientData, DictObj, PatientDataset\n",
    "import import_ipynb\n",
    "#from transformations import DataTransform,TransformationRegistry, IdentityTransform, FourierTransform, LowFourierTransform, LowPsdTransform, WaveDecTransform, DwtTransform, CwtTransform, AutoRegTransform, ShannonEncodingTransform, WaveletLeadersTransform, CrossCorTransform, AutoCorTransform, MultiFracsTransform, AutoEncoderTransform  \n",
    "from data.transformations import *\n",
    "from data.prep_synth_data import create_synth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.model_selection import  KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "# %pip install  --user git+https://github.com/neurospin/pymultifracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the registry\n",
    "registry = initialize_registry()#TransformationRegistry()\n",
    "\n",
    "# # Register transformations\n",
    "# registry.register('identity', IdentityTransform)\n",
    "# registry.register('mean', Mean)\n",
    "# registry.register('std', StandardDeviation)\n",
    "# registry.register('fourier', FourierTransform)\n",
    "# registry.register('low_fourier', LowFourierTransform)\n",
    "# registry.register('low_psd', LowPsdTransform)\n",
    "# registry.register('wavedec', WaveDecTransform)\n",
    "# registry.register('dwt', DwtTransform)\n",
    "# registry.register('cwt', CwtTransform)\n",
    "# registry.register('autoreg', AutoRegTransform)\n",
    "# registry.register('shannon_encoding', ShannonEncodingTransform)\n",
    "# registry.register('wavelet_leaders', WaveletLeadersTransform)\n",
    "# registry.register('multifracs', MultiFracsTransform)\n",
    "# registry.register('crosscor', CrossCorTransform)\n",
    "# registry.register('autocor', AutoCorTransform)\n",
    "# registry.register('autoencoder', AutoEncoderTransform)\n",
    "# registry.register('waveletscattering', WaveletScattering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "Link here [ecgs_labels.npy](https://drive.google.com/file/d/1cbUKH9qGOeIZD6Mf73plMkyXpq56mwIu/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"ECG\"\n",
    "# DATASET = \"HRV\"\n",
    "# DATASET = \"HRV_chall2002\"\n",
    "DATASET = \"SYNTH_DATA\"\n",
    "# DATASET = \"SYNTH_DATA2\"\n",
    "# DATASET = \"SYNTH_DATA3\"\n",
    "#DATASET = \"SYNTH_DATA4\"\n",
    "# DATASET = \"SYNTH_DATA_SAME\"\n",
    "# DATASET = \"HRV_DATA_GOOD\"\n",
    "DATASET = \"NORM_AF_CHF_ST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"ECG\":\n",
    "    ecgs_labels = np.load('ecgs_labels.npy')\n",
    "\n",
    "    X, y = ecgs_labels[1:,:-1], ecgs_labels[1:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"HRV\":\n",
    "    X, y = np.load('hrv_signals.npy'), np.load('hrv_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"HRV_chall2002\":\n",
    "    hrvs_labels = np.load('hrv_data.npy')\n",
    "\n",
    "    X, y = hrvs_labels[:,:-1], hrvs_labels[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"HRV_DATA_GOOD\":\n",
    "    hrvs_labels = np.load('hrv_data_good.npy')\n",
    "\n",
    "    X, y = hrvs_labels[:,:-1], hrvs_labels[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"SYNTH_DATA\":\n",
    "    Hs = [.01,.05,.1,.3,.03,.5,.6,.7,.75,.8,.9]\n",
    "    lams = np.maximum(.17 + .03 * np.random.randn(len(Hs)),0.03)\n",
    "    X, y = create_synth_data(Hs=Hs,\n",
    "                             lams=lams,\n",
    "                             n_per_class=100,\n",
    "                             length = 2048,\n",
    "                             concatenate_result=False\n",
    "                             )\n",
    "    # data = np.load('synth_data.npy')\n",
    "\n",
    "    # X, y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"SYNTH_DATA2\":\n",
    "    data = np.load('synth_data2.npy')\n",
    "\n",
    "    X, y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET ==  \"SYNTH_DATA3\":\n",
    "    data = np.load('synth_data3.npy')\n",
    "\n",
    "    X, y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"SYNTH_DATA4\":\n",
    "    data = np.load('synth_data_0.8_0.75.npy')\n",
    "\n",
    "    X, y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"SYNTH_DATA_SAME\":\n",
    "    data = np.load('synth_data_same.npy')\n",
    "\n",
    "    X, y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"NORM_AF_CHF_ST\":\n",
    "    \n",
    "    \n",
    "    data = torch.load(os.path.join(config.DATA_DIR,'data_with_added_features.pth'))\n",
    "    dataset = PatientDataset(data)\n",
    "    X = np.array(dataset.features)\n",
    "    y = np.array(dataset.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : (1920, 7)\n"
     ]
    }
   ],
   "source": [
    "n,p = X.shape\n",
    "\n",
    "print(f'X.shape : {n,p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j2max = min(12,int(np.log2(p) - 3.3))\n",
    "j2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = 65_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Shape: (10, 65000)\n",
      "Computing  mean ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: mean, Shape: (10, 1)\n",
      "Transformation: std, Shape: (10, 1)\n",
      "Transformation: fourier, Shape: (10, 65000)\n",
      "Transformation: low_fourier, Shape: (10, 1092)\n",
      "Transformation: low_psd, Shape: (10, 1092)\n",
      "Transformation: wavedec, Shape: (10, 4063)\n",
      "Transformation: dwt, Shape: (10, 32500)\n",
      "Transformation: cwt, Shape: (10, 10)\n",
      "Transformation: autoreg, Shape: (10, 3)\n",
      "Transformation: shannon_encoding, Shape: (10, 8)\n",
      "Transformation: wavelet_leaders, Shape: (10, 2)\n",
      "Transformation: multifracs, Shape: (10, 3)\n",
      "Transformation: newmultifracs, Shape: (10, 5)\n",
      "Transformation: crosscor, Shape: (10, 10)\n",
      "Transformation: autocor, Shape: (10, 26000)\n",
      "Computing  autoencoder ..."
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TensorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m trans_names \u001b[38;5;241m=\u001b[39m trans_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trans_names, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m trans_names\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply transformation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m transformed_X \u001b[38;5;241m=\u001b[39m data_transformer\u001b[38;5;241m.\u001b[39mapply_transformation(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mp_))\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m10\u001b[39m,p_)), trans_names, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformed_X\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<string>:88\u001b[0m, in \u001b[0;36mapply_transformation\u001b[1;34m(self, X, transformations)\u001b[0m\n",
      "File \u001b[1;32m<string>:302\u001b[0m, in \u001b[0;36mtransform\u001b[1;34m(X, mode, fourier_transform, n_fourier, dim_encoder, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m<string>:32\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "data_transformer = DataTransform(registry,save_data=False)\n",
    "for trans_names in registry.transformations.keys():\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(np.random.randn((10*p_)).reshape((10,p_)), trans_names, **kwargs)\n",
    "        \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform(registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformations = [\n",
    "    # ['identity'],\n",
    "    ['crosscor'],\n",
    "    ['autocor', {'m':5000,'k':4}],\n",
    "    ['fourier', {'new_dimension':40}],\n",
    "    ['low_fourier'],\n",
    "    ['low_psd'],\n",
    "    ['cwt',{'pca_components' : 10}],\n",
    "    ['wavedec'],\n",
    "    ['autoreg', {'k': 3}],\n",
    "    ['shannon_encoding'],\n",
    "    ['wavelet_leaders'],\n",
    "    ['multifracs'],\n",
    "    ['multifracs', {'j1':1,'j2':12}],\n",
    "    [['wavelet_leaders','shannon_encoding']],\n",
    "    [['wavelet_leaders','multifracs']],\n",
    "    [['fourier','multifracs',], {'new_dimension':40}],\n",
    "    [['fourier','multifracs',], {'new_dimension':40}],\n",
    "    [['fourier','multifracs','shannon_encoding'], {'new_dimension':40}],\n",
    "    [['low_fourier','multifracs','autoreg'], {'k':3}],\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate a classifier using cross-validation\n",
    "def evaluate_classifier_cv(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Loop over each transformation and each classifier\n",
    "results = {}\n",
    "\n",
    "for trans_names in transformations:\n",
    "    # print()\n",
    "    trans_names_str = [str(name) for name in trans_names]\n",
    "    trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "    kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "    trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "    print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\" )\n",
    "    # Standardize the data (important for some classifiers like SVM)\n",
    "    scaler = StandardScaler()\n",
    "    transformed_X = scaler.fit_transform(transformed_X)\n",
    "    \n",
    "    results[trans_name_str] = {}\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier with cross-validation\n",
    "        mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "        results[trans_name_str][clf_name] = (mean_accuracy, std_accuracy)\n",
    "        print(f\"Transformation: {trans_name_str}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "    print()\n",
    "# Print the results\n",
    "for trans_name, clf_results in results.items():\n",
    "    print()\n",
    "    for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform(registry)\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformation_names = ['crosscor','low_psd','low_fourier',['autoreg',{'k':3}],['autoreg',{'k':5}], #'multifracs',\n",
    "                        ['multifracs', {'j1':1,'j2':j2max}],\n",
    "                        'shannon_encoding',['autoencoder',{'fourier_transform':True}]] #list(registry.transformations.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate a classifier using cross-validation\n",
    "def evaluate_classifier_cv(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Function to randomly combine transformations\n",
    "def random_combination_transformations(transformation_list, n_combinations=10):\n",
    "    # all_combinations = []\n",
    "    # for r in range(1, len(transformation_names) + 1):\n",
    "    #     combinations = list(itertools.combinations(transformation_names, r))\n",
    "    #     all_combinations.extend(combinations)\n",
    "    \n",
    "    # return random.sample(all_combinations, min(n_combinations, len(all_combinations)))\n",
    "    nb_transformation = len(transformation_list)\n",
    "    combined_transformations = []\n",
    "    for _ in range(n_combinations):\n",
    "        nb_trans = np.random.randint(1,5)\n",
    "\n",
    "        already_drawn = []\n",
    "        transs = []\n",
    "        for _ in range(nb_trans):\n",
    "            while True:\n",
    "                random_ind = np.random.randint(nb_transformation)\n",
    "                if random_ind not in already_drawn:\n",
    "                    already_drawn.append(random_ind)\n",
    "                    break\n",
    "            trans = transformation_list[random_ind]\n",
    "            transs.append(trans)\n",
    "            \n",
    "        combined_transformations.append(transs)\n",
    "    return combined_transformations\n",
    "# Generate random combinations of transformations\n",
    "random_transformations = random_combination_transformations(transformation_names, n_combinations=5)\n",
    "print(random_transformations)\n",
    "# # Example input data\n",
    "# X = np.random.randn(100, 10)  # Example input data\n",
    "# y = np.random.randint(0, 2, 100)  # Example labels\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "i = 0\n",
    "# Loop over each random combination of transformations and each classifier\n",
    "for trans in random_transformations:\n",
    "    print()\n",
    "    trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "    \n",
    "        \n",
    "    transformed_X = data_transformer.apply_transformation(X, trans)\n",
    "\n",
    "    # trans_name_str = '+'.join(trans_comb)\n",
    "    # transformed_X = data_transformer.apply_transformation(X, trans_comb)\n",
    "    \n",
    "    # Standardize the data (important for some classifiers like SVM)\n",
    "    scaler = StandardScaler()\n",
    "    transformed_X = scaler.fit_transform(transformed_X)\n",
    "    \n",
    "    results[trans_name_str] = {}\n",
    "    i += 1\n",
    "    print(f\"Transformations nÂ°{i}: {trans_name_str} {transformed_X.shape}\")\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier with cross-validation\n",
    "        mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "        results[trans_name_str][clf_name] = {'mean_accuracy': mean_accuracy, 'std_accuracy': std_accuracy}\n",
    "        print(f\"Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open('transformation_results0.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save results to a JSON file\n",
    "# with open('transformation_results_hrv_chall2002.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformations(X, y, transformations, classifiers):\n",
    "    dt = DataTransform(registry)\n",
    "    results = []\n",
    "\n",
    "    for trans in transformations:\n",
    "        trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "        trans_X = dt.apply_transformation(X, trans)\n",
    "\n",
    "        result = {'Transformation (shape)': trans_name_str}\n",
    "        result[\"shape\"] = trans_X.shape[-1]\n",
    "        result['nb_trans'] = len(trans)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        trans_X = scaler.fit_transform(trans_X) \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {trans_X.shape[-1]} \")\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            scores = cross_val_score(clf, trans_X, y, cv=kf, scoring='accuracy')\n",
    "            result[f'{clf_name} accuracy'] = np.mean(scores)\n",
    "            result[f'{clf_name} std'] = np.std(scores)\n",
    "            print(f\"Classifier: {clf_name}, \"\n",
    "                  f\"Mean Accuracy: {np.mean(scores):.3f}, Std Accuracy: {np.std(scores):.3f}\")\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 ...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aejog\\documents\\stage-inria\\projets\\kymatio\\kymatio\\scattering1d\\filter_bank.py:195: UserWarning: Signal support is too small to avoid border effects\n",
      "  warnings.warn('Signal support is too small to avoid border effects')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1920, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m: SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecisionTree\u001b[39m\u001b[38;5;124m'\u001b[39m: DecisionTreeClassifier(),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier()\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m transformations \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaveletscattering\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m}],[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaveletscattering\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 8\u001b[0m results_df \u001b[38;5;241m=\u001b[39m evaluate_transformations(X, y, transformations, classifiers)\n",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m, in \u001b[0;36mevaluate_transformations\u001b[1;34m(X, y, transformations, classifiers)\u001b[0m\n\u001b[0;32m     11\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_trans\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trans)\n\u001b[0;32m     13\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 14\u001b[0m trans_X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(trans_X) \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf_name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    874\u001b[0m     X,\n\u001b[0;32m    875\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    876\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    877\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    878\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:978\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    982\u001b[0m         )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1920, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "transformations = [['waveletscattering',{'Q':1}],['waveletscattering']]\n",
    "results_df = evaluate_transformations(X, y, transformations, classifiers)\n",
    "# print(results_df)\n",
    "\n",
    "# Save results to a CSV file\n",
    "# results_df.to_csv(f'results/test_wst_transformation_results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the classifiers\n",
    "# classifiers = {\n",
    "#     'SVM': SVC(kernel='linear'),\n",
    "#     'DecisionTree': DecisionTreeClassifier(),\n",
    "#     'RandomForest': RandomForestClassifier()\n",
    "# }\n",
    "# Q = 3\n",
    "# transformations = [ ['waveletscattering',{'J':J,'Q':Q}] for J in range(0,12,4) ]\n",
    "# # transformations = [['waveletscattering',{'Q':1}],['waveletscattering',{'J':3,'Q':1}],['waveletscattering',{'J':7,'Q':1}],['waveletscattering',{'pca_components':200,'Q':1}]]\n",
    "# results_df = evaluate_transformations(X, y, transformations, classifiers)\n",
    "# # print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the classifiers\n",
    "# classifiers = {\n",
    "#     'SVM': SVC(kernel='linear'),\n",
    "#     'DecisionTree': DecisionTreeClassifier(),\n",
    "#     'RandomForest': RandomForestClassifier()\n",
    "# }\n",
    "# Q = 3\n",
    "# transformations = [ ['waveletscattering',{'J':J,'Q':Q,'pca_components':200}] for J in range(10) ]\n",
    "# # transformations = [['waveletscattering',{'Q':1}],['waveletscattering',{'J':3,'Q':1}],['waveletscattering',{'J':7,'Q':1}],['waveletscattering',{'pca_components':200,'Q':1}]]\n",
    "# results_df = evaluate_transformations(X, y, transformations, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Transformation: waveletscattering, Shape: 65536\\n\\\n",
    "# Classifier: SVM, Mean Accuracy: 0.995, Std Accuracy: 0.010\\n\\\n",
    "# Classifier: DecisionTree, Mean Accuracy: 0.810, Std Accuracy: 0.085\\n\\\n",
    "# Classifier: RandomForest, Mean Accuracy: 0.995, Std Accuracy: 0.010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_combination_transformations(transformation_names, k = 2):\n",
    "    all_combinations = []\n",
    "    for r in range(1, k + 1):\n",
    "        combinations = list(itertools.combinations(transformation_names, r))\n",
    "        all_combinations.extend(combinations)\n",
    "    \n",
    "    return [list(x) for x in all_combinations] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(f'results/new__results_{DATASET}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: crosscor, Shape: 10 \n",
      "Classifier: SVM, Mean Accuracy: 0.678, Std Accuracy: 0.025\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.622, Std Accuracy: 0.012\n",
      "Classifier: RandomForest, Mean Accuracy: 0.720, Std Accuracy: 0.027\n",
      "Transformation: std, Shape: 1 \n",
      "Classifier: SVM, Mean Accuracy: 0.508, Std Accuracy: 0.013\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.416, Std Accuracy: 0.016\n",
      "Classifier: RandomForest, Mean Accuracy: 0.416, Std Accuracy: 0.016\n",
      "Transformation: identity, Shape: 7 \n",
      "Classifier: SVM, Mean Accuracy: 0.688, Std Accuracy: 0.025\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.658, Std Accuracy: 0.022\n",
      "Classifier: RandomForest, Mean Accuracy: 0.717, Std Accuracy: 0.013\n",
      "                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aejog\\documents\\stage-inria\\projets\\kymatio\\kymatio\\scattering1d\\filter_bank.py:195: UserWarning: Signal support is too small to avoid border effects\n",
      "  warnings.warn('Signal support is too small to avoid border effects')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1920, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m t \u001b[38;5;241m=\u001b[39m random_combination_transformations(transformations,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     36\u001b[0m transformations \u001b[38;5;241m=\u001b[39m t\n\u001b[1;32m---> 40\u001b[0m results_df \u001b[38;5;241m=\u001b[39m evaluate_transformations(X, y, transformations, classifiers)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# print(results_df)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Save results to a CSV file\u001b[39;00m\n\u001b[0;32m     44\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/new__results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m, in \u001b[0;36mevaluate_transformations\u001b[1;34m(X, y, transformations, classifiers)\u001b[0m\n\u001b[0;32m     11\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_trans\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trans)\n\u001b[0;32m     13\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 14\u001b[0m trans_X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(trans_X) \n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf_name, clf \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    874\u001b[0m     X,\n\u001b[0;32m    875\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    876\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m    877\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    878\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[0;32m    879\u001b[0m )\n\u001b[0;32m    880\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:978\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    979\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    980\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    982\u001b[0m         )\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1920, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    # 'MLPClassifier': MLPClassifier(),\n",
    "}\n",
    "\n",
    "# # Define the data transformations\n",
    "# transformations = [\n",
    "#     'identity',\n",
    "#     ['fourier', {'new_dimension': 100}],\n",
    "#     ['wavedec', {'level': 4, 'wavelet': 'db1'}],\n",
    "#     ['autoreg', {'k': 1}]\n",
    "# ]\n",
    "# Define the transformations to be tested\n",
    "transformations = ['crosscor','std',\n",
    "                   'identity',\n",
    "                   #\"waveletscattering\",\n",
    "                    #'low_psd','low_fourier',\n",
    "                    ['autoreg',{'k':1}], ['autoreg',{'k':2}],['autoreg',{'k':3}],\n",
    "                    ['autoreg',{'k':5}],\n",
    "                    ['wavelet_leaders', {'j1':3,'j2':j2max}],\n",
    "                    ['multifracs', {'j1':4,'j2':j2max}], #'multifracs',\n",
    "                    ['multifracs', {'j1':1,'j2':j2max}],\n",
    "                    ['newmultifracs', {'j1':2,'j2':j2max}],\n",
    "                    'shannon_encoding',['autoencoder',{'fourier_transform':True}]]\n",
    "\n",
    "if DATASET == \"ECG\":\n",
    "    transformations.extend([\"low_psd\",\"low_fourier\"])\n",
    "\n",
    "t = random_combination_transformations(transformations,k=4)\n",
    "transformations = t\n",
    "\n",
    "\n",
    "\n",
    "results_df = evaluate_transformations(X, y, transformations, classifiers)\n",
    "# print(results_df)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv(f'results/new__results_{DATASET}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SYNTH_DATA'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformation_names(transformations):\n",
    "    # san_transformations = DataTransform.sanitize_transformations(transformations)\n",
    "    transformation_names = list()\n",
    "    for transformation in transformations:\n",
    "        # print(transformation)\n",
    "        # input = transformation\n",
    "        # print(len(input) == 2 and isinstance(input[0], str) and isinstance(input[1], dict))\n",
    "        s_transformation = DataTransform.sanitize_transformations(transformation)\n",
    "        names = list()\n",
    "        for trans in transformation:\n",
    "            trans_name, kwargs = DataTransform.handle_trans_kwargs(trans)\n",
    "            names.append(DataTransform.get_trans_kwargs_str(trans_name, kwargs)) \n",
    "        transformation_names.append(names)\n",
    "    return transformation_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataTransform.sanitize_transformations(transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = ['crosscor','std',\n",
    "                    #'low_psd','low_fourier',\n",
    "                    #['autoreg',{'k':1}], ['autoreg',{'k':2}],['autoreg',{'k':3}],\n",
    "                    ['autoreg',{'k':5}], #'multifracs',\n",
    "                    ['multifracs', {'j1':1,'j2':j2max}],\n",
    "                    'shannon_encoding',['autoencoder',{'fourier_transform':True}]]\n",
    "\n",
    "if DATASET == \"ECG\":\n",
    "    transformations.extend([\"low_psd\",\"low_fourier\"])\n",
    "\n",
    "transformations = random_combination_transformations(transformations,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformations_and_get_aprior(X, y, transformations, classifier1, classifier2, seed = 42):\n",
    "    dt = DataTransform(registry)\n",
    "    results = []\n",
    "    transformation_names = get_transformation_names(transformations)\n",
    "\n",
    "    clf1better = list()\n",
    "    clf2better = list()\n",
    "    apr_list = list()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for trans, trans_names in zip(transformations,transformation_names):\n",
    "        trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "        trans_X = dt.apply_transformation(X, trans)\n",
    "\n",
    "        result = {'Transformation (shape)': trans_name_str}\n",
    "        result[\"shape\"] = trans_X.shape[-1]\n",
    "        result['nb_trans'] = len(trans)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        trans_X = scaler.fit_transform(trans_X) \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {trans_X.shape[-1]} \")\n",
    "\n",
    "        scores = cross_val_score(classifier1, trans_X, y, cv=kf, scoring='accuracy')\n",
    "        clf1_mean = np.mean(scores)\n",
    "        clf1_std = np.std(scores)\n",
    "        result[f'{classifier1.__class__.__name__} accuracy'] = clf1_mean\n",
    "        result[f'{classifier1.__class__.__name__} std'] = clf1_std\n",
    "        print(f\"Classifier: {classifier1.__class__.__name__}, \"\n",
    "                f\"Mean Accuracy: {np.mean(scores):.3f}, Std Accuracy: {np.std(scores):.3f}\")\n",
    "        scores = cross_val_score(classifier2, trans_X, y, cv=kf, scoring='accuracy')\n",
    "        clf2_mean = np.mean(scores)\n",
    "        clf2_std = np.std(scores)\n",
    "        result[f'{classifier2.__class__.__name__} accuracy'] = clf2_mean\n",
    "        result[f'{classifier2.__class__.__name__} std'] = clf2_std\n",
    "        print(f\"Classifier: {classifier2.__class__.__name__}, \"\n",
    "                f\"Mean Accuracy: {np.mean(scores):.3f}, Std Accuracy: {np.std(scores):.3f}\")\n",
    "        \n",
    "        if clf1_mean - 0.02  > clf2_mean: # clf1_mean > clf2_mean: #clf1_mean - clf1_std > clf2_mean + clf2_std: # + clf2_std:\n",
    "            clf1better.extend(trans_names)\n",
    "            apr_list.append(trans_names + ['clf1'])\n",
    "        elif clf2_mean - 0.02 > clf1_mean: # clf2_mean > clf1_mean:#clf2_mean - clf2_std > clf1_mean + clf1_std: # + clf1_std:\n",
    "            clf2better.extend(trans_names)\n",
    "            apr_list.append(trans_names + ['clf2'])\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results), pd.Series(clf1better), pd.Series(clf2better), apr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: crosscor, Shape: 10 \n",
      "Classifier: SVC, Mean Accuracy: 0.088, Std Accuracy: 0.010\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.121, Std Accuracy: 0.027\n",
      "Transformation: std, Shape: 1 \n",
      "Classifier: SVC, Mean Accuracy: 0.242, Std Accuracy: 0.013\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.261, Std Accuracy: 0.010\n",
      "Transformation: autoreg_k=5, Shape: 5 \n",
      "Classifier: SVC, Mean Accuracy: 0.854, Std Accuracy: 0.013\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.847, Std Accuracy: 0.020\n",
      "Transformation: multifracs_j1=1_j2=7, Shape: 3 \n",
      "Classifier: SVC, Mean Accuracy: 0.633, Std Accuracy: 0.032\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.586, Std Accuracy: 0.018\n",
      "Transformation: shannon_encoding, Shape: 8 \n",
      "Classifier: SVC, Mean Accuracy: 0.506, Std Accuracy: 0.029\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.994, Std Accuracy: 0.002\n",
      "Transformation: autoencoder_fourier_transform=True, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.142, Std Accuracy: 0.018\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.260, Std Accuracy: 0.025\n",
      "Transformation: crosscor_std, Shape: 11 \n",
      "Classifier: SVC, Mean Accuracy: 0.248, Std Accuracy: 0.031\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.355, Std Accuracy: 0.024\n",
      "Transformation: crosscor_autoreg_k=5, Shape: 15 \n",
      "Classifier: SVC, Mean Accuracy: 0.819, Std Accuracy: 0.021\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.833, Std Accuracy: 0.009\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7, Shape: 13 \n",
      "Classifier: SVC, Mean Accuracy: 0.611, Std Accuracy: 0.029\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.589, Std Accuracy: 0.028\n",
      "Transformation: crosscor_shannon_encoding, Shape: 18 \n",
      "Classifier: SVC, Mean Accuracy: 0.529, Std Accuracy: 0.020\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.993, Std Accuracy: 0.005\n",
      "Transformation: crosscor_autoencoder_fourier_transform=True, Shape: 26 \n",
      "Classifier: SVC, Mean Accuracy: 0.165, Std Accuracy: 0.019\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.295, Std Accuracy: 0.027\n",
      "Transformation: std_autoreg_k=5, Shape: 6 \n",
      "Classifier: SVC, Mean Accuracy: 0.854, Std Accuracy: 0.018\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.865, Std Accuracy: 0.020\n",
      "Transformation: std_multifracs_j1=1_j2=7, Shape: 4 \n",
      "Classifier: SVC, Mean Accuracy: 0.635, Std Accuracy: 0.026\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.586, Std Accuracy: 0.022\n",
      "Transformation: std_shannon_encoding, Shape: 9 \n",
      "Classifier: SVC, Mean Accuracy: 0.532, Std Accuracy: 0.027\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.993, Std Accuracy: 0.002\n",
      "Transformation: std_autoencoder_fourier_transform=True, Shape: 17 \n",
      "Classifier: SVC, Mean Accuracy: 0.263, Std Accuracy: 0.023\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.354, Std Accuracy: 0.017\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7, Shape: 8 \n",
      "Classifier: SVC, Mean Accuracy: 0.863, Std Accuracy: 0.015\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.870, Std Accuracy: 0.030\n",
      "Transformation: autoreg_k=5_shannon_encoding, Shape: 13 \n",
      "Classifier: SVC, Mean Accuracy: 0.961, Std Accuracy: 0.010\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.005\n",
      "Transformation: autoreg_k=5_autoencoder_fourier_transform=True, Shape: 21 \n",
      "Classifier: SVC, Mean Accuracy: 0.846, Std Accuracy: 0.012\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.807, Std Accuracy: 0.014\n",
      "Transformation: multifracs_j1=1_j2=7_shannon_encoding, Shape: 11 \n",
      "Classifier: SVC, Mean Accuracy: 0.818, Std Accuracy: 0.046\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.994, Std Accuracy: 0.005\n",
      "Transformation: multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 19 \n",
      "Classifier: SVC, Mean Accuracy: 0.633, Std Accuracy: 0.030\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.577, Std Accuracy: 0.022\n",
      "Transformation: shannon_encoding_autoencoder_fourier_transform=True, Shape: 24 \n",
      "Classifier: SVC, Mean Accuracy: 0.508, Std Accuracy: 0.028\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.004\n",
      "Transformation: crosscor_std_autoreg_k=5, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.817, Std Accuracy: 0.016\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.861, Std Accuracy: 0.013\n",
      "Transformation: crosscor_std_multifracs_j1=1_j2=7, Shape: 14 \n",
      "Classifier: SVC, Mean Accuracy: 0.613, Std Accuracy: 0.031\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.589, Std Accuracy: 0.024\n",
      "Transformation: crosscor_std_shannon_encoding, Shape: 19 \n",
      "Classifier: SVC, Mean Accuracy: 0.552, Std Accuracy: 0.018\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.005\n",
      "Transformation: crosscor_std_autoencoder_fourier_transform=True, Shape: 27 \n",
      "Classifier: SVC, Mean Accuracy: 0.275, Std Accuracy: 0.037\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.378, Std Accuracy: 0.023\n",
      "Transformation: crosscor_autoreg_k=5_multifracs_j1=1_j2=7, Shape: 18 \n",
      "Classifier: SVC, Mean Accuracy: 0.830, Std Accuracy: 0.025\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.865, Std Accuracy: 0.022\n",
      "Transformation: crosscor_autoreg_k=5_shannon_encoding, Shape: 23 \n",
      "Classifier: SVC, Mean Accuracy: 0.943, Std Accuracy: 0.006\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.996, Std Accuracy: 0.004\n",
      "Transformation: crosscor_autoreg_k=5_autoencoder_fourier_transform=True, Shape: 31 \n",
      "Classifier: SVC, Mean Accuracy: 0.817, Std Accuracy: 0.026\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.802, Std Accuracy: 0.022\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7_shannon_encoding, Shape: 21 \n",
      "Classifier: SVC, Mean Accuracy: 0.802, Std Accuracy: 0.031\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.994, Std Accuracy: 0.005\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 29 \n",
      "Classifier: SVC, Mean Accuracy: 0.607, Std Accuracy: 0.032\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.574, Std Accuracy: 0.032\n",
      "Transformation: crosscor_shannon_encoding_autoencoder_fourier_transform=True, Shape: 34 \n",
      "Classifier: SVC, Mean Accuracy: 0.535, Std Accuracy: 0.022\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.003\n",
      "Transformation: std_autoreg_k=5_multifracs_j1=1_j2=7, Shape: 9 \n",
      "Classifier: SVC, Mean Accuracy: 0.862, Std Accuracy: 0.016\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.868, Std Accuracy: 0.024\n",
      "Transformation: std_autoreg_k=5_shannon_encoding, Shape: 14 \n",
      "Classifier: SVC, Mean Accuracy: 0.957, Std Accuracy: 0.009\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.004\n",
      "Transformation: std_autoreg_k=5_autoencoder_fourier_transform=True, Shape: 22 \n",
      "Classifier: SVC, Mean Accuracy: 0.859, Std Accuracy: 0.016\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.839, Std Accuracy: 0.022\n",
      "Transformation: std_multifracs_j1=1_j2=7_shannon_encoding, Shape: 12 \n",
      "Classifier: SVC, Mean Accuracy: 0.819, Std Accuracy: 0.041\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.003\n",
      "Transformation: std_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 20 \n",
      "Classifier: SVC, Mean Accuracy: 0.629, Std Accuracy: 0.024\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.578, Std Accuracy: 0.016\n",
      "Transformation: std_shannon_encoding_autoencoder_fourier_transform=True, Shape: 25 \n",
      "Classifier: SVC, Mean Accuracy: 0.537, Std Accuracy: 0.029\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.005\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7_shannon_encoding, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.955, Std Accuracy: 0.014\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.005\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 24 \n",
      "Classifier: SVC, Mean Accuracy: 0.865, Std Accuracy: 0.023\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.861, Std Accuracy: 0.021\n",
      "Transformation: autoreg_k=5_shannon_encoding_autoencoder_fourier_transform=True, Shape: 29 \n",
      "Classifier: SVC, Mean Accuracy: 0.960, Std Accuracy: 0.011\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.004\n",
      "Transformation: multifracs_j1=1_j2=7_shannon_encoding_autoencoder_fourier_transform=True, Shape: 27 \n",
      "Classifier: SVC, Mean Accuracy: 0.818, Std Accuracy: 0.045\n",
      "Classifier: RandomForestClassifier, Mean Accuracy: 0.995, Std Accuracy: 0.005\n"
     ]
    }
   ],
   "source": [
    "res, apr1, apr2, apr_list = evaluate_transformations_and_get_aprior(X,y,transformations,SVC(kernel='linear'),RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multifracs_j1=1_j2=7                  7\n",
       "autoencoder_fourier_transform=True    4\n",
       "crosscor                              3\n",
       "std                                   3\n",
       "autoreg_k=5                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shannon_encoding                      16\n",
       "crosscor                              11\n",
       "autoencoder_fourier_transform=True     9\n",
       "std                                    9\n",
       "autoreg_k=5                            7\n",
       "multifracs_j1=1_j2=7                   6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: crosscor, Shape: 10 \n",
      "Classifier: SVC, Mean Accuracy: 0.088, Std Accuracy: 0.010\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.129, Std Accuracy: 0.018\n",
      "Transformation: std, Shape: 1 \n",
      "Classifier: SVC, Mean Accuracy: 0.242, Std Accuracy: 0.013\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.261, Std Accuracy: 0.010\n",
      "Transformation: autoreg_k=5, Shape: 5 \n",
      "Classifier: SVC, Mean Accuracy: 0.854, Std Accuracy: 0.013\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.815, Std Accuracy: 0.026\n",
      "Transformation: multifracs_j1=1_j2=7, Shape: 3 \n",
      "Classifier: SVC, Mean Accuracy: 0.633, Std Accuracy: 0.032\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.558, Std Accuracy: 0.014\n",
      "Transformation: shannon_encoding, Shape: 8 \n",
      "Classifier: SVC, Mean Accuracy: 0.506, Std Accuracy: 0.029\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.979, Std Accuracy: 0.006\n",
      "Transformation: autoencoder_fourier_transform=True, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.154, Std Accuracy: 0.021\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.240, Std Accuracy: 0.023\n",
      "Transformation: crosscor_std, Shape: 11 \n",
      "Classifier: SVC, Mean Accuracy: 0.248, Std Accuracy: 0.031\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.354, Std Accuracy: 0.029\n",
      "Transformation: crosscor_autoreg_k=5, Shape: 15 \n",
      "Classifier: SVC, Mean Accuracy: 0.819, Std Accuracy: 0.021\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.789, Std Accuracy: 0.020\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7, Shape: 13 \n",
      "Classifier: SVC, Mean Accuracy: 0.611, Std Accuracy: 0.029\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.548, Std Accuracy: 0.024\n",
      "Transformation: crosscor_shannon_encoding, Shape: 18 \n",
      "Classifier: SVC, Mean Accuracy: 0.529, Std Accuracy: 0.020\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.976, Std Accuracy: 0.011\n",
      "Transformation: crosscor_autoencoder_fourier_transform=True, Shape: 26 \n",
      "Classifier: SVC, Mean Accuracy: 0.185, Std Accuracy: 0.023\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.240, Std Accuracy: 0.026\n",
      "Transformation: std_autoreg_k=5, Shape: 6 \n",
      "Classifier: SVC, Mean Accuracy: 0.854, Std Accuracy: 0.018\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.835, Std Accuracy: 0.029\n",
      "Transformation: std_multifracs_j1=1_j2=7, Shape: 4 \n",
      "Classifier: SVC, Mean Accuracy: 0.635, Std Accuracy: 0.026\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.554, Std Accuracy: 0.019\n",
      "Transformation: std_shannon_encoding, Shape: 9 \n",
      "Classifier: SVC, Mean Accuracy: 0.532, Std Accuracy: 0.027\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.979, Std Accuracy: 0.009\n",
      "Transformation: std_autoencoder_fourier_transform=True, Shape: 17 \n",
      "Classifier: SVC, Mean Accuracy: 0.262, Std Accuracy: 0.020\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.329, Std Accuracy: 0.018\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7, Shape: 8 \n",
      "Classifier: SVC, Mean Accuracy: 0.863, Std Accuracy: 0.015\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.833, Std Accuracy: 0.028\n",
      "Transformation: autoreg_k=5_shannon_encoding, Shape: 13 \n",
      "Classifier: SVC, Mean Accuracy: 0.961, Std Accuracy: 0.010\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.975, Std Accuracy: 0.010\n",
      "Transformation: autoreg_k=5_autoencoder_fourier_transform=True, Shape: 21 \n",
      "Classifier: SVC, Mean Accuracy: 0.843, Std Accuracy: 0.016\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.805, Std Accuracy: 0.023\n",
      "Transformation: multifracs_j1=1_j2=7_shannon_encoding, Shape: 11 \n",
      "Classifier: SVC, Mean Accuracy: 0.818, Std Accuracy: 0.046\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.981, Std Accuracy: 0.007\n",
      "Transformation: multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 19 \n",
      "Classifier: SVC, Mean Accuracy: 0.626, Std Accuracy: 0.024\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.540, Std Accuracy: 0.025\n",
      "Transformation: shannon_encoding_autoencoder_fourier_transform=True, Shape: 24 \n",
      "Classifier: SVC, Mean Accuracy: 0.508, Std Accuracy: 0.028\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.977, Std Accuracy: 0.008\n",
      "Transformation: crosscor_std_autoreg_k=5, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.817, Std Accuracy: 0.016\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.815, Std Accuracy: 0.023\n",
      "Transformation: crosscor_std_multifracs_j1=1_j2=7, Shape: 14 \n",
      "Classifier: SVC, Mean Accuracy: 0.613, Std Accuracy: 0.031\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.545, Std Accuracy: 0.024\n",
      "Transformation: crosscor_std_shannon_encoding, Shape: 19 \n",
      "Classifier: SVC, Mean Accuracy: 0.552, Std Accuracy: 0.018\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.980, Std Accuracy: 0.009\n",
      "Transformation: crosscor_std_autoencoder_fourier_transform=True, Shape: 27 \n",
      "Classifier: SVC, Mean Accuracy: 0.285, Std Accuracy: 0.033\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.372, Std Accuracy: 0.018\n",
      "Transformation: crosscor_autoreg_k=5_multifracs_j1=1_j2=7, Shape: 18 \n",
      "Classifier: SVC, Mean Accuracy: 0.830, Std Accuracy: 0.025\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.815, Std Accuracy: 0.025\n",
      "Transformation: crosscor_autoreg_k=5_shannon_encoding, Shape: 23 \n",
      "Classifier: SVC, Mean Accuracy: 0.943, Std Accuracy: 0.006\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.976, Std Accuracy: 0.009\n",
      "Transformation: crosscor_autoreg_k=5_autoencoder_fourier_transform=True, Shape: 31 \n",
      "Classifier: SVC, Mean Accuracy: 0.822, Std Accuracy: 0.022\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.785, Std Accuracy: 0.026\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7_shannon_encoding, Shape: 21 \n",
      "Classifier: SVC, Mean Accuracy: 0.802, Std Accuracy: 0.031\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.977, Std Accuracy: 0.006\n",
      "Transformation: crosscor_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 29 \n",
      "Classifier: SVC, Mean Accuracy: 0.602, Std Accuracy: 0.028\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.541, Std Accuracy: 0.035\n",
      "Transformation: crosscor_shannon_encoding_autoencoder_fourier_transform=True, Shape: 34 \n",
      "Classifier: SVC, Mean Accuracy: 0.534, Std Accuracy: 0.023\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.975, Std Accuracy: 0.007\n",
      "Transformation: std_autoreg_k=5_multifracs_j1=1_j2=7, Shape: 9 \n",
      "Classifier: SVC, Mean Accuracy: 0.862, Std Accuracy: 0.016\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.831, Std Accuracy: 0.031\n",
      "Transformation: std_autoreg_k=5_shannon_encoding, Shape: 14 \n",
      "Classifier: SVC, Mean Accuracy: 0.957, Std Accuracy: 0.009\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.973, Std Accuracy: 0.015\n",
      "Transformation: std_autoreg_k=5_autoencoder_fourier_transform=True, Shape: 22 \n",
      "Classifier: SVC, Mean Accuracy: 0.859, Std Accuracy: 0.017\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.837, Std Accuracy: 0.023\n",
      "Transformation: std_multifracs_j1=1_j2=7_shannon_encoding, Shape: 12 \n",
      "Classifier: SVC, Mean Accuracy: 0.819, Std Accuracy: 0.041\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.980, Std Accuracy: 0.009\n",
      "Transformation: std_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 20 \n",
      "Classifier: SVC, Mean Accuracy: 0.632, Std Accuracy: 0.019\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.549, Std Accuracy: 0.024\n",
      "Transformation: std_shannon_encoding_autoencoder_fourier_transform=True, Shape: 25 \n",
      "Classifier: SVC, Mean Accuracy: 0.536, Std Accuracy: 0.029\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.978, Std Accuracy: 0.007\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7_shannon_encoding, Shape: 16 \n",
      "Classifier: SVC, Mean Accuracy: 0.955, Std Accuracy: 0.014\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.974, Std Accuracy: 0.015\n",
      "Transformation: autoreg_k=5_multifracs_j1=1_j2=7_autoencoder_fourier_transform=True, Shape: 24 \n",
      "Classifier: SVC, Mean Accuracy: 0.866, Std Accuracy: 0.022\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.845, Std Accuracy: 0.024\n",
      "Transformation: autoreg_k=5_shannon_encoding_autoencoder_fourier_transform=True, Shape: 29 \n",
      "Classifier: SVC, Mean Accuracy: 0.960, Std Accuracy: 0.011\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.973, Std Accuracy: 0.012\n",
      "Transformation: multifracs_j1=1_j2=7_shannon_encoding_autoencoder_fourier_transform=True, Shape: 27 \n",
      "Classifier: SVC, Mean Accuracy: 0.818, Std Accuracy: 0.042\n",
      "Classifier: DecisionTreeClassifier, Mean Accuracy: 0.976, Std Accuracy: 0.009\n"
     ]
    }
   ],
   "source": [
    "res, apr1, apr2, apr_list = evaluate_transformations_and_get_aprior(X,y,transformations,SVC(kernel='linear'),DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multifracs_j1=1_j2=7                  10\n",
       "autoreg_k=5                            8\n",
       "autoencoder_fourier_transform=True     7\n",
       "crosscor                               5\n",
       "std                                    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shannon_encoding                      12\n",
       "crosscor                               9\n",
       "autoencoder_fourier_transform=True     8\n",
       "std                                    7\n",
       "multifracs_j1=1_j2=7                   4\n",
       "autoreg_k=5                            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = list(apriori(apr_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: ['autoencoder_fourier_transform=True', 'clf1']\n",
      "Support: 0.21212121212121213 || 7 examples\n",
      "['autoencoder_fourier_transform=True'] ==> ['clf1']\n",
      "Confidence: 0.4666666666666667\n",
      "Lift: 1.0266666666666666\n",
      "-----\n",
      "Rule: ['autoencoder_fourier_transform=True', 'clf2']\n",
      "Support: 0.24242424242424243 || 8 examples\n",
      "['autoencoder_fourier_transform=True'] ==> ['clf2']\n",
      "Confidence: 0.5333333333333333\n",
      "Lift: 0.9777777777777779\n",
      "-----\n",
      "Rule: ['autoreg_k=5', 'clf1']\n",
      "Support: 0.24242424242424243 || 8 examples\n",
      "['autoreg_k=5'] ==> ['clf1']\n",
      "Confidence: 0.888888888888889\n",
      "Lift: 1.9555555555555557\n",
      "-----\n",
      "Rule: ['crosscor', 'clf1']\n",
      "Support: 0.15151515151515152 || 5 examples\n",
      "['crosscor'] ==> ['clf1']\n",
      "Confidence: 0.35714285714285715\n",
      "Lift: 0.7857142857142858\n",
      "-----\n",
      "Rule: ['multifracs_j1=1_j2=7', 'clf1']\n",
      "Support: 0.30303030303030304 || 10 examples\n",
      "['multifracs_j1=1_j2=7'] ==> ['clf1']\n",
      "Confidence: 0.7142857142857143\n",
      "Lift: 1.5714285714285716\n",
      "-----\n",
      "Rule: ['std', 'clf1']\n",
      "Support: 0.15151515151515152 || 5 examples\n",
      "['std'] ==> ['clf1']\n",
      "Confidence: 0.4166666666666667\n",
      "Lift: 0.9166666666666667\n",
      "-----\n",
      "Rule: ['crosscor', 'clf2']\n",
      "Support: 0.2727272727272727 || 9 examples\n",
      "['crosscor'] ==> ['clf2']\n",
      "Confidence: 0.6428571428571428\n",
      "Lift: 1.1785714285714286\n",
      "-----\n",
      "Rule: ['multifracs_j1=1_j2=7', 'clf2']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['multifracs_j1=1_j2=7'] ==> ['clf2']\n",
      "Confidence: 0.2857142857142857\n",
      "Lift: 0.5238095238095238\n",
      "-----\n",
      "Rule: ['shannon_encoding', 'clf2']\n",
      "Support: 0.36363636363636365 || 12 examples\n",
      "['shannon_encoding'] ==> ['clf2']\n",
      "Confidence: 1.0\n",
      "Lift: 1.8333333333333335\n",
      "-----\n",
      "Rule: ['std', 'clf2']\n",
      "Support: 0.21212121212121213 || 7 examples\n",
      "['std'] ==> ['clf2']\n",
      "Confidence: 0.5833333333333334\n",
      "Lift: 1.0694444444444446\n",
      "-----\n",
      "Rule: ['autoencoder_fourier_transform=True', 'autoreg_k=5', 'clf1']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['autoencoder_fourier_transform=True', 'autoreg_k=5'] ==> ['clf1']\n",
      "Confidence: 1.0\n",
      "Lift: 2.2\n",
      "-----\n",
      "Rule: ['autoencoder_fourier_transform=True', 'multifracs_j1=1_j2=7', 'clf1']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['autoencoder_fourier_transform=True', 'multifracs_j1=1_j2=7'] ==> ['clf1']\n",
      "Confidence: 0.8\n",
      "Lift: 1.7600000000000002\n",
      "-----\n",
      "Rule: ['autoencoder_fourier_transform=True', 'shannon_encoding', 'clf2']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['autoencoder_fourier_transform=True', 'shannon_encoding'] ==> ['clf2']\n",
      "Confidence: 1.0\n",
      "Lift: 1.8333333333333335\n",
      "-----\n",
      "Rule: ['std', 'multifracs_j1=1_j2=7', 'clf1']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['multifracs_j1=1_j2=7', 'std'] ==> ['clf1']\n",
      "Confidence: 0.8\n",
      "Lift: 1.7600000000000002\n",
      "-----\n",
      "Rule: ['crosscor', 'shannon_encoding', 'clf2']\n",
      "Support: 0.15151515151515152 || 5 examples\n",
      "['crosscor', 'shannon_encoding'] ==> ['clf2']\n",
      "Confidence: 1.0\n",
      "Lift: 1.8333333333333335\n",
      "-----\n",
      "Rule: ['multifracs_j1=1_j2=7', 'shannon_encoding', 'clf2']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['multifracs_j1=1_j2=7', 'shannon_encoding'] ==> ['clf2']\n",
      "Confidence: 1.0\n",
      "Lift: 1.8333333333333335\n",
      "-----\n",
      "Rule: ['std', 'shannon_encoding', 'clf2']\n",
      "Support: 0.12121212121212122 || 4 examples\n",
      "['shannon_encoding', 'std'] ==> ['clf2']\n",
      "Confidence: 1.0\n",
      "Lift: 1.8333333333333335\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for result in result_list:\n",
    "    items = [x for x in result.items]\n",
    "    \n",
    "    for ordered_stat in result.ordered_statistics:\n",
    "        if  (list(ordered_stat.items_add) == ['clf1'] or list(ordered_stat.items_add) == ['clf2']) and list(ordered_stat.items_base): \n",
    "            print(f\"Rule: {items}\")\n",
    "            print(f\"Support: {result.support} || {result.support * len(apr_list):.0f} examples\")\n",
    "            print(f\"{list(ordered_stat.items_base)} ==> {list(ordered_stat.items_add)}\")\n",
    "            print(f\"Confidence: {ordered_stat.confidence}\")\n",
    "            print(f\"Lift: {ordered_stat.lift}\")\n",
    "            print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVC'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC().__class__.__name__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
